{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kano117/Sign-Language-Recognition/blob/main/Model_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1kIppd72snQ"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/MSKA/data /content/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/ColabNotebooks/MSKA-main/data/CSL-Daily/CSL-Daily.train /content/data/CSL-Daily"
      ],
      "metadata": {
        "id": "pBDIfAo1Prsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/ColabNotebooks/MSKA-main/data/CSL-Daily/CSL-Daily.dev /content/data/CSL-Daily"
      ],
      "metadata": {
        "id": "GzmwLjGu8JA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/ColabNotebooks/MSKA-main/data/CSL-Daily/CSL-Daily.test /content/data/CSL-Daily"
      ],
      "metadata": {
        "id": "QB7KZHWD8J61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOvH_jGO1Gnc",
        "outputId": "e7ee6339-441f-4d4d-b1d7-dc4f7019448f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MSKA'...\n",
            "remote: Enumerating objects: 156, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 156 (delta 16), reused 8 (delta 8), pack-reused 135 (from 1)\u001b[K\n",
            "Receiving objects: 100% (156/156), 434.47 KiB | 10.86 MiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/sutwangyan/MSKA.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6D24jwMV4qFa",
        "outputId": "7a66b3ba-097a-43fc-eba2-834f09ca2b63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting absl-py==2.0.0 (from -r /content/drive/MyDrive/ColabNotebooks/MSKA-main/requirements.txt (line 1))\n",
            "  Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/ColabNotebooks/MSKA-main/requirements.txt (line 2)) (1.1.1)\n",
            "Collecting addict==2.4.0 (from -r /content/drive/MyDrive/ColabNotebooks/MSKA-main/requirements.txt (line 3))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting aenum==3.1.15 (from -r /content/drive/MyDrive/ColabNotebooks/MSKA-main/requirements.txt (line 4))\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting aiofiles==23.2.1 (from -r /content/drive/MyDrive/ColabNotebooks/MSKA-main/requirements.txt (line 5))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting aiohttp==3.9.1 (from -r /content/drive/MyDrive/ColabNotebooks/MSKA-main/requirements.txt (line 6))\n",
            "  Downloading aiohttp-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: aiosignal==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/ColabNotebooks/MSKA-main/requirements.txt (line 7)) (1.3.1)\n",
            "Collecting albumentations==1.3.1 (from -r /content/drive/MyDrive/ColabNotebooks/MSKA-main/requirements.txt (line 8))\n",
            "  Downloading albumentations-1.3.1-py3-none-any.whl.metadata (34 kB)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Please install PyTorch according to your CUDA version.\n",
        "!pip install -r /content/drive/MyDrive/ColabNotebooks/MSKA-main/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LfSiZtc1nyV",
        "outputId": "3155dbb3-39e4-44e7-e469-1890f43890cd",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/MSKA/train.py\", line 1, in <module>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 2486, in <module>\n",
            "    from torch import _meta_registrations\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py\", line 6636, in <module>\n",
            "    activate_meta()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py\", line 6633, in activate_meta\n",
            "    _meta_lib_dont_use_me_use_register_meta.impl(op_overload, fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/library.py\", line 323, in impl\n",
            "    self.m.impl(\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        " !python /content/MSKA/train.py --config /content/drive/MyDrive/ColabNotebooks/MSKA-main/configs/csl-daily_s2g.yaml --resume /content/drive/MyDrive/ColabNotebooks/MSKA-main/pretrained_models/best.pth --eval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/MSKA/train.py --config /content/drive/MyDrive/ColabNotebooks/MSKA-main/configs/csl-daily_s2g.yaml --epoch 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrcBsdK6eW5W",
        "outputId": "9f938ccd-f685-4d84-d37e-1849b5a0cd09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-25 16:27:35.598486: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-25 16:27:35.677589: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-25 16:27:35.687631: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-25 16:27:35.713670: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-25 16:27:37.599126: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "environ({'SHELL': '/bin/bash', 'NV_LIBCUBLAS_VERSION': '12.2.5.6-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'COLAB_JUPYTER_TRANSPORT': 'ipc', 'NV_NVML_DEV_VERSION': '12.2.140-1', 'NV_CUDNN_PACKAGE_NAME': 'libcudnn8', 'CGROUP_MEMORY_EVENTS': '/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events', 'NV_LIBNCCL_DEV_PACKAGE': 'libnccl-dev=2.19.3-1+cuda12.2', 'NV_LIBNCCL_DEV_PACKAGE_VERSION': '2.19.3-1', 'VM_GCE_METADATA_HOST': '169.254.169.253', 'HOSTNAME': 'e2b9acc4579c', 'LANGUAGE': 'en_US', 'TBE_RUNTIME_ADDR': '172.28.0.1:8011', 'COLAB_TPU_1VM': '', 'GCE_METADATA_TIMEOUT': '3', 'NVIDIA_REQUIRE_CUDA': 'cuda>=12.2 brand=tesla,driver>=470,driver<471 brand=unknown,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=geforce,driver>=470,driver<471 brand=geforcertx,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=titan,driver>=470,driver<471 brand=titanrtx,driver>=470,driver<471 brand=tesla,driver>=525,driver<526 brand=unknown,driver>=525,driver<526 brand=nvidia,driver>=525,driver<526 brand=nvidiartx,driver>=525,driver<526 brand=geforce,driver>=525,driver<526 brand=geforcertx,driver>=525,driver<526 brand=quadro,driver>=525,driver<526 brand=quadrortx,driver>=525,driver<526 brand=titan,driver>=525,driver<526 brand=titanrtx,driver>=525,driver<526', 'NV_LIBCUBLAS_DEV_PACKAGE': 'libcublas-dev-12-2=12.2.5.6-1', 'NV_NVTX_VERSION': '12.2.140-1', 'COLAB_JUPYTER_IP': '172.28.0.12', 'NV_CUDA_CUDART_DEV_VERSION': '12.2.140-1', 'NV_LIBCUSPARSE_VERSION': '12.1.2.141-1', 'COLAB_LANGUAGE_SERVER_PROXY_ROOT_URL': 'http://172.28.0.1:8013/', 'NV_LIBNPP_VERSION': '12.2.1.4-1', 'NCCL_VERSION': '2.19.3-1', 'KMP_LISTEN_PORT': '6000', 'TF_FORCE_GPU_ALLOW_GROWTH': 'true', 'ENV': '/root/.bashrc', 'PWD': '/content', 'TBE_EPHEM_CREDS_ADDR': '172.28.0.1:8009', 'COLAB_LANGUAGE_SERVER_PROXY_REQUEST_TIMEOUT': '30s', 'TBE_CREDS_ADDR': '172.28.0.1:8008', 'NV_CUDNN_PACKAGE': 'libcudnn8=8.9.6.50-1+cuda12.2', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'COLAB_JUPYTER_TOKEN': '', 'LAST_FORCED_REBUILD': '20241216', 'NV_NVPROF_DEV_PACKAGE': 'cuda-nvprof-12-2=12.2.142-1', 'NV_LIBNPP_PACKAGE': 'libnpp-12-2=12.2.1.4-1', 'NV_LIBNCCL_DEV_PACKAGE_NAME': 'libnccl-dev', 'TCLLIBPATH': '/usr/share/tcltk/tcllib1.20', '_': '/usr/local/bin/python', 'NV_LIBCUBLAS_DEV_VERSION': '12.2.5.6-1', 'NVIDIA_PRODUCT_NAME': 'CUDA', 'COLAB_KERNEL_MANAGER_PROXY_HOST': '172.28.0.12', 'NV_LIBCUBLAS_DEV_PACKAGE_NAME': 'libcublas-dev-12-2', 'USE_AUTH_EPHEM': '1', 'NV_CUDA_CUDART_VERSION': '12.2.140-1', 'COLAB_WARMUP_DEFAULTS': '1', 'HOME': '/root', 'LANG': 'en_US.UTF-8', 'COLUMNS': '100', 'CUDA_VERSION': '12.2.2', 'CLOUDSDK_CONFIG': '/content/.config', 'NV_LIBCUBLAS_PACKAGE': 'libcublas-12-2=12.2.5.6-1', 'NV_CUDA_NSIGHT_COMPUTE_DEV_PACKAGE': 'cuda-nsight-compute-12-2=12.2.2-1', 'COLAB_RELEASE_TAG': 'release-colab_20241219-060121_RC00', 'PYDEVD_USE_FRAME_EVAL': 'NO', 'KMP_TARGET_PORT': '9000', 'CLICOLOR': '1', 'KMP_EXTRA_ARGS': '--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https://colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-20wgjs50stvlf --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true --enable_kernel_event_logging=true', 'NV_LIBNPP_DEV_PACKAGE': 'libnpp-dev-12-2=12.2.1.4-1', 'COLAB_LANGUAGE_SERVER_PROXY_LSP_DIRS': '/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages', 'NV_LIBCUBLAS_PACKAGE_NAME': 'libcublas-12-2', 'COLAB_KERNEL_MANAGER_PROXY_PORT': '6000', 'CLOUDSDK_PYTHON': 'python3', 'NV_LIBNPP_DEV_VERSION': '12.2.1.4-1', 'ENABLE_DIRECTORYPREFETCHER': '1', 'NO_GCE_CHECK': 'False', 'JPY_PARENT_PID': '110', 'PYTHONPATH': '/env/python', 'TERM': 'xterm-color', 'NV_LIBCUSPARSE_DEV_VERSION': '12.1.2.141-1', 'GIT_PAGER': 'cat', 'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs', 'NV_CUDNN_VERSION': '8.9.6.50', 'SHLVL': '0', 'PAGER': 'cat', 'NV_CUDA_LIB_VERSION': '12.2.2-1', 'COLAB_LANGUAGE_SERVER_PROXY': '/usr/colab/bin/language_service', 'NVARCH': 'x86_64', 'NV_CUDNN_PACKAGE_DEV': 'libcudnn8-dev=8.9.6.50-1+cuda12.2', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-12-2', 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline', 'NV_LIBNCCL_PACKAGE': 'libnccl2=2.19.3-1+cuda12.2', 'LD_LIBRARY_PATH': '/usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia', 'COLAB_GPU': '1', 'NV_CUDA_NSIGHT_COMPUTE_VERSION': '12.2.2-1', 'GCS_READ_CACHE_BLOCK_SIZE_MB': '16', 'NV_NVPROF_VERSION': '12.2.142-1', 'LC_ALL': 'en_US.UTF-8', 'COLAB_FILE_HANDLER_ADDR': 'localhost:3453', 'PATH': '/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin', 'NV_LIBNCCL_PACKAGE_NAME': 'libnccl2', 'COLAB_DEBUG_ADAPTER_MUX_PATH': '/usr/local/bin/dap_multiplexer', 'NV_LIBNCCL_PACKAGE_VERSION': '2.19.3-1', 'PYTHONWARNINGS': 'ignore:::pip._internal.cli.base_command', 'DEBIAN_FRONTEND': 'noninteractive', 'COLAB_BACKEND_VERSION': 'next', 'OLDPWD': '/', 'TF2_BEHAVIOR': '1', 'TPU_ML_PLATFORM': 'Tensorflow', 'TPU_ML_PLATFORM_VERSION': '2.17.1', 'TF_CPP_MIN_LOG_LEVEL': '1', 'QT_QPA_PLATFORM_PLUGIN_PATH': '/usr/local/lib/python3.10/dist-packages/cv2/qt/plugins', 'QT_QPA_FONTDIR': '/usr/local/lib/python3.10/dist-packages/cv2/qt/fonts', 'KMP_DUPLICATE_LIB_OK': 'True', 'KMP_INIT_AT_FORK': 'FALSE', 'TOKENIZERS_PARALLELISM': 'false', 'WANDB_MODE': 'disabled'})\n",
            "Not using distributed mode\n",
            "Namespace(batch_size=2, epochs=2, world_size=2, dist_url='env://', local_rank=0, finetune='', device='cuda', seed=0, resume='', start_epoch=0, eval=False, num_workers=4, pin_mem=True, config='/content/drive/MyDrive/ColabNotebooks/MSKA-main/configs/csl-daily_s2g.yaml', log_all=False, entity=None, project='VLP', run=<wandb.sdk.wandb_run.Run object at 0x7f2939d7b670>, distributed=False)\n",
            "Creating dataset:\n",
            "0\n",
            "#total train set: 18401.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "#total val set: 1077.\n",
            "#total test set: 1176.\n",
            "Creating model:\n",
            "SignLanguageModel(\n",
            "  (recognition_network): Recognition(\n",
            "    (visual_backbone_keypoint): DSTA(\n",
            "      (left_input_map): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): LeakyReLU(negative_slope=0.1)\n",
            "      )\n",
            "      (right_input_map): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): LeakyReLU(negative_slope=0.1)\n",
            "      )\n",
            "      (body_input_map): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): LeakyReLU(negative_slope=0.1)\n",
            "      )\n",
            "      (face_input_map): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): LeakyReLU(negative_slope=0.1)\n",
            "      )\n",
            "      (face_graph_layers): ModuleList(\n",
            "        (0): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(7, 1), stride=(2, 1), padding=(3, 0))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (1): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (2): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (3): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (4): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (5-7): 3 x STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (left_graph_layers): ModuleList(\n",
            "        (0): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(7, 1), stride=(2, 1), padding=(3, 0))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (1): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (2): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (3): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (4): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (5-7): 3 x STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (right_graph_layers): ModuleList(\n",
            "        (0): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(7, 1), stride=(2, 1), padding=(3, 0))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (1): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (2): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (3): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (4): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (5-7): 3 x STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (body_graph_layers): ModuleList(\n",
            "        (0): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(7, 1), stride=(2, 1), padding=(3, 0))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (1): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (2): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (3): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (4): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (5-7): 3 x STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (drop_out): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (fuse_visual_head): VisualHead(\n",
            "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
            "      (bn1): MaskedNorm(\n",
            "        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu1): ReLU()\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (pe): PositionalEncoding()\n",
            "      (feedforward): PositionwiseFeedForward(\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (pwff_layer): Sequential(\n",
            "          (0): Conv1d(512, 2048, kernel_size=(3,), stride=(1,), padding=same)\n",
            "          (1): ReLU()\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Conv1d(2048, 512, kernel_size=(3,), stride=(1,), padding=same)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      (plus_conv): Identity()\n",
            "      (gloss_output_layer): Linear(in_features=512, out_features=2004, bias=True)\n",
            "    )\n",
            "    (body_visual_head): VisualHead(\n",
            "      (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
            "      (bn1): MaskedNorm(\n",
            "        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu1): ReLU()\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (pe): PositionalEncoding()\n",
            "      (feedforward): PositionwiseFeedForward(\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (pwff_layer): Sequential(\n",
            "          (0): Conv1d(512, 2048, kernel_size=(3,), stride=(1,), padding=same)\n",
            "          (1): ReLU()\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Conv1d(2048, 512, kernel_size=(3,), stride=(1,), padding=same)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      (plus_conv): Identity()\n",
            "      (gloss_output_layer): Linear(in_features=512, out_features=2004, bias=True)\n",
            "    )\n",
            "    (left_visual_head): VisualHead(\n",
            "      (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (bn1): MaskedNorm(\n",
            "        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu1): ReLU()\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (pe): PositionalEncoding()\n",
            "      (feedforward): PositionwiseFeedForward(\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (pwff_layer): Sequential(\n",
            "          (0): Conv1d(512, 2048, kernel_size=(3,), stride=(1,), padding=same)\n",
            "          (1): ReLU()\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Conv1d(2048, 512, kernel_size=(3,), stride=(1,), padding=same)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      (plus_conv): Identity()\n",
            "      (gloss_output_layer): Linear(in_features=512, out_features=2004, bias=True)\n",
            "    )\n",
            "    (right_visual_head): VisualHead(\n",
            "      (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (bn1): MaskedNorm(\n",
            "        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu1): ReLU()\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (pe): PositionalEncoding()\n",
            "      (feedforward): PositionwiseFeedForward(\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (pwff_layer): Sequential(\n",
            "          (0): Conv1d(512, 2048, kernel_size=(3,), stride=(1,), padding=same)\n",
            "          (1): ReLU()\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Conv1d(2048, 512, kernel_size=(3,), stride=(1,), padding=same)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      (plus_conv): Identity()\n",
            "      (gloss_output_layer): Linear(in_features=512, out_features=2004, bias=True)\n",
            "    )\n",
            "    (recognition_loss_func): CTCLoss()\n",
            "  )\n",
            ")\n",
            "number of params: 46.026592M\n",
            "Start training for 2 epochs\n",
            "Epoch: [0/2]  [   0/9200]  eta: 10:30:24  lr: 0.001000  loss: 623.0298 (623.0298)  time: 4.1113  data: 0.5782  max mem: 1837\n",
            "Epoch: [0/2]  [  10/9200]  eta: 2:32:01  lr: 0.001000  loss: 247.0733 (319.7754)  time: 0.9926  data: 0.0584  max mem: 3972\n",
            "Epoch: [0/2]  [  20/9200]  eta: 2:01:25  lr: 0.001000  loss: 229.2643 (275.5196)  time: 0.6278  data: 0.0042  max mem: 3972\n",
            "Epoch: [0/2]  [  30/9200]  eta: 1:45:31  lr: 0.001000  loss: 199.4405 (255.0148)  time: 0.5243  data: 0.0011  max mem: 3972\n",
            "Epoch: [0/2]  [  40/9200]  eta: 1:41:07  lr: 0.001000  loss: 216.3627 (243.6994)  time: 0.5244  data: 0.0017  max mem: 3972\n",
            "Epoch: [0/2]  [  50/9200]  eta: 1:37:42  lr: 0.001000  loss: 216.3627 (239.4288)  time: 0.5635  data: 0.0031  max mem: 3972\n",
            "Epoch: [0/2]  [  60/9200]  eta: 1:33:39  lr: 0.001000  loss: 189.4725 (233.8586)  time: 0.5173  data: 0.0016  max mem: 4405\n",
            "Epoch: [0/2]  [  70/9200]  eta: 1:31:50  lr: 0.001000  loss: 202.8995 (229.2247)  time: 0.5091  data: 0.0016  max mem: 4405\n",
            "Epoch: [0/2]  [  80/9200]  eta: 1:31:48  lr: 0.001000  loss: 218.9889 (227.2672)  time: 0.5709  data: 0.0047  max mem: 4405\n",
            "Epoch: [0/2]  [  90/9200]  eta: 1:29:13  lr: 0.001000  loss: 213.6202 (227.2271)  time: 0.5308  data: 0.0036  max mem: 4405\n",
            "Epoch: [0/2]  [ 100/9200]  eta: 1:27:08  lr: 0.001000  loss: 201.4705 (223.1554)  time: 0.4553  data: 0.0005  max mem: 4405\n",
            "Epoch: [0/2]  [ 110/9200]  eta: 1:27:27  lr: 0.001000  loss: 210.2843 (224.1747)  time: 0.5305  data: 0.0027  max mem: 4747\n",
            "Epoch: [0/2]  [ 120/9200]  eta: 1:26:48  lr: 0.001000  loss: 212.8986 (221.6541)  time: 0.5692  data: 0.0048  max mem: 4747\n",
            "Epoch: [0/2]  [ 130/9200]  eta: 1:26:29  lr: 0.001000  loss: 214.4469 (224.5389)  time: 0.5433  data: 0.0022  max mem: 4915\n",
            "Epoch: [0/2]  [ 140/9200]  eta: 1:26:00  lr: 0.001000  loss: 214.4469 (222.1371)  time: 0.5454  data: 0.0023  max mem: 4915\n",
            "Epoch: [0/2]  [ 150/9200]  eta: 1:25:27  lr: 0.001000  loss: 213.8466 (222.7069)  time: 0.5302  data: 0.0039  max mem: 4915\n",
            "Epoch: [0/2]  [ 160/9200]  eta: 1:24:47  lr: 0.001000  loss: 222.2330 (221.7999)  time: 0.5147  data: 0.0018  max mem: 4915\n",
            "Epoch: [0/2]  [ 170/9200]  eta: 1:24:19  lr: 0.001000  loss: 193.1764 (219.1281)  time: 0.5127  data: 0.0016  max mem: 4915\n",
            "Epoch: [0/2]  [ 180/9200]  eta: 1:24:58  lr: 0.001000  loss: 193.1764 (220.6589)  time: 0.5850  data: 0.0040  max mem: 5670\n",
            "Epoch: [0/2]  [ 190/9200]  eta: 1:24:14  lr: 0.001000  loss: 204.1279 (219.9770)  time: 0.5675  data: 0.0027  max mem: 5670\n",
            "Epoch: [0/2]  [ 200/9200]  eta: 1:23:43  lr: 0.001000  loss: 197.1659 (219.7259)  time: 0.4939  data: 0.0004  max mem: 5670\n",
            "Epoch: [0/2]  [ 210/9200]  eta: 1:23:51  lr: 0.001000  loss: 197.1659 (218.8539)  time: 0.5467  data: 0.0032  max mem: 5670\n",
            "Epoch: [0/2]  [ 220/9200]  eta: 1:23:21  lr: 0.001000  loss: 207.3490 (219.3203)  time: 0.5455  data: 0.0034  max mem: 5670\n",
            "Epoch: [0/2]  [ 230/9200]  eta: 1:22:37  lr: 0.001000  loss: 202.3724 (218.3349)  time: 0.4785  data: 0.0007  max mem: 5670\n",
            "Epoch: [0/2]  [ 240/9200]  eta: 1:22:49  lr: 0.001000  loss: 176.4533 (217.4373)  time: 0.5280  data: 0.0023  max mem: 5670\n",
            "Epoch: [0/2]  [ 250/9200]  eta: 1:22:32  lr: 0.001000  loss: 189.1292 (216.6157)  time: 0.5614  data: 0.0034  max mem: 5670\n",
            "Epoch: [0/2]  [ 260/9200]  eta: 1:21:53  lr: 0.001000  loss: 191.5869 (216.5924)  time: 0.4889  data: 0.0013  max mem: 5670\n",
            "Epoch: [0/2]  [ 270/9200]  eta: 1:21:39  lr: 0.001000  loss: 199.9215 (216.7175)  time: 0.4905  data: 0.0019  max mem: 5670\n",
            "Epoch: [0/2]  [ 280/9200]  eta: 1:21:30  lr: 0.001000  loss: 205.5079 (216.3821)  time: 0.5310  data: 0.0059  max mem: 5670\n",
            "Epoch: [0/2]  [ 290/9200]  eta: 1:21:01  lr: 0.001000  loss: 184.4981 (215.3824)  time: 0.5046  data: 0.0041  max mem: 5670\n",
            "Epoch: [0/2]  [ 300/9200]  eta: 1:20:56  lr: 0.001000  loss: 184.4981 (215.5676)  time: 0.5101  data: 0.0011  max mem: 5670\n",
            "Epoch: [0/2]  [ 310/9200]  eta: 1:20:55  lr: 0.001000  loss: 196.0411 (214.6537)  time: 0.5543  data: 0.0034  max mem: 5670\n",
            "Epoch: [0/2]  [ 320/9200]  eta: 1:20:32  lr: 0.001000  loss: 186.5972 (213.8353)  time: 0.5224  data: 0.0026  max mem: 5670\n",
            "Epoch: [0/2]  [ 330/9200]  eta: 1:20:28  lr: 0.001000  loss: 191.2794 (213.7833)  time: 0.5150  data: 0.0007  max mem: 5670\n",
            "Epoch: [0/2]  [ 340/9200]  eta: 1:20:37  lr: 0.001000  loss: 198.5080 (213.2594)  time: 0.5749  data: 0.0042  max mem: 5670\n",
            "Epoch: [0/2]  [ 350/9200]  eta: 1:20:22  lr: 0.001000  loss: 214.1341 (214.0272)  time: 0.5539  data: 0.0052  max mem: 5670\n",
            "Epoch: [0/2]  [ 360/9200]  eta: 1:20:04  lr: 0.001000  loss: 232.9189 (214.2037)  time: 0.5000  data: 0.0017  max mem: 5670\n",
            "Epoch: [0/2]  [ 370/9200]  eta: 1:19:52  lr: 0.001000  loss: 216.9395 (213.8906)  time: 0.5052  data: 0.0023  max mem: 5670\n",
            "Epoch: [0/2]  [ 380/9200]  eta: 1:19:56  lr: 0.001000  loss: 201.8653 (213.8505)  time: 0.5487  data: 0.0053  max mem: 5670\n",
            "Epoch: [0/2]  [ 390/9200]  eta: 1:19:25  lr: 0.001000  loss: 185.8974 (212.8600)  time: 0.5069  data: 0.0032  max mem: 5670\n",
            "Epoch: [0/2]  [ 400/9200]  eta: 1:19:15  lr: 0.001000  loss: 172.6019 (212.5301)  time: 0.4761  data: 0.0006  max mem: 5670\n",
            "Epoch: [0/2]  [ 410/9200]  eta: 1:19:18  lr: 0.001000  loss: 203.6866 (212.6105)  time: 0.5499  data: 0.0026  max mem: 5670\n",
            "Epoch: [0/2]  [ 420/9200]  eta: 1:18:54  lr: 0.001000  loss: 192.7270 (211.6349)  time: 0.5166  data: 0.0022  max mem: 5670\n",
            "Epoch: [0/2]  [ 430/9200]  eta: 1:18:45  lr: 0.001000  loss: 191.5588 (211.7748)  time: 0.4866  data: 0.0004  max mem: 5670\n",
            "Epoch: [0/2]  [ 440/9200]  eta: 1:18:43  lr: 0.001000  loss: 195.3639 (211.5502)  time: 0.5376  data: 0.0041  max mem: 5670\n",
            "Epoch: [0/2]  [ 450/9200]  eta: 1:18:43  lr: 0.001000  loss: 203.9282 (211.5535)  time: 0.5610  data: 0.0044  max mem: 5670\n",
            "Epoch: [0/2]  [ 460/9200]  eta: 1:18:45  lr: 0.001000  loss: 212.5337 (211.6093)  time: 0.5735  data: 0.0008  max mem: 5670\n",
            "Epoch: [0/2]  [ 470/9200]  eta: 1:18:48  lr: 0.001000  loss: 188.5055 (211.5680)  time: 0.5825  data: 0.0039  max mem: 5670\n",
            "Epoch: [0/2]  [ 480/9200]  eta: 1:18:27  lr: 0.001000  loss: 193.4978 (211.0974)  time: 0.5223  data: 0.0045  max mem: 5670\n",
            "Epoch: [0/2]  [ 490/9200]  eta: 1:18:14  lr: 0.001000  loss: 193.4978 (210.8479)  time: 0.4784  data: 0.0013  max mem: 5670\n",
            "Epoch: [0/2]  [ 500/9200]  eta: 1:18:23  lr: 0.001000  loss: 197.7575 (210.9560)  time: 0.5593  data: 0.0037  max mem: 5670\n",
            "Epoch: [0/2]  [ 510/9200]  eta: 1:18:02  lr: 0.001000  loss: 206.8461 (210.2607)  time: 0.5344  data: 0.0044  max mem: 5670\n",
            "Epoch: [0/2]  [ 520/9200]  eta: 1:17:50  lr: 0.001000  loss: 161.0041 (209.8621)  time: 0.4730  data: 0.0014  max mem: 5670\n",
            "Epoch: [0/2]  [ 530/9200]  eta: 1:17:43  lr: 0.001000  loss: 163.9818 (209.2662)  time: 0.5132  data: 0.0027  max mem: 5670\n",
            "Epoch: [0/2]  [ 540/9200]  eta: 1:17:40  lr: 0.001000  loss: 167.2060 (209.1674)  time: 0.5397  data: 0.0057  max mem: 5670\n",
            "Epoch: [0/2]  [ 550/9200]  eta: 1:17:23  lr: 0.001000  loss: 184.6776 (208.6496)  time: 0.5073  data: 0.0033  max mem: 5670\n",
            "Epoch: [0/2]  [ 560/9200]  eta: 1:17:01  lr: 0.001000  loss: 180.2360 (208.2402)  time: 0.4454  data: 0.0002  max mem: 5670\n",
            "Epoch: [0/2]  [ 570/9200]  eta: 1:17:01  lr: 0.001000  loss: 172.1065 (207.4842)  time: 0.5004  data: 0.0035  max mem: 5670\n",
            "Epoch: [0/2]  [ 580/9200]  eta: 1:16:53  lr: 0.001000  loss: 176.6217 (207.7210)  time: 0.5441  data: 0.0041  max mem: 5670\n",
            "Epoch: [0/2]  [ 590/9200]  eta: 1:16:41  lr: 0.001000  loss: 214.9341 (207.9740)  time: 0.5031  data: 0.0007  max mem: 5670\n",
            "Epoch: [0/2]  [ 600/9200]  eta: 1:16:37  lr: 0.001000  loss: 202.1374 (207.5509)  time: 0.5182  data: 0.0027  max mem: 5670\n",
            "Epoch: [0/2]  [ 610/9200]  eta: 1:16:33  lr: 0.001000  loss: 202.5856 (207.8519)  time: 0.5439  data: 0.0042  max mem: 5670\n",
            "Epoch: [0/2]  [ 620/9200]  eta: 1:16:21  lr: 0.001000  loss: 193.1228 (207.6617)  time: 0.5147  data: 0.0017  max mem: 5670\n",
            "Epoch: [0/2]  [ 630/9200]  eta: 1:16:05  lr: 0.001000  loss: 183.9382 (207.4180)  time: 0.4741  data: 0.0009  max mem: 5670\n",
            "Epoch: [0/2]  [ 640/9200]  eta: 1:16:08  lr: 0.001000  loss: 208.0705 (207.4774)  time: 0.5259  data: 0.0042  max mem: 5670\n",
            "Epoch: [0/2]  [ 650/9200]  eta: 1:16:02  lr: 0.001000  loss: 194.6879 (207.4025)  time: 0.5608  data: 0.0034  max mem: 5670\n",
            "Epoch: [0/2]  [ 660/9200]  eta: 1:15:53  lr: 0.001000  loss: 183.2651 (207.6569)  time: 0.5175  data: 0.0005  max mem: 5670\n",
            "Epoch: [0/2]  [ 670/9200]  eta: 1:15:50  lr: 0.001000  loss: 203.6151 (207.5511)  time: 0.5292  data: 0.0038  max mem: 5670\n",
            "Epoch: [0/2]  [ 680/9200]  eta: 1:15:38  lr: 0.001000  loss: 190.5609 (207.2238)  time: 0.5167  data: 0.0036  max mem: 5670\n",
            "Epoch: [0/2]  [ 690/9200]  eta: 1:15:28  lr: 0.001000  loss: 175.1057 (206.9495)  time: 0.4856  data: 0.0002  max mem: 5670\n",
            "Epoch: [0/2]  [ 700/9200]  eta: 1:15:27  lr: 0.001000  loss: 184.4562 (206.5206)  time: 0.5287  data: 0.0034  max mem: 5670\n",
            "Epoch: [0/2]  [ 710/9200]  eta: 1:15:22  lr: 0.001000  loss: 166.4022 (206.1268)  time: 0.5522  data: 0.0050  max mem: 5670\n",
            "Epoch: [0/2]  [ 720/9200]  eta: 1:15:09  lr: 0.001000  loss: 168.8763 (205.9856)  time: 0.5014  data: 0.0018  max mem: 5670\n",
            "Epoch: [0/2]  [ 730/9200]  eta: 1:15:04  lr: 0.001000  loss: 189.3664 (205.8175)  time: 0.5026  data: 0.0016  max mem: 5670\n",
            "Epoch: [0/2]  [ 740/9200]  eta: 1:15:01  lr: 0.001000  loss: 185.1810 (205.3813)  time: 0.5445  data: 0.0055  max mem: 5670\n",
            "Epoch: [0/2]  [ 750/9200]  eta: 1:14:41  lr: 0.001000  loss: 156.9851 (204.8278)  time: 0.4768  data: 0.0047  max mem: 5670\n",
            "Epoch: [0/2]  [ 760/9200]  eta: 1:14:28  lr: 0.001000  loss: 159.5927 (204.6144)  time: 0.4335  data: 0.0009  max mem: 5670\n",
            "Epoch: [0/2]  [ 770/9200]  eta: 1:14:24  lr: 0.001000  loss: 198.0901 (204.6184)  time: 0.5002  data: 0.0022  max mem: 5670\n",
            "Epoch: [0/2]  [ 780/9200]  eta: 1:14:19  lr: 0.001000  loss: 197.6308 (204.5252)  time: 0.5345  data: 0.0039  max mem: 5670\n",
            "Epoch: [0/2]  [ 790/9200]  eta: 1:14:18  lr: 0.001000  loss: 197.6308 (204.6189)  time: 0.5502  data: 0.0020  max mem: 5670\n",
            "Epoch: [0/2]  [ 800/9200]  eta: 1:14:15  lr: 0.001000  loss: 195.0880 (204.3715)  time: 0.5599  data: 0.0018  max mem: 5670\n",
            "Epoch: [0/2]  [ 810/9200]  eta: 1:14:11  lr: 0.001000  loss: 172.7599 (204.3771)  time: 0.5476  data: 0.0044  max mem: 5670\n",
            "Epoch: [0/2]  [ 820/9200]  eta: 1:14:08  lr: 0.001000  loss: 210.1458 (204.4260)  time: 0.5476  data: 0.0027  max mem: 5670\n",
            "Epoch: [0/2]  [ 830/9200]  eta: 1:14:07  lr: 0.001000  loss: 206.1846 (204.6067)  time: 0.5623  data: 0.0010  max mem: 5670\n",
            "Epoch: [0/2]  [ 840/9200]  eta: 1:14:06  lr: 0.001000  loss: 201.5915 (204.5381)  time: 0.5760  data: 0.0040  max mem: 5670\n",
            "Epoch: [0/2]  [ 850/9200]  eta: 1:14:00  lr: 0.001000  loss: 210.0190 (204.7097)  time: 0.5494  data: 0.0033  max mem: 5670\n",
            "Epoch: [0/2]  [ 860/9200]  eta: 1:13:53  lr: 0.001000  loss: 184.6269 (204.4168)  time: 0.5187  data: 0.0008  max mem: 5670\n",
            "Epoch: [0/2]  [ 870/9200]  eta: 1:13:49  lr: 0.001000  loss: 178.1244 (204.1811)  time: 0.5326  data: 0.0033  max mem: 5670\n",
            "Epoch: [0/2]  [ 880/9200]  eta: 1:13:47  lr: 0.001000  loss: 199.0570 (204.5842)  time: 0.5559  data: 0.0032  max mem: 5670\n",
            "Epoch: [0/2]  [ 890/9200]  eta: 1:13:41  lr: 0.001000  loss: 203.2461 (204.4252)  time: 0.5459  data: 0.0008  max mem: 5670\n",
            "Epoch: [0/2]  [ 900/9200]  eta: 1:13:35  lr: 0.001000  loss: 182.9594 (204.0875)  time: 0.5243  data: 0.0048  max mem: 5670\n",
            "Epoch: [0/2]  [ 910/9200]  eta: 1:13:21  lr: 0.001000  loss: 166.0608 (203.7797)  time: 0.4782  data: 0.0054  max mem: 5670\n",
            "Epoch: [0/2]  [ 920/9200]  eta: 1:13:14  lr: 0.001000  loss: 183.4226 (203.6479)  time: 0.4762  data: 0.0015  max mem: 5670\n",
            "Epoch: [0/2]  [ 930/9200]  eta: 1:13:13  lr: 0.001000  loss: 187.4946 (203.5766)  time: 0.5474  data: 0.0030  max mem: 5670\n",
            "Epoch: [0/2]  [ 940/9200]  eta: 1:13:05  lr: 0.001000  loss: 183.6145 (203.3818)  time: 0.5384  data: 0.0041  max mem: 5670\n",
            "Epoch: [0/2]  [ 950/9200]  eta: 1:12:55  lr: 0.001000  loss: 183.6145 (203.3208)  time: 0.4902  data: 0.0017  max mem: 5670\n",
            "Epoch: [0/2]  [ 960/9200]  eta: 1:12:49  lr: 0.001000  loss: 190.7451 (203.4758)  time: 0.5015  data: 0.0012  max mem: 5670\n",
            "Epoch: [0/2]  [ 970/9200]  eta: 1:12:44  lr: 0.001000  loss: 189.1551 (203.4976)  time: 0.5272  data: 0.0042  max mem: 5670\n",
            "Epoch: [0/2]  [ 980/9200]  eta: 1:12:35  lr: 0.001000  loss: 191.8973 (203.4657)  time: 0.5092  data: 0.0036  max mem: 5670\n",
            "Epoch: [0/2]  [ 990/9200]  eta: 1:12:33  lr: 0.001000  loss: 196.9990 (203.6680)  time: 0.5299  data: 0.0007  max mem: 5670\n",
            "Epoch: [0/2]  [1000/9200]  eta: 1:12:31  lr: 0.001000  loss: 218.0910 (203.8733)  time: 0.5731  data: 0.0031  max mem: 5670\n",
            "Epoch: [0/2]  [1010/9200]  eta: 1:12:24  lr: 0.001000  loss: 168.1437 (203.6870)  time: 0.5398  data: 0.0034  max mem: 5670\n",
            "Epoch: [0/2]  [1020/9200]  eta: 1:12:16  lr: 0.001000  loss: 174.9983 (203.4572)  time: 0.5030  data: 0.0005  max mem: 5670\n",
            "Epoch: [0/2]  [1030/9200]  eta: 1:12:13  lr: 0.001000  loss: 178.8516 (203.5358)  time: 0.5237  data: 0.0034  max mem: 5670\n",
            "Epoch: [0/2]  [1040/9200]  eta: 1:12:02  lr: 0.001000  loss: 181.6329 (203.3630)  time: 0.5064  data: 0.0045  max mem: 5670\n",
            "Epoch: [0/2]  [1050/9200]  eta: 1:11:55  lr: 0.001000  loss: 181.6329 (203.2753)  time: 0.4842  data: 0.0017  max mem: 5670\n",
            "Epoch: [0/2]  [1060/9200]  eta: 1:11:52  lr: 0.001000  loss: 182.5875 (203.3385)  time: 0.5327  data: 0.0022  max mem: 5670\n",
            "Epoch: [0/2]  [1070/9200]  eta: 1:11:45  lr: 0.001000  loss: 168.5918 (203.0641)  time: 0.5339  data: 0.0049  max mem: 5670\n",
            "Epoch: [0/2]  [1080/9200]  eta: 1:11:34  lr: 0.001000  loss: 174.4640 (202.7464)  time: 0.4820  data: 0.0032  max mem: 5670\n",
            "Epoch: [0/2]  [1090/9200]  eta: 1:11:25  lr: 0.001000  loss: 180.4182 (202.7946)  time: 0.4639  data: 0.0002  max mem: 5670\n",
            "Epoch: [0/2]  [1100/9200]  eta: 1:11:24  lr: 0.001000  loss: 198.7645 (202.7298)  time: 0.5298  data: 0.0032  max mem: 5670\n",
            "Epoch: [0/2]  [1110/9200]  eta: 1:11:14  lr: 0.001000  loss: 188.2142 (202.6310)  time: 0.5300  data: 0.0050  max mem: 5670\n",
            "Epoch: [0/2]  [1120/9200]  eta: 1:11:06  lr: 0.001000  loss: 194.2408 (202.6018)  time: 0.4794  data: 0.0022  max mem: 5670\n",
            "Epoch: [0/2]  [1130/9200]  eta: 1:10:55  lr: 0.001000  loss: 183.1857 (202.5173)  time: 0.4695  data: 0.0013  max mem: 5670\n",
            "Epoch: [0/2]  [1140/9200]  eta: 1:10:56  lr: 0.001000  loss: 182.7355 (202.4513)  time: 0.5314  data: 0.0046  max mem: 5670\n",
            "Epoch: [0/2]  [1150/9200]  eta: 1:10:47  lr: 0.001000  loss: 197.2636 (202.5391)  time: 0.5440  data: 0.0040  max mem: 5670\n",
            "Epoch: [0/2]  [1160/9200]  eta: 1:10:36  lr: 0.001000  loss: 196.1180 (202.3489)  time: 0.4621  data: 0.0006  max mem: 5670\n",
            "Epoch: [0/2]  [1170/9200]  eta: 1:10:33  lr: 0.001000  loss: 185.6393 (202.2802)  time: 0.5020  data: 0.0030  max mem: 5670\n",
            "Epoch: [0/2]  [1180/9200]  eta: 1:10:28  lr: 0.001000  loss: 192.9726 (202.3175)  time: 0.5473  data: 0.0055  max mem: 5670\n",
            "Epoch: [0/2]  [1190/9200]  eta: 1:10:17  lr: 0.001000  loss: 173.9339 (201.9787)  time: 0.4874  data: 0.0027  max mem: 5670\n",
            "Epoch: [0/2]  [1200/9200]  eta: 1:10:12  lr: 0.001000  loss: 164.4820 (201.8566)  time: 0.4816  data: 0.0011  max mem: 5670\n",
            "Epoch: [0/2]  [1210/9200]  eta: 1:10:10  lr: 0.001000  loss: 191.8861 (202.0116)  time: 0.5549  data: 0.0044  max mem: 5670\n",
            "Epoch: [0/2]  [1220/9200]  eta: 1:10:07  lr: 0.001000  loss: 201.5334 (202.0091)  time: 0.5668  data: 0.0034  max mem: 5670\n",
            "Epoch: [0/2]  [1230/9200]  eta: 1:10:00  lr: 0.001000  loss: 193.2148 (202.0114)  time: 0.5266  data: 0.0008  max mem: 5670\n",
            "Epoch: [0/2]  [1240/9200]  eta: 1:10:00  lr: 0.001000  loss: 204.0108 (202.1316)  time: 0.5573  data: 0.0033  max mem: 5670\n",
            "Epoch: [0/2]  [1250/9200]  eta: 1:09:50  lr: 0.001000  loss: 183.8630 (201.9606)  time: 0.5316  data: 0.0026  max mem: 5670\n",
            "Epoch: [0/2]  [1260/9200]  eta: 1:09:42  lr: 0.001000  loss: 201.4323 (202.1469)  time: 0.4730  data: 0.0002  max mem: 5670\n",
            "Epoch: [0/2]  [1270/9200]  eta: 1:09:40  lr: 0.001000  loss: 222.8063 (202.0901)  time: 0.5337  data: 0.0029  max mem: 5670\n",
            "Epoch: [0/2]  [1280/9200]  eta: 1:09:32  lr: 0.001000  loss: 164.0996 (201.8267)  time: 0.5248  data: 0.0038  max mem: 5670\n",
            "Epoch: [0/2]  [1290/9200]  eta: 1:09:24  lr: 0.001000  loss: 173.5914 (201.9223)  time: 0.4792  data: 0.0013  max mem: 5670\n",
            "Epoch: [0/2]  [1300/9200]  eta: 1:09:18  lr: 0.001000  loss: 185.9471 (201.8449)  time: 0.5012  data: 0.0020  max mem: 5670\n",
            "Epoch: [0/2]  [1310/9200]  eta: 1:09:11  lr: 0.001000  loss: 173.8118 (201.7551)  time: 0.5115  data: 0.0052  max mem: 5670\n",
            "Epoch: [0/2]  [1320/9200]  eta: 1:09:04  lr: 0.001000  loss: 187.8746 (201.7729)  time: 0.4975  data: 0.0036  max mem: 5670\n",
            "Epoch: [0/2]  [1330/9200]  eta: 1:08:58  lr: 0.001000  loss: 196.0895 (201.8835)  time: 0.5053  data: 0.0005  max mem: 5670\n",
            "Epoch: [0/2]  [1340/9200]  eta: 1:08:58  lr: 0.001000  loss: 212.7325 (201.9461)  time: 0.5683  data: 0.0043  max mem: 5670\n",
            "Epoch: [0/2]  [1350/9200]  eta: 1:08:52  lr: 0.001000  loss: 184.3028 (201.7913)  time: 0.5584  data: 0.0043  max mem: 5670\n",
            "Epoch: [0/2]  [1360/9200]  eta: 1:08:44  lr: 0.001000  loss: 188.5012 (201.8851)  time: 0.4954  data: 0.0005  max mem: 5670\n",
            "Epoch: [0/2]  [1370/9200]  eta: 1:08:43  lr: 0.001000  loss: 210.6722 (201.8611)  time: 0.5421  data: 0.0022  max mem: 5670\n",
            "Epoch: [0/2]  [1380/9200]  eta: 1:08:39  lr: 0.001000  loss: 197.5418 (201.9094)  time: 0.5751  data: 0.0028  max mem: 5670\n",
            "Epoch: [0/2]  [1390/9200]  eta: 1:08:29  lr: 0.001000  loss: 191.6957 (201.9287)  time: 0.4967  data: 0.0010  max mem: 5670\n",
            "Epoch: [0/2]  [1400/9200]  eta: 1:08:26  lr: 0.001000  loss: 179.4556 (201.8209)  time: 0.5061  data: 0.0028  max mem: 5670\n",
            "Epoch: [0/2]  [1410/9200]  eta: 1:08:27  lr: 0.001000  loss: 175.7505 (201.9699)  time: 0.6000  data: 0.0046  max mem: 5670\n",
            "Epoch: [0/2]  [1420/9200]  eta: 1:08:18  lr: 0.001000  loss: 209.7599 (202.0045)  time: 0.5482  data: 0.0022  max mem: 5670\n",
            "Epoch: [0/2]  [1430/9200]  eta: 1:08:12  lr: 0.001000  loss: 209.7599 (201.9949)  time: 0.4881  data: 0.0018  max mem: 5670\n",
            "Epoch: [0/2]  [1440/9200]  eta: 1:08:11  lr: 0.001000  loss: 201.3354 (202.0148)  time: 0.5570  data: 0.0047  max mem: 5670\n",
            "Epoch: [0/2]  [1450/9200]  eta: 1:08:00  lr: 0.001000  loss: 183.8708 (201.7827)  time: 0.5129  data: 0.0031  max mem: 5670\n",
            "Epoch: [0/2]  [1460/9200]  eta: 1:07:54  lr: 0.001000  loss: 174.7802 (201.7657)  time: 0.4702  data: 0.0008  max mem: 5670\n",
            "Epoch: [0/2]  [1470/9200]  eta: 1:07:51  lr: 0.001000  loss: 192.8984 (201.5984)  time: 0.5417  data: 0.0029  max mem: 5670\n",
            "Epoch: [0/2]  [1480/9200]  eta: 1:07:43  lr: 0.001000  loss: 190.4418 (201.6717)  time: 0.5149  data: 0.0028  max mem: 5670\n",
            "Epoch: [0/2]  [1490/9200]  eta: 1:07:35  lr: 0.001000  loss: 193.1149 (201.6437)  time: 0.4741  data: 0.0006  max mem: 5670\n",
            "Epoch: [0/2]  [1500/9200]  eta: 1:07:33  lr: 0.001000  loss: 200.0478 (201.8345)  time: 0.5368  data: 0.0030  max mem: 5670\n",
            "Epoch: [0/2]  [1510/9200]  eta: 1:07:28  lr: 0.001000  loss: 192.4777 (201.7071)  time: 0.5663  data: 0.0040  max mem: 5670\n",
            "Epoch: [0/2]  [1520/9200]  eta: 1:07:21  lr: 0.001000  loss: 167.6761 (201.5523)  time: 0.5098  data: 0.0012  max mem: 5670\n",
            "Epoch: [0/2]  [1530/9200]  eta: 1:07:17  lr: 0.001000  loss: 181.7696 (201.5226)  time: 0.5165  data: 0.0021  max mem: 5670\n",
            "Epoch: [0/2]  [1540/9200]  eta: 1:07:11  lr: 0.001000  loss: 199.3778 (201.4369)  time: 0.5346  data: 0.0048  max mem: 5670\n",
            "Epoch: [0/2]  [1550/9200]  eta: 1:07:04  lr: 0.001000  loss: 199.3778 (201.4282)  time: 0.4989  data: 0.0030  max mem: 5670\n",
            "Epoch: [0/2]  [1560/9200]  eta: 1:06:56  lr: 0.001000  loss: 185.2715 (201.3228)  time: 0.4814  data: 0.0010  max mem: 5670\n",
            "Epoch: [0/2]  [1570/9200]  eta: 1:06:53  lr: 0.001000  loss: 177.4343 (201.2107)  time: 0.5256  data: 0.0043  max mem: 5670\n",
            "Epoch: [0/2]  [1580/9200]  eta: 1:06:46  lr: 0.001000  loss: 202.9465 (201.3046)  time: 0.5317  data: 0.0039  max mem: 5670\n",
            "Epoch: [0/2]  [1590/9200]  eta: 1:06:43  lr: 0.001000  loss: 214.3352 (201.4261)  time: 0.5350  data: 0.0005  max mem: 5670\n",
            "Epoch: [0/2]  [1600/9200]  eta: 1:06:41  lr: 0.001000  loss: 214.3352 (201.4643)  time: 0.5770  data: 0.0029  max mem: 5670\n",
            "Epoch: [0/2]  [1610/9200]  eta: 1:06:36  lr: 0.001000  loss: 188.8748 (201.5124)  time: 0.5625  data: 0.0029  max mem: 5670\n",
            "Epoch: [0/2]  [1620/9200]  eta: 1:06:30  lr: 0.001000  loss: 182.9534 (201.4845)  time: 0.5263  data: 0.0006  max mem: 5670\n",
            "Epoch: [0/2]  [1630/9200]  eta: 1:06:27  lr: 0.001000  loss: 192.9951 (201.5342)  time: 0.5380  data: 0.0040  max mem: 5670\n",
            "Epoch: [0/2]  [1640/9200]  eta: 1:06:21  lr: 0.001000  loss: 192.0621 (201.4201)  time: 0.5371  data: 0.0048  max mem: 5670\n",
            "Epoch: [0/2]  [1650/9200]  eta: 1:06:14  lr: 0.001000  loss: 175.2684 (201.3048)  time: 0.5013  data: 0.0015  max mem: 5670\n",
            "Epoch: [0/2]  [1660/9200]  eta: 1:06:12  lr: 0.001000  loss: 190.7555 (201.4009)  time: 0.5439  data: 0.0025  max mem: 5670\n",
            "Epoch: [0/2]  [1670/9200]  eta: 1:06:05  lr: 0.001000  loss: 193.8909 (201.3869)  time: 0.5482  data: 0.0035  max mem: 5670\n",
            "Epoch: [0/2]  [1680/9200]  eta: 1:06:00  lr: 0.001000  loss: 192.7686 (201.4819)  time: 0.5100  data: 0.0012  max mem: 5670\n",
            "Epoch: [0/2]  [1690/9200]  eta: 1:05:55  lr: 0.001000  loss: 192.7686 (201.3422)  time: 0.5260  data: 0.0027  max mem: 5670\n",
            "Epoch: [0/2]  [1700/9200]  eta: 1:05:50  lr: 0.001000  loss: 179.6619 (201.3326)  time: 0.5387  data: 0.0050  max mem: 5670\n",
            "Epoch: [0/2]  [1710/9200]  eta: 1:05:42  lr: 0.001000  loss: 202.1219 (201.3327)  time: 0.5041  data: 0.0029  max mem: 5670\n",
            "Epoch: [0/2]  [1720/9200]  eta: 1:05:37  lr: 0.001000  loss: 208.1216 (201.3962)  time: 0.4933  data: 0.0010  max mem: 5670\n",
            "Epoch: [0/2]  [1730/9200]  eta: 1:05:33  lr: 0.001000  loss: 195.2796 (201.3530)  time: 0.5405  data: 0.0045  max mem: 5670\n",
            "Epoch: [0/2]  [1740/9200]  eta: 1:05:25  lr: 0.001000  loss: 190.2517 (201.3546)  time: 0.5160  data: 0.0043  max mem: 5670\n",
            "Epoch: [0/2]  [1750/9200]  eta: 1:05:19  lr: 0.001000  loss: 208.6549 (201.3933)  time: 0.4805  data: 0.0005  max mem: 5670\n",
            "Epoch: [0/2]  [1760/9200]  eta: 1:05:14  lr: 0.001000  loss: 208.6549 (201.4450)  time: 0.5153  data: 0.0035  max mem: 5670\n",
            "Epoch: [0/2]  [1770/9200]  eta: 1:05:07  lr: 0.001000  loss: 172.6545 (201.2976)  time: 0.5189  data: 0.0056  max mem: 5670\n",
            "Epoch: [0/2]  [1780/9200]  eta: 1:04:59  lr: 0.001000  loss: 172.6545 (201.1972)  time: 0.4706  data: 0.0023  max mem: 5670\n",
            "Epoch: [0/2]  [1790/9200]  eta: 1:04:54  lr: 0.001000  loss: 196.7966 (201.2354)  time: 0.4940  data: 0.0009  max mem: 5670\n",
            "Epoch: [0/2]  [1800/9200]  eta: 1:04:52  lr: 0.001000  loss: 178.2327 (201.2028)  time: 0.5740  data: 0.0040  max mem: 5670\n",
            "Epoch: [0/2]  [1810/9200]  eta: 1:04:43  lr: 0.001000  loss: 167.8428 (201.0561)  time: 0.5162  data: 0.0036  max mem: 5670\n",
            "Epoch: [0/2]  [1820/9200]  eta: 1:04:36  lr: 0.001000  loss: 165.8366 (201.0017)  time: 0.4500  data: 0.0005  max mem: 5670\n",
            "Epoch: [0/2]  [1830/9200]  eta: 1:04:32  lr: 0.001000  loss: 174.0515 (200.8914)  time: 0.5172  data: 0.0019  max mem: 5670\n",
            "Epoch: [0/2]  [1840/9200]  eta: 1:04:24  lr: 0.001000  loss: 179.2677 (200.8832)  time: 0.5147  data: 0.0034  max mem: 5670\n",
            "Epoch: [0/2]  [1850/9200]  eta: 1:04:18  lr: 0.001000  loss: 195.6706 (200.8997)  time: 0.4832  data: 0.0018  max mem: 5670\n",
            "Epoch: [0/2]  [1860/9200]  eta: 1:04:14  lr: 0.001000  loss: 217.9905 (201.0124)  time: 0.5242  data: 0.0019  max mem: 5670\n",
            "Epoch: [0/2]  [1870/9200]  eta: 1:04:09  lr: 0.001000  loss: 190.5453 (200.9201)  time: 0.5413  data: 0.0046  max mem: 5670\n",
            "Epoch: [0/2]  [1880/9200]  eta: 1:04:05  lr: 0.001000  loss: 181.8335 (200.9384)  time: 0.5430  data: 0.0030  max mem: 5670\n",
            "Epoch: [0/2]  [1890/9200]  eta: 1:03:58  lr: 0.001000  loss: 181.8335 (200.8475)  time: 0.5169  data: 0.0012  max mem: 5670\n",
            "Epoch: [0/2]  [1900/9200]  eta: 1:03:56  lr: 0.001000  loss: 183.9720 (200.7785)  time: 0.5494  data: 0.0051  max mem: 5670\n",
            "Epoch: [0/2]  [1910/9200]  eta: 1:03:50  lr: 0.001000  loss: 195.1541 (200.8723)  time: 0.5607  data: 0.0041  max mem: 5670\n",
            "Epoch: [0/2]  [1920/9200]  eta: 1:03:41  lr: 0.001000  loss: 180.4006 (200.6790)  time: 0.4699  data: 0.0002  max mem: 5670\n",
            "Epoch: [0/2]  [1930/9200]  eta: 1:03:37  lr: 0.001000  loss: 170.1162 (200.6975)  time: 0.4891  data: 0.0032  max mem: 5670\n",
            "Epoch: [0/2]  [1940/9200]  eta: 1:03:30  lr: 0.001000  loss: 186.4791 (200.7332)  time: 0.5114  data: 0.0041  max mem: 5670\n",
            "Epoch: [0/2]  [1950/9200]  eta: 1:03:25  lr: 0.001000  loss: 183.6088 (200.6736)  time: 0.5037  data: 0.0011  max mem: 5670\n",
            "Epoch: [0/2]  [1960/9200]  eta: 1:03:20  lr: 0.001000  loss: 183.1829 (200.6296)  time: 0.5335  data: 0.0019  max mem: 5670\n",
            "Epoch: [0/2]  [1970/9200]  eta: 1:03:16  lr: 0.001000  loss: 148.5706 (200.5274)  time: 0.5573  data: 0.0046  max mem: 5670\n",
            "Epoch: [0/2]  [1980/9200]  eta: 1:03:11  lr: 0.001000  loss: 192.3810 (200.5206)  time: 0.5522  data: 0.0029  max mem: 5670\n",
            "Epoch: [0/2]  [1990/9200]  eta: 1:03:04  lr: 0.001000  loss: 159.2365 (200.3551)  time: 0.4994  data: 0.0010  max mem: 5670\n",
            "Epoch: [0/2]  [2000/9200]  eta: 1:03:01  lr: 0.001000  loss: 159.2365 (200.3916)  time: 0.5326  data: 0.0036  max mem: 5670\n",
            "Epoch: [0/2]  [2010/9200]  eta: 1:02:55  lr: 0.001000  loss: 190.5119 (200.2838)  time: 0.5430  data: 0.0036  max mem: 5670\n",
            "Epoch: [0/2]  [2020/9200]  eta: 1:02:47  lr: 0.001000  loss: 190.5119 (200.3543)  time: 0.4722  data: 0.0010  max mem: 5670\n",
            "Epoch: [0/2]  [2030/9200]  eta: 1:02:45  lr: 0.001000  loss: 205.1586 (200.3727)  time: 0.5322  data: 0.0031  max mem: 5670\n",
            "Epoch: [0/2]  [2040/9200]  eta: 1:02:41  lr: 0.001000  loss: 199.1631 (200.4284)  time: 0.5936  data: 0.0044  max mem: 5670\n",
            "Epoch: [0/2]  [2050/9200]  eta: 1:02:34  lr: 0.001000  loss: 192.7624 (200.4099)  time: 0.5135  data: 0.0019  max mem: 5670\n",
            "Epoch: [0/2]  [2060/9200]  eta: 1:02:31  lr: 0.001000  loss: 185.7482 (200.3985)  time: 0.5256  data: 0.0022  max mem: 5670\n",
            "Epoch: [0/2]  [2070/9200]  eta: 1:02:25  lr: 0.001000  loss: 178.6737 (200.2311)  time: 0.5512  data: 0.0043  max mem: 5670\n",
            "Epoch: [0/2]  [2080/9200]  eta: 1:02:19  lr: 0.001000  loss: 176.8466 (200.1619)  time: 0.5068  data: 0.0027  max mem: 5670\n",
            "Epoch: [0/2]  [2090/9200]  eta: 1:02:12  lr: 0.001000  loss: 189.1317 (200.0797)  time: 0.4958  data: 0.0006  max mem: 5670\n",
            "Epoch: [0/2]  [2100/9200]  eta: 1:02:08  lr: 0.001000  loss: 189.1317 (200.0811)  time: 0.5209  data: 0.0037  max mem: 5670\n",
            "Epoch: [0/2]  [2110/9200]  eta: 1:02:02  lr: 0.001000  loss: 187.5826 (200.0113)  time: 0.5242  data: 0.0044  max mem: 5670\n",
            "Epoch: [0/2]  [2120/9200]  eta: 1:01:56  lr: 0.001000  loss: 186.8672 (199.9725)  time: 0.5042  data: 0.0013  max mem: 5670\n",
            "Epoch: [0/2]  [2130/9200]  eta: 1:01:52  lr: 0.001000  loss: 187.5333 (199.8878)  time: 0.5357  data: 0.0023  max mem: 5670\n",
            "Epoch: [0/2]  [2140/9200]  eta: 1:01:48  lr: 0.001000  loss: 183.8442 (199.8243)  time: 0.5621  data: 0.0043  max mem: 5670\n",
            "Epoch: [0/2]  [2150/9200]  eta: 1:01:41  lr: 0.001000  loss: 189.7027 (199.8216)  time: 0.5237  data: 0.0021  max mem: 5670\n",
            "Epoch: [0/2]  [2160/9200]  eta: 1:01:35  lr: 0.001000  loss: 185.0771 (199.7106)  time: 0.4802  data: 0.0011  max mem: 5670\n",
            "Epoch: [0/2]  [2170/9200]  eta: 1:01:29  lr: 0.001000  loss: 159.1948 (199.5180)  time: 0.5023  data: 0.0040  max mem: 5670\n",
            "Epoch: [0/2]  [2180/9200]  eta: 1:01:23  lr: 0.001000  loss: 159.1948 (199.4306)  time: 0.5019  data: 0.0031  max mem: 5670\n",
            "Epoch: [0/2]  [2190/9200]  eta: 1:01:17  lr: 0.001000  loss: 158.1526 (199.2520)  time: 0.4922  data: 0.0002  max mem: 5670\n",
            "Epoch: [0/2]  [2200/9200]  eta: 1:01:11  lr: 0.001000  loss: 152.0967 (199.0641)  time: 0.5033  data: 0.0045  max mem: 5670\n",
            "Epoch: [0/2]  [2210/9200]  eta: 1:01:05  lr: 0.001000  loss: 168.9157 (199.0191)  time: 0.5062  data: 0.0061  max mem: 5670\n",
            "Epoch: [0/2]  [2220/9200]  eta: 1:00:58  lr: 0.001000  loss: 179.3211 (199.0305)  time: 0.4853  data: 0.0018  max mem: 5670\n",
            "Epoch: [0/2]  [2230/9200]  eta: 1:00:53  lr: 0.001000  loss: 179.3211 (198.9847)  time: 0.4927  data: 0.0013  max mem: 5670\n",
            "Epoch: [0/2]  [2240/9200]  eta: 1:00:47  lr: 0.001000  loss: 185.1121 (198.9342)  time: 0.5213  data: 0.0041  max mem: 5670\n",
            "Epoch: [0/2]  [2250/9200]  eta: 1:00:41  lr: 0.001000  loss: 188.5268 (198.9115)  time: 0.5051  data: 0.0030  max mem: 5670\n",
            "Epoch: [0/2]  [2260/9200]  eta: 1:00:35  lr: 0.001000  loss: 188.5268 (198.8112)  time: 0.4908  data: 0.0002  max mem: 5670\n",
            "Epoch: [0/2]  [2270/9200]  eta: 1:00:32  lr: 0.001000  loss: 191.1349 (198.8678)  time: 0.5417  data: 0.0040  max mem: 5670\n",
            "Epoch: [0/2]  [2280/9200]  eta: 1:00:26  lr: 0.001000  loss: 191.0494 (198.7715)  time: 0.5444  data: 0.0059  max mem: 5670\n",
            "Epoch: [0/2]  [2290/9200]  eta: 1:00:19  lr: 0.001000  loss: 186.4927 (198.7486)  time: 0.4895  data: 0.0020  max mem: 5670\n",
            "Epoch: [0/2]  [2300/9200]  eta: 1:00:13  lr: 0.001000  loss: 163.9716 (198.5531)  time: 0.4843  data: 0.0013  max mem: 5670\n",
            "Epoch: [0/2]  [2310/9200]  eta: 1:00:09  lr: 0.001000  loss: 170.3928 (198.6127)  time: 0.5324  data: 0.0044  max mem: 5670\n",
            "Epoch: [0/2]  [2320/9200]  eta: 1:00:03  lr: 0.001000  loss: 179.7568 (198.6145)  time: 0.5337  data: 0.0033  max mem: 5670\n",
            "Epoch: [0/2]  [2330/9200]  eta: 0:59:58  lr: 0.001000  loss: 196.2257 (198.7108)  time: 0.5162  data: 0.0005  max mem: 5670\n",
            "Epoch: [0/2]  [2340/9200]  eta: 0:59:53  lr: 0.001000  loss: 193.6147 (198.6391)  time: 0.5378  data: 0.0040  max mem: 5670\n",
            "Epoch: [0/2]  [2350/9200]  eta: 0:59:47  lr: 0.001000  loss: 183.0742 (198.6735)  time: 0.5147  data: 0.0043  max mem: 5670\n",
            "Epoch: [0/2]  [2360/9200]  eta: 0:59:40  lr: 0.001000  loss: 200.2367 (198.7407)  time: 0.4803  data: 0.0008  max mem: 5670\n",
            "Epoch: [0/2]  [2370/9200]  eta: 0:59:37  lr: 0.001000  loss: 200.2367 (198.7498)  time: 0.5296  data: 0.0027  max mem: 5670\n",
            "Epoch: [0/2]  [2380/9200]  eta: 0:59:31  lr: 0.001000  loss: 175.8087 (198.5970)  time: 0.5366  data: 0.0043  max mem: 5670\n",
            "Epoch: [0/2]  [2390/9200]  eta: 0:59:24  lr: 0.001000  loss: 152.4810 (198.5160)  time: 0.4809  data: 0.0018  max mem: 5670\n",
            "Epoch: [0/2]  [2400/9200]  eta: 0:59:18  lr: 0.001000  loss: 164.8050 (198.3872)  time: 0.4908  data: 0.0016  max mem: 5670\n",
            "Epoch: [0/2]  [2410/9200]  eta: 0:59:14  lr: 0.001000  loss: 175.2047 (198.3768)  time: 0.5365  data: 0.0042  max mem: 5670\n",
            "Epoch: [0/2]  [2420/9200]  eta: 0:59:09  lr: 0.001000  loss: 192.7625 (198.3197)  time: 0.5383  data: 0.0028  max mem: 5670\n",
            "Epoch: [0/2]  [2430/9200]  eta: 0:59:04  lr: 0.001000  loss: 183.9310 (198.2846)  time: 0.5315  data: 0.0009  max mem: 5670\n",
            "Epoch: [0/2]  [2440/9200]  eta: 0:59:01  lr: 0.001000  loss: 190.0883 (198.3155)  time: 0.5701  data: 0.0038  max mem: 5670\n",
            "Epoch: [0/2]  [2450/9200]  eta: 0:58:53  lr: 0.001000  loss: 187.8390 (198.2110)  time: 0.5147  data: 0.0032  max mem: 5670\n",
            "Epoch: [0/2]  [2460/9200]  eta: 0:58:47  lr: 0.001000  loss: 181.6828 (198.1518)  time: 0.4573  data: 0.0002  max mem: 5670\n",
            "Epoch: [0/2]  [2470/9200]  eta: 0:58:42  lr: 0.001000  loss: 188.7422 (198.1067)  time: 0.5079  data: 0.0025  max mem: 5670\n",
            "Epoch: [0/2]  [2480/9200]  eta: 0:58:39  lr: 0.001000  loss: 198.2884 (198.1936)  time: 0.5754  data: 0.0037  max mem: 5670\n",
            "Epoch: [0/2]  [2490/9200]  eta: 0:58:33  lr: 0.001000  loss: 200.4691 (198.2363)  time: 0.5547  data: 0.0014  max mem: 5670\n",
            "Epoch: [0/2]  [2500/9200]  eta: 0:58:29  lr: 0.001000  loss: 207.1270 (198.2133)  time: 0.5249  data: 0.0022  max mem: 5670\n",
            "Epoch: [0/2]  [2510/9200]  eta: 0:58:25  lr: 0.001000  loss: 207.5205 (198.3061)  time: 0.5582  data: 0.0033  max mem: 5670\n",
            "Epoch: [0/2]  [2520/9200]  eta: 0:58:18  lr: 0.001000  loss: 213.5357 (198.3598)  time: 0.5312  data: 0.0014  max mem: 5670\n",
            "Epoch: [0/2]  [2530/9200]  eta: 0:58:13  lr: 0.001000  loss: 197.2393 (198.3304)  time: 0.5003  data: 0.0021  max mem: 5670\n",
            "Epoch: [0/2]  [2540/9200]  eta: 0:58:09  lr: 0.001000  loss: 167.3854 (198.1851)  time: 0.5495  data: 0.0038  max mem: 5670\n",
            "Epoch: [0/2]  [2550/9200]  eta: 0:58:02  lr: 0.001000  loss: 164.3355 (198.0881)  time: 0.5139  data: 0.0021  max mem: 5670\n",
            "Epoch: [0/2]  [2560/9200]  eta: 0:57:58  lr: 0.001000  loss: 173.7583 (198.1149)  time: 0.5021  data: 0.0009  max mem: 5670\n",
            "Epoch: [0/2]  [2570/9200]  eta: 0:57:54  lr: 0.001000  loss: 180.6722 (198.0643)  time: 0.5690  data: 0.0037  max mem: 5670\n",
            "Epoch: [0/2]  [2580/9200]  eta: 0:57:47  lr: 0.001000  loss: 169.1987 (198.0004)  time: 0.5209  data: 0.0031  max mem: 5670\n",
            "Epoch: [0/2]  [2590/9200]  eta: 0:57:40  lr: 0.001000  loss: 172.7676 (197.8692)  time: 0.4629  data: 0.0002  max mem: 5670\n",
            "Epoch: [0/2]  [2600/9200]  eta: 0:57:37  lr: 0.001000  loss: 186.6773 (197.8557)  time: 0.5254  data: 0.0040  max mem: 5670\n",
            "Epoch: [0/2]  [2610/9200]  eta: 0:57:30  lr: 0.001000  loss: 187.8544 (197.8611)  time: 0.5239  data: 0.0047  max mem: 5670\n",
            "Epoch: [0/2]  [2620/9200]  eta: 0:57:23  lr: 0.001000  loss: 185.1974 (197.9073)  time: 0.4604  data: 0.0009  max mem: 5670\n",
            "Epoch: [0/2]  [2630/9200]  eta: 0:57:17  lr: 0.001000  loss: 189.7959 (197.9234)  time: 0.4868  data: 0.0021  max mem: 5670\n",
            "Epoch: [0/2]  [2640/9200]  eta: 0:57:13  lr: 0.001000  loss: 163.9338 (197.9006)  time: 0.5311  data: 0.0042  max mem: 5804\n",
            "Epoch: [0/2]  [2650/9200]  eta: 0:57:07  lr: 0.001000  loss: 171.7857 (197.9074)  time: 0.5318  data: 0.0023  max mem: 5804\n",
            "Epoch: [0/2]  [2660/9200]  eta: 0:57:02  lr: 0.001000  loss: 198.9098 (197.8733)  time: 0.5047  data: 0.0011  max mem: 5804\n",
            "Epoch: [0/2]  [2670/9200]  eta: 0:56:56  lr: 0.001000  loss: 194.1674 (197.8544)  time: 0.5101  data: 0.0050  max mem: 5804\n",
            "Epoch: [0/2]  [2680/9200]  eta: 0:56:49  lr: 0.001000  loss: 175.8440 (197.7287)  time: 0.4864  data: 0.0050  max mem: 5804\n",
            "Epoch: [0/2]  [2690/9200]  eta: 0:56:43  lr: 0.001000  loss: 178.2695 (197.7734)  time: 0.4720  data: 0.0012  max mem: 5804\n",
            "Epoch: [0/2]  [2700/9200]  eta: 0:56:39  lr: 0.001000  loss: 179.7907 (197.7234)  time: 0.5326  data: 0.0019  max mem: 5804\n",
            "Epoch: [0/2]  [2710/9200]  eta: 0:56:35  lr: 0.001000  loss: 188.4828 (197.8057)  time: 0.5706  data: 0.0044  max mem: 5804\n",
            "Epoch: [0/2]  [2720/9200]  eta: 0:56:29  lr: 0.001000  loss: 188.4828 (197.8077)  time: 0.5318  data: 0.0028  max mem: 5804\n",
            "Epoch: [0/2]  [2730/9200]  eta: 0:56:26  lr: 0.001000  loss: 188.3930 (197.9342)  time: 0.5480  data: 0.0017  max mem: 5804\n",
            "Epoch: [0/2]  [2740/9200]  eta: 0:56:22  lr: 0.001000  loss: 203.8378 (198.0041)  time: 0.5994  data: 0.0041  max mem: 5804\n",
            "Epoch: [0/2]  [2750/9200]  eta: 0:56:16  lr: 0.001000  loss: 203.8378 (197.9993)  time: 0.5256  data: 0.0029  max mem: 5804\n",
            "Epoch: [0/2]  [2760/9200]  eta: 0:56:10  lr: 0.001000  loss: 185.1645 (197.9154)  time: 0.4925  data: 0.0013  max mem: 5804\n",
            "Epoch: [0/2]  [2770/9200]  eta: 0:56:07  lr: 0.001000  loss: 181.3056 (197.8637)  time: 0.5697  data: 0.0043  max mem: 5804\n",
            "Epoch: [0/2]  [2780/9200]  eta: 0:56:01  lr: 0.001000  loss: 186.6855 (197.8199)  time: 0.5430  data: 0.0035  max mem: 5804\n",
            "Epoch: [0/2]  [2790/9200]  eta: 0:55:55  lr: 0.001000  loss: 191.9994 (197.8801)  time: 0.4932  data: 0.0003  max mem: 5804\n",
            "Epoch: [0/2]  [2800/9200]  eta: 0:55:51  lr: 0.001000  loss: 184.5168 (197.8133)  time: 0.5282  data: 0.0037  max mem: 5804\n",
            "Epoch: [0/2]  [2810/9200]  eta: 0:55:44  lr: 0.001000  loss: 181.8811 (197.7526)  time: 0.5100  data: 0.0052  max mem: 5804\n",
            "Epoch: [0/2]  [2820/9200]  eta: 0:55:39  lr: 0.001000  loss: 185.4539 (197.7671)  time: 0.5047  data: 0.0019  max mem: 5804\n",
            "Epoch: [0/2]  [2830/9200]  eta: 0:55:34  lr: 0.001000  loss: 197.1523 (197.7516)  time: 0.5306  data: 0.0023  max mem: 5804\n",
            "Epoch: [0/2]  [2840/9200]  eta: 0:55:28  lr: 0.001000  loss: 197.1523 (197.7568)  time: 0.5128  data: 0.0041  max mem: 5804\n",
            "Epoch: [0/2]  [2850/9200]  eta: 0:55:22  lr: 0.001000  loss: 203.5750 (197.7460)  time: 0.4951  data: 0.0021  max mem: 5804\n",
            "Epoch: [0/2]  [2860/9200]  eta: 0:55:18  lr: 0.001000  loss: 184.7609 (197.7342)  time: 0.5230  data: 0.0020  max mem: 5804\n",
            "Epoch: [0/2]  [2870/9200]  eta: 0:55:13  lr: 0.001000  loss: 184.7609 (197.6751)  time: 0.5532  data: 0.0043  max mem: 5804\n",
            "Epoch: [0/2]  [2880/9200]  eta: 0:55:07  lr: 0.001000  loss: 180.8028 (197.5854)  time: 0.5151  data: 0.0025  max mem: 5804\n",
            "Epoch: [0/2]  [2890/9200]  eta: 0:55:02  lr: 0.001000  loss: 180.8028 (197.6366)  time: 0.5105  data: 0.0009  max mem: 5804\n",
            "Epoch: [0/2]  [2900/9200]  eta: 0:54:58  lr: 0.001000  loss: 205.2374 (197.6523)  time: 0.5533  data: 0.0042  max mem: 5804\n",
            "Epoch: [0/2]  [2910/9200]  eta: 0:54:52  lr: 0.001000  loss: 192.7570 (197.6338)  time: 0.5206  data: 0.0035  max mem: 5804\n",
            "Epoch: [0/2]  [2920/9200]  eta: 0:54:46  lr: 0.001000  loss: 192.7570 (197.6142)  time: 0.4920  data: 0.0002  max mem: 5804\n",
            "Epoch: [0/2]  [2930/9200]  eta: 0:54:40  lr: 0.001000  loss: 162.0847 (197.4438)  time: 0.5014  data: 0.0029  max mem: 5804\n",
            "Epoch: [0/2]  [2940/9200]  eta: 0:54:35  lr: 0.001000  loss: 169.3793 (197.4862)  time: 0.5029  data: 0.0041  max mem: 5804\n",
            "Epoch: [0/2]  [2950/9200]  eta: 0:54:27  lr: 0.001000  loss: 175.8544 (197.4058)  time: 0.4707  data: 0.0015  max mem: 5804\n",
            "Epoch: [0/2]  [2960/9200]  eta: 0:54:22  lr: 0.001000  loss: 168.3430 (197.3665)  time: 0.4743  data: 0.0009  max mem: 5804\n",
            "Epoch: [0/2]  [2970/9200]  eta: 0:54:18  lr: 0.001000  loss: 188.3472 (197.3129)  time: 0.5367  data: 0.0033  max mem: 5804\n",
            "Epoch: [0/2]  [2980/9200]  eta: 0:54:12  lr: 0.001000  loss: 179.6240 (197.2957)  time: 0.5307  data: 0.0026  max mem: 5804\n",
            "Epoch: [0/2]  [2990/9200]  eta: 0:54:07  lr: 0.001000  loss: 187.4482 (197.3078)  time: 0.5249  data: 0.0005  max mem: 5804\n",
            "Epoch: [0/2]  [3000/9200]  eta: 0:54:04  lr: 0.001000  loss: 188.2564 (197.2914)  time: 0.5689  data: 0.0037  max mem: 5804\n",
            "Epoch: [0/2]  [3010/9200]  eta: 0:53:57  lr: 0.001000  loss: 174.1837 (197.1526)  time: 0.5225  data: 0.0034  max mem: 5804\n",
            "Epoch: [0/2]  [3020/9200]  eta: 0:53:51  lr: 0.001000  loss: 176.6704 (197.1725)  time: 0.4690  data: 0.0002  max mem: 5804\n",
            "Epoch: [0/2]  [3030/9200]  eta: 0:53:46  lr: 0.001000  loss: 195.1413 (197.1568)  time: 0.5237  data: 0.0025  max mem: 5804\n",
            "Epoch: [0/2]  [3040/9200]  eta: 0:53:41  lr: 0.001000  loss: 182.3533 (197.1528)  time: 0.5303  data: 0.0034  max mem: 5804\n",
            "Epoch: [0/2]  [3050/9200]  eta: 0:53:34  lr: 0.001000  loss: 179.1065 (197.1676)  time: 0.4785  data: 0.0011  max mem: 5804\n",
            "Epoch: [0/2]  [3060/9200]  eta: 0:53:30  lr: 0.001000  loss: 174.9265 (197.1484)  time: 0.5119  data: 0.0021  max mem: 5804\n",
            "Epoch: [0/2]  [3070/9200]  eta: 0:53:26  lr: 0.001000  loss: 201.6494 (197.2055)  time: 0.5809  data: 0.0035  max mem: 5804\n",
            "Epoch: [0/2]  [3080/9200]  eta: 0:53:20  lr: 0.001000  loss: 201.6494 (197.2056)  time: 0.5424  data: 0.0015  max mem: 5804\n",
            "Epoch: [0/2]  [3090/9200]  eta: 0:53:16  lr: 0.001000  loss: 190.1177 (197.2367)  time: 0.5295  data: 0.0018  max mem: 5804\n",
            "Epoch: [0/2]  [3100/9200]  eta: 0:53:11  lr: 0.001000  loss: 185.8861 (197.2464)  time: 0.5580  data: 0.0044  max mem: 5804\n",
            "Epoch: [0/2]  [3110/9200]  eta: 0:53:07  lr: 0.001000  loss: 199.5237 (197.2559)  time: 0.5569  data: 0.0029  max mem: 5844\n",
            "Epoch: [0/2]  [3120/9200]  eta: 0:53:00  lr: 0.001000  loss: 162.9749 (197.1455)  time: 0.5162  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [3130/9200]  eta: 0:52:56  lr: 0.001000  loss: 162.9749 (197.1261)  time: 0.5103  data: 0.0036  max mem: 5844\n",
            "Epoch: [0/2]  [3140/9200]  eta: 0:52:50  lr: 0.001000  loss: 189.0253 (197.1224)  time: 0.5199  data: 0.0033  max mem: 5844\n",
            "Epoch: [0/2]  [3150/9200]  eta: 0:52:45  lr: 0.001000  loss: 188.8949 (197.0995)  time: 0.5112  data: 0.0006  max mem: 5844\n",
            "Epoch: [0/2]  [3160/9200]  eta: 0:52:40  lr: 0.001000  loss: 160.9554 (197.0389)  time: 0.5439  data: 0.0040  max mem: 5844\n",
            "Epoch: [0/2]  [3170/9200]  eta: 0:52:35  lr: 0.001000  loss: 176.8070 (197.0879)  time: 0.5320  data: 0.0046  max mem: 5844\n",
            "Epoch: [0/2]  [3180/9200]  eta: 0:52:29  lr: 0.001000  loss: 176.8070 (197.0534)  time: 0.5003  data: 0.0014  max mem: 5844\n",
            "Epoch: [0/2]  [3190/9200]  eta: 0:52:24  lr: 0.001000  loss: 187.5797 (197.0928)  time: 0.5340  data: 0.0027  max mem: 5844\n",
            "Epoch: [0/2]  [3200/9200]  eta: 0:52:19  lr: 0.001000  loss: 193.9181 (197.1013)  time: 0.5310  data: 0.0032  max mem: 5844\n",
            "Epoch: [0/2]  [3210/9200]  eta: 0:52:12  lr: 0.001000  loss: 192.1556 (197.1082)  time: 0.4724  data: 0.0010  max mem: 5844\n",
            "Epoch: [0/2]  [3220/9200]  eta: 0:52:06  lr: 0.001000  loss: 195.4510 (197.0820)  time: 0.4790  data: 0.0012  max mem: 5844\n",
            "Epoch: [0/2]  [3230/9200]  eta: 0:52:02  lr: 0.001000  loss: 195.4510 (197.1225)  time: 0.5249  data: 0.0035  max mem: 5844\n",
            "Epoch: [0/2]  [3240/9200]  eta: 0:51:55  lr: 0.001000  loss: 162.8016 (197.0879)  time: 0.5063  data: 0.0025  max mem: 5844\n",
            "Epoch: [0/2]  [3250/9200]  eta: 0:51:50  lr: 0.001000  loss: 158.5298 (197.0720)  time: 0.4961  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [3260/9200]  eta: 0:51:45  lr: 0.001000  loss: 183.0050 (197.0431)  time: 0.5196  data: 0.0027  max mem: 5844\n",
            "Epoch: [0/2]  [3270/9200]  eta: 0:51:39  lr: 0.001000  loss: 181.8781 (197.0302)  time: 0.4932  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [3280/9200]  eta: 0:51:33  lr: 0.001000  loss: 176.0330 (196.9931)  time: 0.4784  data: 0.0009  max mem: 5844\n",
            "Epoch: [0/2]  [3290/9200]  eta: 0:51:28  lr: 0.001000  loss: 186.4678 (196.9920)  time: 0.5155  data: 0.0028  max mem: 5844\n",
            "Epoch: [0/2]  [3300/9200]  eta: 0:51:23  lr: 0.001000  loss: 177.3947 (196.9161)  time: 0.5489  data: 0.0057  max mem: 5844\n",
            "Epoch: [0/2]  [3310/9200]  eta: 0:51:17  lr: 0.001000  loss: 172.5620 (196.9270)  time: 0.5034  data: 0.0031  max mem: 5844\n",
            "Epoch: [0/2]  [3320/9200]  eta: 0:51:11  lr: 0.001000  loss: 183.8307 (196.8876)  time: 0.4797  data: 0.0003  max mem: 5844\n",
            "Epoch: [0/2]  [3330/9200]  eta: 0:51:07  lr: 0.001000  loss: 190.4095 (197.0075)  time: 0.5387  data: 0.0026  max mem: 5844\n",
            "Epoch: [0/2]  [3340/9200]  eta: 0:51:03  lr: 0.001000  loss: 201.3563 (197.0409)  time: 0.5740  data: 0.0036  max mem: 5844\n",
            "Epoch: [0/2]  [3350/9200]  eta: 0:50:57  lr: 0.001000  loss: 197.8572 (197.0591)  time: 0.5236  data: 0.0012  max mem: 5844\n",
            "Epoch: [0/2]  [3360/9200]  eta: 0:50:52  lr: 0.001000  loss: 182.7178 (196.9886)  time: 0.5070  data: 0.0020  max mem: 5844\n",
            "Epoch: [0/2]  [3370/9200]  eta: 0:50:46  lr: 0.001000  loss: 161.3053 (196.8675)  time: 0.5065  data: 0.0035  max mem: 5844\n",
            "Epoch: [0/2]  [3380/9200]  eta: 0:50:39  lr: 0.001000  loss: 163.7072 (196.7782)  time: 0.4501  data: 0.0017  max mem: 5844\n",
            "Epoch: [0/2]  [3390/9200]  eta: 0:50:33  lr: 0.001000  loss: 178.5203 (196.7857)  time: 0.4710  data: 0.0012  max mem: 5844\n",
            "Epoch: [0/2]  [3400/9200]  eta: 0:50:30  lr: 0.001000  loss: 198.5240 (196.8275)  time: 0.5677  data: 0.0046  max mem: 5844\n",
            "Epoch: [0/2]  [3410/9200]  eta: 0:50:24  lr: 0.001000  loss: 196.9874 (196.8021)  time: 0.5529  data: 0.0036  max mem: 5844\n",
            "Epoch: [0/2]  [3420/9200]  eta: 0:50:18  lr: 0.001000  loss: 203.6828 (196.8898)  time: 0.4920  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [3430/9200]  eta: 0:50:14  lr: 0.001000  loss: 198.6436 (196.8183)  time: 0.5396  data: 0.0033  max mem: 5844\n",
            "Epoch: [0/2]  [3440/9200]  eta: 0:50:09  lr: 0.001000  loss: 172.8121 (196.7955)  time: 0.5559  data: 0.0044  max mem: 5844\n",
            "Epoch: [0/2]  [3450/9200]  eta: 0:50:02  lr: 0.001000  loss: 176.6399 (196.7143)  time: 0.4856  data: 0.0016  max mem: 5844\n",
            "Epoch: [0/2]  [3460/9200]  eta: 0:49:58  lr: 0.001000  loss: 176.6399 (196.7128)  time: 0.5170  data: 0.0025  max mem: 5844\n",
            "Epoch: [0/2]  [3470/9200]  eta: 0:49:54  lr: 0.001000  loss: 193.3360 (196.7491)  time: 0.5714  data: 0.0043  max mem: 5844\n",
            "Epoch: [0/2]  [3480/9200]  eta: 0:49:47  lr: 0.001000  loss: 182.3343 (196.6972)  time: 0.5080  data: 0.0021  max mem: 5844\n",
            "Epoch: [0/2]  [3490/9200]  eta: 0:49:43  lr: 0.001000  loss: 165.6694 (196.7687)  time: 0.5132  data: 0.0025  max mem: 5844\n",
            "Epoch: [0/2]  [3500/9200]  eta: 0:49:39  lr: 0.001000  loss: 193.7276 (196.7711)  time: 0.5740  data: 0.0048  max mem: 5844\n",
            "Epoch: [0/2]  [3510/9200]  eta: 0:49:33  lr: 0.001000  loss: 193.7276 (196.7921)  time: 0.5305  data: 0.0024  max mem: 5844\n",
            "Epoch: [0/2]  [3520/9200]  eta: 0:49:27  lr: 0.001000  loss: 191.5917 (196.7957)  time: 0.4941  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [3530/9200]  eta: 0:49:23  lr: 0.001000  loss: 175.7983 (196.7531)  time: 0.5321  data: 0.0031  max mem: 5844\n",
            "Epoch: [0/2]  [3540/9200]  eta: 0:49:18  lr: 0.001000  loss: 177.8863 (196.7383)  time: 0.5475  data: 0.0033  max mem: 5844\n",
            "Epoch: [0/2]  [3550/9200]  eta: 0:49:12  lr: 0.001000  loss: 201.6111 (196.7586)  time: 0.5350  data: 0.0011  max mem: 5844\n",
            "Epoch: [0/2]  [3560/9200]  eta: 0:49:08  lr: 0.001000  loss: 186.2566 (196.7812)  time: 0.5613  data: 0.0036  max mem: 5844\n",
            "Epoch: [0/2]  [3570/9200]  eta: 0:49:02  lr: 0.001000  loss: 183.5384 (196.7345)  time: 0.5349  data: 0.0037  max mem: 5844\n",
            "Epoch: [0/2]  [3580/9200]  eta: 0:48:56  lr: 0.001000  loss: 182.1839 (196.6885)  time: 0.4622  data: 0.0007  max mem: 5844\n",
            "Epoch: [0/2]  [3590/9200]  eta: 0:48:51  lr: 0.001000  loss: 175.0489 (196.6735)  time: 0.4968  data: 0.0016  max mem: 5844\n",
            "Epoch: [0/2]  [3600/9200]  eta: 0:48:46  lr: 0.001000  loss: 168.4557 (196.6394)  time: 0.5513  data: 0.0037  max mem: 5844\n",
            "Epoch: [0/2]  [3610/9200]  eta: 0:48:41  lr: 0.001000  loss: 189.8127 (196.6187)  time: 0.5371  data: 0.0023  max mem: 5844\n",
            "Epoch: [0/2]  [3620/9200]  eta: 0:48:35  lr: 0.001000  loss: 192.9325 (196.5860)  time: 0.5029  data: 0.0012  max mem: 5844\n",
            "Epoch: [0/2]  [3630/9200]  eta: 0:48:30  lr: 0.001000  loss: 177.2295 (196.5342)  time: 0.5027  data: 0.0041  max mem: 5844\n",
            "Epoch: [0/2]  [3640/9200]  eta: 0:48:24  lr: 0.001000  loss: 157.6623 (196.4760)  time: 0.4920  data: 0.0031  max mem: 5844\n",
            "Epoch: [0/2]  [3650/9200]  eta: 0:48:18  lr: 0.001000  loss: 163.6965 (196.4776)  time: 0.4704  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [3660/9200]  eta: 0:48:14  lr: 0.001000  loss: 185.4175 (196.4712)  time: 0.5227  data: 0.0042  max mem: 5844\n",
            "Epoch: [0/2]  [3670/9200]  eta: 0:48:08  lr: 0.001000  loss: 189.4094 (196.4957)  time: 0.5432  data: 0.0044  max mem: 5844\n",
            "Epoch: [0/2]  [3680/9200]  eta: 0:48:03  lr: 0.001000  loss: 189.5488 (196.5028)  time: 0.5057  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [3690/9200]  eta: 0:47:58  lr: 0.001000  loss: 175.9353 (196.4337)  time: 0.5151  data: 0.0030  max mem: 5844\n",
            "Epoch: [0/2]  [3700/9200]  eta: 0:47:52  lr: 0.001000  loss: 166.2784 (196.3908)  time: 0.5277  data: 0.0042  max mem: 5844\n",
            "Epoch: [0/2]  [3710/9200]  eta: 0:47:47  lr: 0.001000  loss: 167.4287 (196.4090)  time: 0.5170  data: 0.0017  max mem: 5844\n",
            "Epoch: [0/2]  [3720/9200]  eta: 0:47:41  lr: 0.001000  loss: 168.1096 (196.3557)  time: 0.5018  data: 0.0027  max mem: 5844\n",
            "Epoch: [0/2]  [3730/9200]  eta: 0:47:36  lr: 0.001000  loss: 158.4555 (196.2844)  time: 0.5092  data: 0.0057  max mem: 5844\n",
            "Epoch: [0/2]  [3740/9200]  eta: 0:47:30  lr: 0.001000  loss: 180.9190 (196.2573)  time: 0.4821  data: 0.0036  max mem: 5844\n",
            "Epoch: [0/2]  [3750/9200]  eta: 0:47:24  lr: 0.001000  loss: 178.1517 (196.2142)  time: 0.4765  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [3760/9200]  eta: 0:47:20  lr: 0.001000  loss: 182.5667 (196.2666)  time: 0.5337  data: 0.0045  max mem: 5844\n",
            "Epoch: [0/2]  [3770/9200]  eta: 0:47:14  lr: 0.001000  loss: 182.5667 (196.2513)  time: 0.5312  data: 0.0053  max mem: 5844\n",
            "Epoch: [0/2]  [3780/9200]  eta: 0:47:08  lr: 0.001000  loss: 186.1962 (196.2796)  time: 0.4954  data: 0.0013  max mem: 5844\n",
            "Epoch: [0/2]  [3790/9200]  eta: 0:47:04  lr: 0.001000  loss: 199.4915 (196.2928)  time: 0.5194  data: 0.0024  max mem: 5844\n",
            "Epoch: [0/2]  [3800/9200]  eta: 0:46:59  lr: 0.001000  loss: 184.0203 (196.2554)  time: 0.5424  data: 0.0037  max mem: 5844\n",
            "Epoch: [0/2]  [3810/9200]  eta: 0:46:52  lr: 0.001000  loss: 165.4081 (196.1410)  time: 0.4641  data: 0.0015  max mem: 5844\n",
            "Epoch: [0/2]  [3820/9200]  eta: 0:46:47  lr: 0.001000  loss: 169.4485 (196.1230)  time: 0.4873  data: 0.0016  max mem: 5844\n",
            "Epoch: [0/2]  [3830/9200]  eta: 0:46:42  lr: 0.001000  loss: 186.6393 (196.0937)  time: 0.5518  data: 0.0048  max mem: 5844\n",
            "Epoch: [0/2]  [3840/9200]  eta: 0:46:36  lr: 0.001000  loss: 151.0792 (196.0612)  time: 0.5150  data: 0.0033  max mem: 5844\n",
            "Epoch: [0/2]  [3850/9200]  eta: 0:46:32  lr: 0.001000  loss: 184.8839 (196.0735)  time: 0.5331  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [3860/9200]  eta: 0:46:27  lr: 0.001000  loss: 195.1477 (196.1068)  time: 0.5597  data: 0.0037  max mem: 5844\n",
            "Epoch: [0/2]  [3870/9200]  eta: 0:46:22  lr: 0.001000  loss: 177.2047 (196.0463)  time: 0.5284  data: 0.0038  max mem: 5844\n",
            "Epoch: [0/2]  [3880/9200]  eta: 0:46:16  lr: 0.001000  loss: 161.5386 (195.9911)  time: 0.4846  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [3890/9200]  eta: 0:46:11  lr: 0.001000  loss: 187.0918 (196.0048)  time: 0.5117  data: 0.0025  max mem: 5844\n",
            "Epoch: [0/2]  [3900/9200]  eta: 0:46:06  lr: 0.001000  loss: 187.0918 (195.9557)  time: 0.5420  data: 0.0039  max mem: 5844\n",
            "Epoch: [0/2]  [3910/9200]  eta: 0:46:00  lr: 0.001000  loss: 194.9260 (195.9859)  time: 0.5080  data: 0.0017  max mem: 5844\n",
            "Epoch: [0/2]  [3920/9200]  eta: 0:45:55  lr: 0.001000  loss: 201.8602 (195.9893)  time: 0.5055  data: 0.0021  max mem: 5844\n",
            "Epoch: [0/2]  [3930/9200]  eta: 0:45:50  lr: 0.001000  loss: 181.7846 (195.9533)  time: 0.5526  data: 0.0055  max mem: 5844\n",
            "Epoch: [0/2]  [3940/9200]  eta: 0:45:45  lr: 0.001000  loss: 182.3971 (195.9821)  time: 0.5344  data: 0.0036  max mem: 5844\n",
            "Epoch: [0/2]  [3950/9200]  eta: 0:45:39  lr: 0.001000  loss: 182.3971 (195.9575)  time: 0.4925  data: 0.0003  max mem: 5844\n",
            "Epoch: [0/2]  [3960/9200]  eta: 0:45:35  lr: 0.001000  loss: 207.1880 (196.0348)  time: 0.5419  data: 0.0037  max mem: 5844\n",
            "Epoch: [0/2]  [3970/9200]  eta: 0:45:29  lr: 0.001000  loss: 189.5664 (195.9933)  time: 0.5331  data: 0.0040  max mem: 5844\n",
            "Epoch: [0/2]  [3980/9200]  eta: 0:45:23  lr: 0.001000  loss: 168.4804 (195.9607)  time: 0.4544  data: 0.0006  max mem: 5844\n",
            "Epoch: [0/2]  [3990/9200]  eta: 0:45:18  lr: 0.001000  loss: 168.4804 (195.9658)  time: 0.4782  data: 0.0023  max mem: 5844\n",
            "Epoch: [0/2]  [4000/9200]  eta: 0:45:13  lr: 0.001000  loss: 194.5513 (195.9739)  time: 0.5490  data: 0.0044  max mem: 5844\n",
            "Epoch: [0/2]  [4010/9200]  eta: 0:45:07  lr: 0.001000  loss: 194.8260 (195.9698)  time: 0.5150  data: 0.0028  max mem: 5844\n",
            "Epoch: [0/2]  [4020/9200]  eta: 0:45:01  lr: 0.001000  loss: 185.0803 (195.8830)  time: 0.4654  data: 0.0017  max mem: 5844\n",
            "Epoch: [0/2]  [4030/9200]  eta: 0:44:56  lr: 0.001000  loss: 185.0803 (195.9145)  time: 0.4976  data: 0.0039  max mem: 5844\n",
            "Epoch: [0/2]  [4040/9200]  eta: 0:44:50  lr: 0.001000  loss: 195.1131 (195.9029)  time: 0.5070  data: 0.0030  max mem: 5844\n",
            "Epoch: [0/2]  [4050/9200]  eta: 0:44:45  lr: 0.001000  loss: 194.2398 (195.9071)  time: 0.4913  data: 0.0009  max mem: 5844\n",
            "Epoch: [0/2]  [4060/9200]  eta: 0:44:40  lr: 0.001000  loss: 194.2398 (195.9286)  time: 0.5279  data: 0.0044  max mem: 5844\n",
            "Epoch: [0/2]  [4070/9200]  eta: 0:44:34  lr: 0.001000  loss: 176.1364 (195.9075)  time: 0.5246  data: 0.0043  max mem: 5844\n",
            "Epoch: [0/2]  [4080/9200]  eta: 0:44:29  lr: 0.001000  loss: 183.6196 (195.9026)  time: 0.4951  data: 0.0009  max mem: 5844\n",
            "Epoch: [0/2]  [4090/9200]  eta: 0:44:24  lr: 0.001000  loss: 200.3349 (195.9154)  time: 0.5432  data: 0.0030  max mem: 5844\n",
            "Epoch: [0/2]  [4100/9200]  eta: 0:44:19  lr: 0.001000  loss: 175.4319 (195.8992)  time: 0.5592  data: 0.0048  max mem: 5844\n",
            "Epoch: [0/2]  [4110/9200]  eta: 0:44:13  lr: 0.001000  loss: 175.4319 (195.8374)  time: 0.4701  data: 0.0021  max mem: 5844\n",
            "Epoch: [0/2]  [4120/9200]  eta: 0:44:08  lr: 0.001000  loss: 189.6909 (195.8323)  time: 0.4728  data: 0.0017  max mem: 5844\n",
            "Epoch: [0/2]  [4130/9200]  eta: 0:44:02  lr: 0.001000  loss: 169.6038 (195.7697)  time: 0.5181  data: 0.0044  max mem: 5844\n",
            "Epoch: [0/2]  [4140/9200]  eta: 0:43:57  lr: 0.001000  loss: 169.6038 (195.7929)  time: 0.4966  data: 0.0036  max mem: 5844\n",
            "Epoch: [0/2]  [4150/9200]  eta: 0:43:51  lr: 0.001000  loss: 191.4624 (195.8044)  time: 0.4953  data: 0.0013  max mem: 5844\n",
            "Epoch: [0/2]  [4160/9200]  eta: 0:43:47  lr: 0.001000  loss: 183.4894 (195.7809)  time: 0.5443  data: 0.0025  max mem: 5844\n",
            "Epoch: [0/2]  [4170/9200]  eta: 0:43:41  lr: 0.001000  loss: 165.2563 (195.7335)  time: 0.5325  data: 0.0022  max mem: 5844\n",
            "Epoch: [0/2]  [4180/9200]  eta: 0:43:35  lr: 0.001000  loss: 155.6009 (195.6755)  time: 0.4734  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [4190/9200]  eta: 0:43:30  lr: 0.001000  loss: 180.7177 (195.7015)  time: 0.5118  data: 0.0040  max mem: 5844\n",
            "Epoch: [0/2]  [4200/9200]  eta: 0:43:26  lr: 0.001000  loss: 192.7455 (195.7582)  time: 0.5517  data: 0.0044  max mem: 5844\n",
            "Epoch: [0/2]  [4210/9200]  eta: 0:43:20  lr: 0.001000  loss: 176.0382 (195.7610)  time: 0.5155  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [4220/9200]  eta: 0:43:15  lr: 0.001000  loss: 172.3152 (195.7373)  time: 0.5070  data: 0.0030  max mem: 5844\n",
            "Epoch: [0/2]  [4230/9200]  eta: 0:43:09  lr: 0.001000  loss: 176.9650 (195.6913)  time: 0.5031  data: 0.0048  max mem: 5844\n",
            "Epoch: [0/2]  [4240/9200]  eta: 0:43:03  lr: 0.001000  loss: 178.9410 (195.6795)  time: 0.4816  data: 0.0020  max mem: 5844\n",
            "Epoch: [0/2]  [4250/9200]  eta: 0:42:59  lr: 0.001000  loss: 204.9449 (195.7155)  time: 0.5389  data: 0.0012  max mem: 5844\n",
            "Epoch: [0/2]  [4260/9200]  eta: 0:42:54  lr: 0.001000  loss: 204.9449 (195.7457)  time: 0.5699  data: 0.0037  max mem: 5844\n",
            "Epoch: [0/2]  [4270/9200]  eta: 0:42:48  lr: 0.001000  loss: 182.0868 (195.7358)  time: 0.5136  data: 0.0026  max mem: 5844\n",
            "Epoch: [0/2]  [4280/9200]  eta: 0:42:43  lr: 0.001000  loss: 183.4904 (195.7554)  time: 0.4791  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [4290/9200]  eta: 0:42:38  lr: 0.001000  loss: 204.5409 (195.7889)  time: 0.5258  data: 0.0024  max mem: 5844\n",
            "Epoch: [0/2]  [4300/9200]  eta: 0:42:33  lr: 0.001000  loss: 207.0045 (195.7843)  time: 0.5606  data: 0.0038  max mem: 5844\n",
            "Epoch: [0/2]  [4310/9200]  eta: 0:42:27  lr: 0.001000  loss: 185.1486 (195.7344)  time: 0.5070  data: 0.0016  max mem: 5844\n",
            "Epoch: [0/2]  [4320/9200]  eta: 0:42:23  lr: 0.001000  loss: 175.3446 (195.6752)  time: 0.5193  data: 0.0027  max mem: 5844\n",
            "Epoch: [0/2]  [4330/9200]  eta: 0:42:19  lr: 0.001000  loss: 177.5294 (195.6978)  time: 0.6014  data: 0.0046  max mem: 5844\n",
            "Epoch: [0/2]  [4340/9200]  eta: 0:42:14  lr: 0.001000  loss: 182.7623 (195.7298)  time: 0.5799  data: 0.0021  max mem: 5844\n",
            "Epoch: [0/2]  [4350/9200]  eta: 0:42:09  lr: 0.001000  loss: 194.8059 (195.7418)  time: 0.5674  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [4360/9200]  eta: 0:42:05  lr: 0.001000  loss: 210.1979 (195.8546)  time: 0.6064  data: 0.0049  max mem: 5844\n",
            "Epoch: [0/2]  [4370/9200]  eta: 0:42:00  lr: 0.001000  loss: 209.7337 (195.8471)  time: 0.5665  data: 0.0017  max mem: 5844\n",
            "Epoch: [0/2]  [4380/9200]  eta: 0:41:55  lr: 0.001000  loss: 183.7922 (195.8462)  time: 0.5537  data: 0.0029  max mem: 5844\n",
            "Epoch: [0/2]  [4390/9200]  eta: 0:41:50  lr: 0.001000  loss: 183.7922 (195.8374)  time: 0.5443  data: 0.0045  max mem: 5844\n",
            "Epoch: [0/2]  [4400/9200]  eta: 0:41:45  lr: 0.001000  loss: 194.3710 (195.8254)  time: 0.5182  data: 0.0018  max mem: 5844\n",
            "Epoch: [0/2]  [4410/9200]  eta: 0:41:40  lr: 0.001000  loss: 175.1861 (195.7864)  time: 0.5456  data: 0.0019  max mem: 5844\n",
            "Epoch: [0/2]  [4420/9200]  eta: 0:41:35  lr: 0.001000  loss: 174.2394 (195.7250)  time: 0.5480  data: 0.0047  max mem: 5844\n",
            "Epoch: [0/2]  [4430/9200]  eta: 0:41:30  lr: 0.001000  loss: 174.1300 (195.7065)  time: 0.5276  data: 0.0030  max mem: 5844\n",
            "Epoch: [0/2]  [4440/9200]  eta: 0:41:25  lr: 0.001000  loss: 174.1300 (195.7297)  time: 0.5389  data: 0.0014  max mem: 5844\n",
            "Epoch: [0/2]  [4450/9200]  eta: 0:41:20  lr: 0.001000  loss: 164.8922 (195.7010)  time: 0.5676  data: 0.0036  max mem: 5844\n",
            "Epoch: [0/2]  [4460/9200]  eta: 0:41:14  lr: 0.001000  loss: 185.7500 (195.6993)  time: 0.5071  data: 0.0024  max mem: 5844\n",
            "Epoch: [0/2]  [4470/9200]  eta: 0:41:08  lr: 0.001000  loss: 183.0497 (195.6485)  time: 0.4492  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [4480/9200]  eta: 0:41:04  lr: 0.001000  loss: 174.8276 (195.6350)  time: 0.5225  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [4490/9200]  eta: 0:40:59  lr: 0.001000  loss: 186.4379 (195.5940)  time: 0.5610  data: 0.0044  max mem: 5844\n",
            "Epoch: [0/2]  [4500/9200]  eta: 0:40:53  lr: 0.001000  loss: 186.4379 (195.6002)  time: 0.5186  data: 0.0012  max mem: 5844\n",
            "Epoch: [0/2]  [4510/9200]  eta: 0:40:48  lr: 0.001000  loss: 189.1714 (195.5895)  time: 0.5132  data: 0.0018  max mem: 5844\n",
            "Epoch: [0/2]  [4520/9200]  eta: 0:40:43  lr: 0.001000  loss: 195.0605 (195.6329)  time: 0.5556  data: 0.0039  max mem: 5844\n",
            "Epoch: [0/2]  [4530/9200]  eta: 0:40:38  lr: 0.001000  loss: 192.7448 (195.6360)  time: 0.5520  data: 0.0026  max mem: 5844\n",
            "Epoch: [0/2]  [4540/9200]  eta: 0:40:32  lr: 0.001000  loss: 174.7916 (195.6163)  time: 0.4786  data: 0.0008  max mem: 5844\n",
            "Epoch: [0/2]  [4550/9200]  eta: 0:40:28  lr: 0.001000  loss: 167.4054 (195.5938)  time: 0.5268  data: 0.0032  max mem: 5844\n",
            "Epoch: [0/2]  [4560/9200]  eta: 0:40:23  lr: 0.001000  loss: 192.4035 (195.6234)  time: 0.5782  data: 0.0028  max mem: 5844\n",
            "Epoch: [0/2]  [4570/9200]  eta: 0:40:17  lr: 0.001000  loss: 167.8960 (195.5652)  time: 0.5131  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [4580/9200]  eta: 0:40:12  lr: 0.001000  loss: 148.1736 (195.5033)  time: 0.5124  data: 0.0036  max mem: 5844\n",
            "Epoch: [0/2]  [4590/9200]  eta: 0:40:07  lr: 0.001000  loss: 188.6656 (195.5955)  time: 0.5499  data: 0.0046  max mem: 5844\n",
            "Epoch: [0/2]  [4600/9200]  eta: 0:40:02  lr: 0.001000  loss: 201.1605 (195.5486)  time: 0.5359  data: 0.0013  max mem: 5844\n",
            "Epoch: [0/2]  [4610/9200]  eta: 0:39:57  lr: 0.001000  loss: 187.3171 (195.5645)  time: 0.5243  data: 0.0023  max mem: 5844\n",
            "Epoch: [0/2]  [4620/9200]  eta: 0:39:52  lr: 0.001000  loss: 208.7277 (195.6465)  time: 0.5540  data: 0.0046  max mem: 5844\n",
            "Epoch: [0/2]  [4630/9200]  eta: 0:39:46  lr: 0.001000  loss: 198.8749 (195.6137)  time: 0.5203  data: 0.0024  max mem: 5844\n",
            "Epoch: [0/2]  [4640/9200]  eta: 0:39:40  lr: 0.001000  loss: 176.8686 (195.6254)  time: 0.4541  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [4650/9200]  eta: 0:39:36  lr: 0.001000  loss: 184.5223 (195.6312)  time: 0.5474  data: 0.0039  max mem: 5844\n",
            "Epoch: [0/2]  [4660/9200]  eta: 0:39:30  lr: 0.001000  loss: 184.5223 (195.6280)  time: 0.5397  data: 0.0036  max mem: 5844\n",
            "Epoch: [0/2]  [4670/9200]  eta: 0:39:24  lr: 0.001000  loss: 183.5385 (195.5838)  time: 0.4324  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [4680/9200]  eta: 0:39:19  lr: 0.001000  loss: 176.6270 (195.5910)  time: 0.4822  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [4690/9200]  eta: 0:39:14  lr: 0.001000  loss: 174.4093 (195.5517)  time: 0.5213  data: 0.0048  max mem: 5844\n",
            "Epoch: [0/2]  [4700/9200]  eta: 0:39:08  lr: 0.001000  loss: 169.1321 (195.5440)  time: 0.4843  data: 0.0016  max mem: 5844\n",
            "Epoch: [0/2]  [4710/9200]  eta: 0:39:02  lr: 0.001000  loss: 179.3462 (195.5367)  time: 0.4658  data: 0.0012  max mem: 5844\n",
            "Epoch: [0/2]  [4720/9200]  eta: 0:38:57  lr: 0.001000  loss: 163.4519 (195.4749)  time: 0.5066  data: 0.0048  max mem: 5844\n",
            "Epoch: [0/2]  [4730/9200]  eta: 0:38:52  lr: 0.001000  loss: 163.4519 (195.4375)  time: 0.5178  data: 0.0037  max mem: 5844\n",
            "Epoch: [0/2]  [4740/9200]  eta: 0:38:46  lr: 0.001000  loss: 170.7548 (195.4249)  time: 0.4691  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [4750/9200]  eta: 0:38:41  lr: 0.001000  loss: 174.8993 (195.4070)  time: 0.4834  data: 0.0028  max mem: 5844\n",
            "Epoch: [0/2]  [4760/9200]  eta: 0:38:35  lr: 0.001000  loss: 160.3424 (195.3845)  time: 0.5229  data: 0.0052  max mem: 5844\n",
            "Epoch: [0/2]  [4770/9200]  eta: 0:38:29  lr: 0.001000  loss: 156.5970 (195.3496)  time: 0.4752  data: 0.0029  max mem: 5844\n",
            "Epoch: [0/2]  [4780/9200]  eta: 0:38:24  lr: 0.001000  loss: 182.0873 (195.3544)  time: 0.4650  data: 0.0008  max mem: 5844\n",
            "Epoch: [0/2]  [4790/9200]  eta: 0:38:19  lr: 0.001000  loss: 179.2141 (195.3068)  time: 0.5282  data: 0.0041  max mem: 5844\n",
            "Epoch: [0/2]  [4800/9200]  eta: 0:38:14  lr: 0.001000  loss: 187.0181 (195.4073)  time: 0.5456  data: 0.0038  max mem: 5844\n",
            "Epoch: [0/2]  [4810/9200]  eta: 0:38:08  lr: 0.001000  loss: 207.0491 (195.4282)  time: 0.4917  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [4820/9200]  eta: 0:38:03  lr: 0.001000  loss: 180.4521 (195.4329)  time: 0.4913  data: 0.0024  max mem: 5844\n",
            "Epoch: [0/2]  [4830/9200]  eta: 0:37:58  lr: 0.001000  loss: 179.4677 (195.4419)  time: 0.5427  data: 0.0041  max mem: 5844\n",
            "Epoch: [0/2]  [4840/9200]  eta: 0:37:52  lr: 0.001000  loss: 189.0121 (195.4342)  time: 0.5040  data: 0.0019  max mem: 5844\n",
            "Epoch: [0/2]  [4850/9200]  eta: 0:37:47  lr: 0.001000  loss: 189.4390 (195.4455)  time: 0.4804  data: 0.0008  max mem: 5844\n",
            "Epoch: [0/2]  [4860/9200]  eta: 0:37:42  lr: 0.001000  loss: 183.8047 (195.4313)  time: 0.5292  data: 0.0035  max mem: 5844\n",
            "Epoch: [0/2]  [4870/9200]  eta: 0:37:36  lr: 0.001000  loss: 194.8573 (195.4331)  time: 0.4946  data: 0.0029  max mem: 5844\n",
            "Epoch: [0/2]  [4880/9200]  eta: 0:37:31  lr: 0.001000  loss: 185.4301 (195.3917)  time: 0.4818  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [4890/9200]  eta: 0:37:26  lr: 0.001000  loss: 163.2294 (195.3433)  time: 0.5472  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [4900/9200]  eta: 0:37:21  lr: 0.001000  loss: 202.2307 (195.3998)  time: 0.5611  data: 0.0044  max mem: 5844\n",
            "Epoch: [0/2]  [4910/9200]  eta: 0:37:16  lr: 0.001000  loss: 209.9694 (195.3954)  time: 0.5212  data: 0.0013  max mem: 5844\n",
            "Epoch: [0/2]  [4920/9200]  eta: 0:37:11  lr: 0.001000  loss: 183.8395 (195.4097)  time: 0.5459  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [4930/9200]  eta: 0:37:06  lr: 0.001000  loss: 199.0599 (195.3995)  time: 0.5519  data: 0.0051  max mem: 5844\n",
            "Epoch: [0/2]  [4940/9200]  eta: 0:37:00  lr: 0.001000  loss: 198.4447 (195.4284)  time: 0.4949  data: 0.0019  max mem: 5844\n",
            "Epoch: [0/2]  [4950/9200]  eta: 0:36:56  lr: 0.001000  loss: 198.4447 (195.4560)  time: 0.5464  data: 0.0015  max mem: 5844\n",
            "Epoch: [0/2]  [4960/9200]  eta: 0:36:50  lr: 0.001000  loss: 184.5071 (195.4374)  time: 0.5564  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [4970/9200]  eta: 0:36:45  lr: 0.001000  loss: 184.5071 (195.4460)  time: 0.5127  data: 0.0021  max mem: 5844\n",
            "Epoch: [0/2]  [4980/9200]  eta: 0:36:40  lr: 0.001000  loss: 192.3947 (195.4586)  time: 0.5068  data: 0.0013  max mem: 5844\n",
            "Epoch: [0/2]  [4990/9200]  eta: 0:36:35  lr: 0.001000  loss: 188.5918 (195.4649)  time: 0.5295  data: 0.0035  max mem: 5844\n",
            "Epoch: [0/2]  [5000/9200]  eta: 0:36:29  lr: 0.001000  loss: 188.5918 (195.4760)  time: 0.5153  data: 0.0024  max mem: 5844\n",
            "Epoch: [0/2]  [5010/9200]  eta: 0:36:24  lr: 0.001000  loss: 207.9077 (195.4842)  time: 0.5035  data: 0.0015  max mem: 5844\n",
            "Epoch: [0/2]  [5020/9200]  eta: 0:36:19  lr: 0.001000  loss: 184.5480 (195.4252)  time: 0.5605  data: 0.0057  max mem: 5844\n",
            "Epoch: [0/2]  [5030/9200]  eta: 0:36:14  lr: 0.001000  loss: 182.8067 (195.4643)  time: 0.5285  data: 0.0044  max mem: 5844\n",
            "Epoch: [0/2]  [5040/9200]  eta: 0:36:08  lr: 0.001000  loss: 199.0628 (195.5415)  time: 0.4942  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [5050/9200]  eta: 0:36:04  lr: 0.001000  loss: 196.3225 (195.5041)  time: 0.5387  data: 0.0040  max mem: 5844\n",
            "Epoch: [0/2]  [5060/9200]  eta: 0:35:58  lr: 0.001000  loss: 169.6922 (195.4504)  time: 0.5107  data: 0.0048  max mem: 5844\n",
            "Epoch: [0/2]  [5070/9200]  eta: 0:35:52  lr: 0.001000  loss: 173.0808 (195.3955)  time: 0.4431  data: 0.0011  max mem: 5844\n",
            "Epoch: [0/2]  [5080/9200]  eta: 0:35:47  lr: 0.001000  loss: 178.2280 (195.4057)  time: 0.4627  data: 0.0012  max mem: 5844\n",
            "Epoch: [0/2]  [5090/9200]  eta: 0:35:41  lr: 0.001000  loss: 191.6004 (195.3974)  time: 0.5147  data: 0.0040  max mem: 5844\n",
            "Epoch: [0/2]  [5100/9200]  eta: 0:35:36  lr: 0.001000  loss: 184.9681 (195.3910)  time: 0.4855  data: 0.0030  max mem: 5844\n",
            "Epoch: [0/2]  [5110/9200]  eta: 0:35:30  lr: 0.001000  loss: 183.7905 (195.3746)  time: 0.4503  data: 0.0004  max mem: 5844\n",
            "Epoch: [0/2]  [5120/9200]  eta: 0:35:25  lr: 0.001000  loss: 183.0101 (195.3754)  time: 0.5324  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [5130/9200]  eta: 0:35:20  lr: 0.001000  loss: 173.7899 (195.3492)  time: 0.5464  data: 0.0045  max mem: 5844\n",
            "Epoch: [0/2]  [5140/9200]  eta: 0:35:15  lr: 0.001000  loss: 199.4306 (195.4109)  time: 0.5186  data: 0.0015  max mem: 5844\n",
            "Epoch: [0/2]  [5150/9200]  eta: 0:35:10  lr: 0.001000  loss: 199.4306 (195.4016)  time: 0.5653  data: 0.0026  max mem: 5844\n",
            "Epoch: [0/2]  [5160/9200]  eta: 0:35:05  lr: 0.001000  loss: 177.3518 (195.3359)  time: 0.5578  data: 0.0036  max mem: 5844\n",
            "Epoch: [0/2]  [5170/9200]  eta: 0:35:00  lr: 0.001000  loss: 187.6758 (195.3960)  time: 0.5445  data: 0.0012  max mem: 5844\n",
            "Epoch: [0/2]  [5180/9200]  eta: 0:34:55  lr: 0.001000  loss: 187.0151 (195.3529)  time: 0.5541  data: 0.0033  max mem: 5844\n",
            "Epoch: [0/2]  [5190/9200]  eta: 0:34:50  lr: 0.001000  loss: 171.4758 (195.3593)  time: 0.5641  data: 0.0056  max mem: 5844\n",
            "Epoch: [0/2]  [5200/9200]  eta: 0:34:45  lr: 0.001000  loss: 194.6155 (195.3737)  time: 0.5571  data: 0.0025  max mem: 5844\n",
            "Epoch: [0/2]  [5210/9200]  eta: 0:34:40  lr: 0.001000  loss: 182.6654 (195.3770)  time: 0.5588  data: 0.0018  max mem: 5844\n",
            "Epoch: [0/2]  [5220/9200]  eta: 0:34:35  lr: 0.001000  loss: 177.8865 (195.3670)  time: 0.5649  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [5230/9200]  eta: 0:34:30  lr: 0.001000  loss: 162.0215 (195.3025)  time: 0.4975  data: 0.0019  max mem: 5844\n",
            "Epoch: [0/2]  [5240/9200]  eta: 0:34:25  lr: 0.001000  loss: 184.8830 (195.3088)  time: 0.5014  data: 0.0019  max mem: 5844\n",
            "Epoch: [0/2]  [5250/9200]  eta: 0:34:20  lr: 0.001000  loss: 196.7042 (195.3238)  time: 0.5997  data: 0.0052  max mem: 5844\n",
            "Epoch: [0/2]  [5260/9200]  eta: 0:34:15  lr: 0.001000  loss: 178.4720 (195.3125)  time: 0.5935  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [5270/9200]  eta: 0:34:10  lr: 0.001000  loss: 165.5441 (195.2768)  time: 0.5125  data: 0.0004  max mem: 5844\n",
            "Epoch: [0/2]  [5280/9200]  eta: 0:34:05  lr: 0.001000  loss: 165.7011 (195.2344)  time: 0.5249  data: 0.0035  max mem: 5844\n",
            "Epoch: [0/2]  [5290/9200]  eta: 0:33:59  lr: 0.001000  loss: 177.0933 (195.2163)  time: 0.5280  data: 0.0039  max mem: 5844\n",
            "Epoch: [0/2]  [5300/9200]  eta: 0:33:54  lr: 0.001000  loss: 173.5694 (195.2054)  time: 0.4550  data: 0.0008  max mem: 5844\n",
            "Epoch: [0/2]  [5310/9200]  eta: 0:33:49  lr: 0.001000  loss: 173.5694 (195.2274)  time: 0.5207  data: 0.0023  max mem: 5844\n",
            "Epoch: [0/2]  [5320/9200]  eta: 0:33:44  lr: 0.001000  loss: 185.5756 (195.2458)  time: 0.5767  data: 0.0032  max mem: 5844\n",
            "Epoch: [0/2]  [5330/9200]  eta: 0:33:39  lr: 0.001000  loss: 176.4055 (195.2013)  time: 0.5245  data: 0.0012  max mem: 5844\n",
            "Epoch: [0/2]  [5340/9200]  eta: 0:33:34  lr: 0.001000  loss: 170.1832 (195.1656)  time: 0.5697  data: 0.0022  max mem: 5844\n",
            "Epoch: [0/2]  [5350/9200]  eta: 0:33:29  lr: 0.001000  loss: 174.4578 (195.1548)  time: 0.5644  data: 0.0024  max mem: 5844\n",
            "Epoch: [0/2]  [5360/9200]  eta: 0:33:23  lr: 0.001000  loss: 178.1835 (195.1638)  time: 0.4907  data: 0.0006  max mem: 5844\n",
            "Epoch: [0/2]  [5370/9200]  eta: 0:33:18  lr: 0.001000  loss: 182.8120 (195.1550)  time: 0.5239  data: 0.0019  max mem: 5844\n",
            "Epoch: [0/2]  [5380/9200]  eta: 0:33:14  lr: 0.001000  loss: 200.7413 (195.1903)  time: 0.5892  data: 0.0040  max mem: 5844\n",
            "Epoch: [0/2]  [5390/9200]  eta: 0:33:08  lr: 0.001000  loss: 187.3202 (195.1369)  time: 0.5500  data: 0.0023  max mem: 5844\n",
            "Epoch: [0/2]  [5400/9200]  eta: 0:33:03  lr: 0.001000  loss: 143.1305 (195.0897)  time: 0.4897  data: 0.0011  max mem: 5844\n",
            "Epoch: [0/2]  [5410/9200]  eta: 0:32:58  lr: 0.001000  loss: 157.1479 (195.0587)  time: 0.5311  data: 0.0043  max mem: 5844\n",
            "Epoch: [0/2]  [5420/9200]  eta: 0:32:53  lr: 0.001000  loss: 172.0654 (195.0580)  time: 0.5364  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [5430/9200]  eta: 0:32:47  lr: 0.001000  loss: 200.9483 (195.1101)  time: 0.5102  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [5440/9200]  eta: 0:32:43  lr: 0.001000  loss: 199.9143 (195.1144)  time: 0.5518  data: 0.0039  max mem: 5844\n",
            "Epoch: [0/2]  [5450/9200]  eta: 0:32:37  lr: 0.001000  loss: 181.6181 (195.0622)  time: 0.5314  data: 0.0050  max mem: 5844\n",
            "Epoch: [0/2]  [5460/9200]  eta: 0:32:31  lr: 0.001000  loss: 159.3733 (195.0093)  time: 0.4592  data: 0.0017  max mem: 5844\n",
            "Epoch: [0/2]  [5470/9200]  eta: 0:32:26  lr: 0.001000  loss: 176.6890 (195.0101)  time: 0.5082  data: 0.0014  max mem: 5844\n",
            "Epoch: [0/2]  [5480/9200]  eta: 0:32:21  lr: 0.001000  loss: 199.5700 (195.0346)  time: 0.5529  data: 0.0040  max mem: 5844\n",
            "Epoch: [0/2]  [5490/9200]  eta: 0:32:16  lr: 0.001000  loss: 191.0832 (195.0290)  time: 0.5141  data: 0.0028  max mem: 5844\n",
            "Epoch: [0/2]  [5500/9200]  eta: 0:32:11  lr: 0.001000  loss: 178.6169 (195.0331)  time: 0.5050  data: 0.0006  max mem: 5844\n",
            "Epoch: [0/2]  [5510/9200]  eta: 0:32:06  lr: 0.001000  loss: 169.8295 (194.9770)  time: 0.5219  data: 0.0022  max mem: 5844\n",
            "Epoch: [0/2]  [5520/9200]  eta: 0:32:00  lr: 0.001000  loss: 169.8335 (194.9827)  time: 0.5074  data: 0.0018  max mem: 5844\n",
            "Epoch: [0/2]  [5530/9200]  eta: 0:31:55  lr: 0.001000  loss: 187.9387 (194.9626)  time: 0.4852  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [5540/9200]  eta: 0:31:50  lr: 0.001000  loss: 187.9387 (194.9811)  time: 0.5587  data: 0.0016  max mem: 5844\n",
            "Epoch: [0/2]  [5550/9200]  eta: 0:31:45  lr: 0.001000  loss: 172.9052 (194.9585)  time: 0.5508  data: 0.0026  max mem: 5844\n",
            "Epoch: [0/2]  [5560/9200]  eta: 0:31:39  lr: 0.001000  loss: 162.0524 (194.9287)  time: 0.4617  data: 0.0018  max mem: 5844\n",
            "Epoch: [0/2]  [5570/9200]  eta: 0:31:34  lr: 0.001000  loss: 183.7434 (194.9531)  time: 0.4896  data: 0.0022  max mem: 5844\n",
            "Epoch: [0/2]  [5580/9200]  eta: 0:31:29  lr: 0.001000  loss: 183.7434 (194.9272)  time: 0.5565  data: 0.0049  max mem: 5844\n",
            "Epoch: [0/2]  [5590/9200]  eta: 0:31:23  lr: 0.001000  loss: 179.2639 (194.9144)  time: 0.5237  data: 0.0035  max mem: 5844\n",
            "Epoch: [0/2]  [5600/9200]  eta: 0:31:17  lr: 0.001000  loss: 167.4717 (194.8472)  time: 0.4385  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [5610/9200]  eta: 0:31:12  lr: 0.001000  loss: 166.9858 (194.8396)  time: 0.4803  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [5620/9200]  eta: 0:31:07  lr: 0.001000  loss: 188.0072 (194.8349)  time: 0.5381  data: 0.0047  max mem: 5844\n",
            "Epoch: [0/2]  [5630/9200]  eta: 0:31:02  lr: 0.001000  loss: 182.2795 (194.8154)  time: 0.5011  data: 0.0016  max mem: 5844\n",
            "Epoch: [0/2]  [5640/9200]  eta: 0:30:56  lr: 0.001000  loss: 162.3631 (194.8150)  time: 0.4888  data: 0.0010  max mem: 5844\n",
            "Epoch: [0/2]  [5650/9200]  eta: 0:30:51  lr: 0.001000  loss: 157.5732 (194.7957)  time: 0.5357  data: 0.0032  max mem: 5844\n",
            "Epoch: [0/2]  [5660/9200]  eta: 0:30:46  lr: 0.001000  loss: 182.1581 (194.8049)  time: 0.5352  data: 0.0023  max mem: 5844\n",
            "Epoch: [0/2]  [5670/9200]  eta: 0:30:41  lr: 0.001000  loss: 213.7366 (194.8274)  time: 0.5285  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [5680/9200]  eta: 0:30:36  lr: 0.001000  loss: 193.6037 (194.8184)  time: 0.5821  data: 0.0038  max mem: 5844\n",
            "Epoch: [0/2]  [5690/9200]  eta: 0:30:31  lr: 0.001000  loss: 187.7549 (194.8507)  time: 0.5632  data: 0.0041  max mem: 5844\n",
            "Epoch: [0/2]  [5700/9200]  eta: 0:30:25  lr: 0.001000  loss: 180.9517 (194.8107)  time: 0.4854  data: 0.0012  max mem: 5844\n",
            "Epoch: [0/2]  [5710/9200]  eta: 0:30:21  lr: 0.001000  loss: 175.2630 (194.8087)  time: 0.5444  data: 0.0026  max mem: 5844\n",
            "Epoch: [0/2]  [5720/9200]  eta: 0:30:16  lr: 0.001000  loss: 186.3636 (194.8063)  time: 0.5820  data: 0.0026  max mem: 5844\n",
            "Epoch: [0/2]  [5730/9200]  eta: 0:30:10  lr: 0.001000  loss: 182.1128 (194.7838)  time: 0.5192  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [5740/9200]  eta: 0:30:05  lr: 0.001000  loss: 205.2083 (194.8029)  time: 0.5322  data: 0.0020  max mem: 5844\n",
            "Epoch: [0/2]  [5750/9200]  eta: 0:30:00  lr: 0.001000  loss: 195.7863 (194.7695)  time: 0.5387  data: 0.0038  max mem: 5844\n",
            "Epoch: [0/2]  [5760/9200]  eta: 0:29:55  lr: 0.001000  loss: 178.3719 (194.7828)  time: 0.4983  data: 0.0019  max mem: 5844\n",
            "Epoch: [0/2]  [5770/9200]  eta: 0:29:49  lr: 0.001000  loss: 173.8050 (194.7559)  time: 0.4732  data: 0.0014  max mem: 5844\n",
            "Epoch: [0/2]  [5780/9200]  eta: 0:29:44  lr: 0.001000  loss: 173.8050 (194.7561)  time: 0.5069  data: 0.0031  max mem: 5844\n",
            "Epoch: [0/2]  [5790/9200]  eta: 0:29:39  lr: 0.001000  loss: 177.7037 (194.7171)  time: 0.5093  data: 0.0019  max mem: 5844\n",
            "Epoch: [0/2]  [5800/9200]  eta: 0:29:33  lr: 0.001000  loss: 171.5961 (194.6967)  time: 0.4845  data: 0.0009  max mem: 5844\n",
            "Epoch: [0/2]  [5810/9200]  eta: 0:29:28  lr: 0.001000  loss: 171.5857 (194.6669)  time: 0.5081  data: 0.0039  max mem: 5844\n",
            "Epoch: [0/2]  [5820/9200]  eta: 0:29:23  lr: 0.001000  loss: 168.5174 (194.6431)  time: 0.5020  data: 0.0045  max mem: 5844\n",
            "Epoch: [0/2]  [5830/9200]  eta: 0:29:17  lr: 0.001000  loss: 186.8301 (194.6942)  time: 0.4957  data: 0.0016  max mem: 5844\n",
            "Epoch: [0/2]  [5840/9200]  eta: 0:29:12  lr: 0.001000  loss: 186.8301 (194.6885)  time: 0.5279  data: 0.0021  max mem: 5844\n",
            "Epoch: [0/2]  [5850/9200]  eta: 0:29:07  lr: 0.001000  loss: 196.2005 (194.7032)  time: 0.5392  data: 0.0044  max mem: 5844\n",
            "Epoch: [0/2]  [5860/9200]  eta: 0:29:02  lr: 0.001000  loss: 196.7624 (194.6966)  time: 0.5195  data: 0.0025  max mem: 5844\n",
            "Epoch: [0/2]  [5870/9200]  eta: 0:28:57  lr: 0.001000  loss: 158.7919 (194.6838)  time: 0.5236  data: 0.0009  max mem: 5844\n",
            "Epoch: [0/2]  [5880/9200]  eta: 0:28:52  lr: 0.001000  loss: 183.0697 (194.7117)  time: 0.5593  data: 0.0035  max mem: 5844\n",
            "Epoch: [0/2]  [5890/9200]  eta: 0:28:46  lr: 0.001000  loss: 198.2849 (194.7095)  time: 0.5461  data: 0.0027  max mem: 5844\n",
            "Epoch: [0/2]  [5900/9200]  eta: 0:28:41  lr: 0.001000  loss: 188.8457 (194.6868)  time: 0.5209  data: 0.0014  max mem: 5844\n",
            "Epoch: [0/2]  [5910/9200]  eta: 0:28:36  lr: 0.001000  loss: 169.3624 (194.6535)  time: 0.5478  data: 0.0044  max mem: 5844\n",
            "Epoch: [0/2]  [5920/9200]  eta: 0:28:31  lr: 0.001000  loss: 170.2966 (194.6278)  time: 0.5255  data: 0.0032  max mem: 5844\n",
            "Epoch: [0/2]  [5930/9200]  eta: 0:28:26  lr: 0.001000  loss: 172.7507 (194.6329)  time: 0.5220  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [5940/9200]  eta: 0:28:21  lr: 0.001000  loss: 172.7507 (194.5909)  time: 0.5478  data: 0.0032  max mem: 5844\n",
            "Epoch: [0/2]  [5950/9200]  eta: 0:28:15  lr: 0.001000  loss: 160.3248 (194.5341)  time: 0.4797  data: 0.0042  max mem: 5844\n",
            "Epoch: [0/2]  [5960/9200]  eta: 0:28:10  lr: 0.001000  loss: 164.7894 (194.5502)  time: 0.4712  data: 0.0015  max mem: 5844\n",
            "Epoch: [0/2]  [5970/9200]  eta: 0:28:05  lr: 0.001000  loss: 168.1819 (194.5021)  time: 0.5211  data: 0.0021  max mem: 5844\n",
            "Epoch: [0/2]  [5980/9200]  eta: 0:27:59  lr: 0.001000  loss: 170.0356 (194.4840)  time: 0.5256  data: 0.0056  max mem: 5844\n",
            "Epoch: [0/2]  [5990/9200]  eta: 0:27:54  lr: 0.001000  loss: 192.8252 (194.4957)  time: 0.5091  data: 0.0038  max mem: 5844\n",
            "Epoch: [0/2]  [6000/9200]  eta: 0:27:49  lr: 0.001000  loss: 192.5652 (194.4910)  time: 0.4854  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [6010/9200]  eta: 0:27:44  lr: 0.001000  loss: 166.9922 (194.4276)  time: 0.5297  data: 0.0033  max mem: 5844\n",
            "Epoch: [0/2]  [6020/9200]  eta: 0:27:38  lr: 0.001000  loss: 164.0446 (194.4562)  time: 0.5406  data: 0.0038  max mem: 5844\n",
            "Epoch: [0/2]  [6030/9200]  eta: 0:27:33  lr: 0.001000  loss: 184.3673 (194.4611)  time: 0.4808  data: 0.0009  max mem: 5844\n",
            "Epoch: [0/2]  [6040/9200]  eta: 0:27:28  lr: 0.001000  loss: 216.8184 (194.5135)  time: 0.5111  data: 0.0020  max mem: 5844\n",
            "Epoch: [0/2]  [6050/9200]  eta: 0:27:23  lr: 0.001000  loss: 209.8714 (194.5198)  time: 0.5581  data: 0.0044  max mem: 5844\n",
            "Epoch: [0/2]  [6060/9200]  eta: 0:27:17  lr: 0.001000  loss: 186.2911 (194.4988)  time: 0.5059  data: 0.0026  max mem: 5844\n",
            "Epoch: [0/2]  [6070/9200]  eta: 0:27:12  lr: 0.001000  loss: 180.8968 (194.4677)  time: 0.4530  data: 0.0006  max mem: 5844\n",
            "Epoch: [0/2]  [6080/9200]  eta: 0:27:07  lr: 0.001000  loss: 187.2696 (194.4879)  time: 0.5074  data: 0.0043  max mem: 5844\n",
            "Epoch: [0/2]  [6090/9200]  eta: 0:27:01  lr: 0.001000  loss: 189.9186 (194.4899)  time: 0.5132  data: 0.0044  max mem: 5844\n",
            "Epoch: [0/2]  [6100/9200]  eta: 0:26:56  lr: 0.001000  loss: 190.6778 (194.4976)  time: 0.4916  data: 0.0007  max mem: 5844\n",
            "Epoch: [0/2]  [6110/9200]  eta: 0:26:51  lr: 0.001000  loss: 172.2141 (194.4560)  time: 0.5570  data: 0.0036  max mem: 5844\n",
            "Epoch: [0/2]  [6120/9200]  eta: 0:26:46  lr: 0.001000  loss: 171.8680 (194.4437)  time: 0.5497  data: 0.0059  max mem: 5844\n",
            "Epoch: [0/2]  [6130/9200]  eta: 0:26:40  lr: 0.001000  loss: 191.0756 (194.4551)  time: 0.4845  data: 0.0025  max mem: 5844\n",
            "Epoch: [0/2]  [6140/9200]  eta: 0:26:35  lr: 0.001000  loss: 177.7014 (194.4410)  time: 0.4918  data: 0.0004  max mem: 5844\n",
            "Epoch: [0/2]  [6150/9200]  eta: 0:26:30  lr: 0.001000  loss: 188.6199 (194.4885)  time: 0.5653  data: 0.0028  max mem: 5844\n",
            "Epoch: [0/2]  [6160/9200]  eta: 0:26:25  lr: 0.001000  loss: 205.0386 (194.5010)  time: 0.5733  data: 0.0026  max mem: 5844\n",
            "Epoch: [0/2]  [6170/9200]  eta: 0:26:20  lr: 0.001000  loss: 205.0386 (194.5287)  time: 0.5694  data: 0.0013  max mem: 5844\n",
            "Epoch: [0/2]  [6180/9200]  eta: 0:26:15  lr: 0.001000  loss: 204.2426 (194.5430)  time: 0.5744  data: 0.0040  max mem: 5844\n",
            "Epoch: [0/2]  [6190/9200]  eta: 0:26:10  lr: 0.001000  loss: 180.0033 (194.5233)  time: 0.4940  data: 0.0029  max mem: 5844\n",
            "Epoch: [0/2]  [6200/9200]  eta: 0:26:04  lr: 0.001000  loss: 177.3281 (194.5071)  time: 0.4451  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [6210/9200]  eta: 0:25:59  lr: 0.001000  loss: 181.9076 (194.4967)  time: 0.4970  data: 0.0035  max mem: 5844\n",
            "Epoch: [0/2]  [6220/9200]  eta: 0:25:54  lr: 0.001000  loss: 188.4059 (194.5526)  time: 0.5319  data: 0.0045  max mem: 5844\n",
            "Epoch: [0/2]  [6230/9200]  eta: 0:25:48  lr: 0.001000  loss: 181.1130 (194.5231)  time: 0.5230  data: 0.0015  max mem: 5844\n",
            "Epoch: [0/2]  [6240/9200]  eta: 0:25:43  lr: 0.001000  loss: 164.5460 (194.4942)  time: 0.5215  data: 0.0026  max mem: 5844\n",
            "Epoch: [0/2]  [6250/9200]  eta: 0:25:38  lr: 0.001000  loss: 179.9237 (194.4942)  time: 0.5173  data: 0.0040  max mem: 5844\n",
            "Epoch: [0/2]  [6260/9200]  eta: 0:25:32  lr: 0.001000  loss: 177.8078 (194.4836)  time: 0.4871  data: 0.0016  max mem: 5844\n",
            "Epoch: [0/2]  [6270/9200]  eta: 0:25:27  lr: 0.001000  loss: 158.0560 (194.4372)  time: 0.4528  data: 0.0010  max mem: 5844\n",
            "Epoch: [0/2]  [6280/9200]  eta: 0:25:22  lr: 0.001000  loss: 176.4350 (194.4603)  time: 0.5256  data: 0.0041  max mem: 5844\n",
            "Epoch: [0/2]  [6290/9200]  eta: 0:25:16  lr: 0.001000  loss: 179.1368 (194.4207)  time: 0.5202  data: 0.0033  max mem: 5844\n",
            "Epoch: [0/2]  [6300/9200]  eta: 0:25:11  lr: 0.001000  loss: 197.1037 (194.4457)  time: 0.4990  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [6310/9200]  eta: 0:25:06  lr: 0.001000  loss: 197.1037 (194.4100)  time: 0.5546  data: 0.0026  max mem: 5844\n",
            "Epoch: [0/2]  [6320/9200]  eta: 0:25:01  lr: 0.001000  loss: 164.4312 (194.3701)  time: 0.5349  data: 0.0032  max mem: 5844\n",
            "Epoch: [0/2]  [6330/9200]  eta: 0:24:56  lr: 0.001000  loss: 172.6134 (194.3504)  time: 0.5065  data: 0.0011  max mem: 5844\n",
            "Epoch: [0/2]  [6340/9200]  eta: 0:24:51  lr: 0.001000  loss: 182.1524 (194.3344)  time: 0.5330  data: 0.0023  max mem: 5844\n",
            "Epoch: [0/2]  [6350/9200]  eta: 0:24:46  lr: 0.001000  loss: 187.1216 (194.3186)  time: 0.5468  data: 0.0052  max mem: 5844\n",
            "Epoch: [0/2]  [6360/9200]  eta: 0:24:40  lr: 0.001000  loss: 185.6673 (194.2932)  time: 0.4989  data: 0.0033  max mem: 5844\n",
            "Epoch: [0/2]  [6370/9200]  eta: 0:24:35  lr: 0.001000  loss: 161.7912 (194.2411)  time: 0.4690  data: 0.0004  max mem: 5844\n",
            "Epoch: [0/2]  [6380/9200]  eta: 0:24:30  lr: 0.001000  loss: 161.7912 (194.2287)  time: 0.5183  data: 0.0035  max mem: 5844\n",
            "Epoch: [0/2]  [6390/9200]  eta: 0:24:24  lr: 0.001000  loss: 188.6635 (194.2769)  time: 0.5389  data: 0.0039  max mem: 5844\n",
            "Epoch: [0/2]  [6400/9200]  eta: 0:24:19  lr: 0.001000  loss: 188.6635 (194.2731)  time: 0.4984  data: 0.0006  max mem: 5844\n",
            "Epoch: [0/2]  [6410/9200]  eta: 0:24:14  lr: 0.001000  loss: 178.5409 (194.2423)  time: 0.5286  data: 0.0022  max mem: 5844\n",
            "Epoch: [0/2]  [6420/9200]  eta: 0:24:09  lr: 0.001000  loss: 157.6196 (194.2559)  time: 0.5203  data: 0.0044  max mem: 5844\n",
            "Epoch: [0/2]  [6430/9200]  eta: 0:24:03  lr: 0.001000  loss: 164.0302 (194.2673)  time: 0.4765  data: 0.0024  max mem: 5844\n",
            "Epoch: [0/2]  [6440/9200]  eta: 0:23:58  lr: 0.001000  loss: 179.4635 (194.2655)  time: 0.4892  data: 0.0007  max mem: 5844\n",
            "Epoch: [0/2]  [6450/9200]  eta: 0:23:53  lr: 0.001000  loss: 192.3467 (194.2536)  time: 0.5237  data: 0.0037  max mem: 5844\n",
            "Epoch: [0/2]  [6460/9200]  eta: 0:23:48  lr: 0.001000  loss: 198.8309 (194.2695)  time: 0.5220  data: 0.0032  max mem: 5844\n",
            "Epoch: [0/2]  [6470/9200]  eta: 0:23:42  lr: 0.001000  loss: 191.9782 (194.2480)  time: 0.5237  data: 0.0009  max mem: 5844\n",
            "Epoch: [0/2]  [6480/9200]  eta: 0:23:37  lr: 0.001000  loss: 188.2886 (194.2390)  time: 0.5556  data: 0.0044  max mem: 5844\n",
            "Epoch: [0/2]  [6490/9200]  eta: 0:23:32  lr: 0.001000  loss: 202.2368 (194.2512)  time: 0.5410  data: 0.0043  max mem: 5844\n",
            "Epoch: [0/2]  [6500/9200]  eta: 0:23:27  lr: 0.001000  loss: 208.8665 (194.3048)  time: 0.5174  data: 0.0008  max mem: 5844\n",
            "Epoch: [0/2]  [6510/9200]  eta: 0:23:22  lr: 0.001000  loss: 208.8665 (194.3237)  time: 0.5651  data: 0.0031  max mem: 5844\n",
            "Epoch: [0/2]  [6520/9200]  eta: 0:23:17  lr: 0.001000  loss: 173.6737 (194.2841)  time: 0.5393  data: 0.0041  max mem: 5844\n",
            "Epoch: [0/2]  [6530/9200]  eta: 0:23:11  lr: 0.001000  loss: 173.6737 (194.2751)  time: 0.4888  data: 0.0013  max mem: 5844\n",
            "Epoch: [0/2]  [6540/9200]  eta: 0:23:06  lr: 0.001000  loss: 178.9821 (194.2519)  time: 0.5380  data: 0.0018  max mem: 5844\n",
            "Epoch: [0/2]  [6550/9200]  eta: 0:23:01  lr: 0.001000  loss: 167.1412 (194.2148)  time: 0.5432  data: 0.0046  max mem: 5844\n",
            "Epoch: [0/2]  [6560/9200]  eta: 0:22:56  lr: 0.001000  loss: 183.5314 (194.2283)  time: 0.5225  data: 0.0031  max mem: 5844\n",
            "Epoch: [0/2]  [6570/9200]  eta: 0:22:51  lr: 0.001000  loss: 168.6698 (194.1945)  time: 0.5000  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [6580/9200]  eta: 0:22:46  lr: 0.001000  loss: 185.2704 (194.2468)  time: 0.5582  data: 0.0031  max mem: 5844\n",
            "Epoch: [0/2]  [6590/9200]  eta: 0:22:40  lr: 0.001000  loss: 206.4225 (194.2508)  time: 0.5553  data: 0.0028  max mem: 5844\n",
            "Epoch: [0/2]  [6600/9200]  eta: 0:22:35  lr: 0.001000  loss: 197.1831 (194.2422)  time: 0.4974  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [6610/9200]  eta: 0:22:30  lr: 0.001000  loss: 197.1831 (194.2565)  time: 0.5624  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [6620/9200]  eta: 0:22:25  lr: 0.001000  loss: 165.8297 (194.2026)  time: 0.5472  data: 0.0036  max mem: 5844\n",
            "Epoch: [0/2]  [6630/9200]  eta: 0:22:19  lr: 0.001000  loss: 152.2129 (194.1518)  time: 0.4694  data: 0.0008  max mem: 5844\n",
            "Epoch: [0/2]  [6640/9200]  eta: 0:22:14  lr: 0.001000  loss: 159.8637 (194.1537)  time: 0.5010  data: 0.0027  max mem: 5844\n",
            "Epoch: [0/2]  [6650/9200]  eta: 0:22:09  lr: 0.001000  loss: 174.8988 (194.1925)  time: 0.5434  data: 0.0032  max mem: 5844\n",
            "Epoch: [0/2]  [6660/9200]  eta: 0:22:04  lr: 0.001000  loss: 166.2702 (194.1692)  time: 0.5156  data: 0.0010  max mem: 5844\n",
            "Epoch: [0/2]  [6670/9200]  eta: 0:21:59  lr: 0.001000  loss: 172.6908 (194.1659)  time: 0.5063  data: 0.0023  max mem: 5844\n",
            "Epoch: [0/2]  [6680/9200]  eta: 0:21:54  lr: 0.001000  loss: 174.2550 (194.1349)  time: 0.5456  data: 0.0057  max mem: 5844\n",
            "Epoch: [0/2]  [6690/9200]  eta: 0:21:48  lr: 0.001000  loss: 166.5230 (194.0984)  time: 0.5137  data: 0.0037  max mem: 5844\n",
            "Epoch: [0/2]  [6700/9200]  eta: 0:21:43  lr: 0.001000  loss: 174.1783 (194.0993)  time: 0.4690  data: 0.0006  max mem: 5844\n",
            "Epoch: [0/2]  [6710/9200]  eta: 0:21:38  lr: 0.001000  loss: 164.4198 (194.0569)  time: 0.5303  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [6720/9200]  eta: 0:21:33  lr: 0.001000  loss: 179.7928 (194.0747)  time: 0.5641  data: 0.0033  max mem: 5844\n",
            "Epoch: [0/2]  [6730/9200]  eta: 0:21:27  lr: 0.001000  loss: 187.2523 (194.0580)  time: 0.5056  data: 0.0004  max mem: 5844\n",
            "Epoch: [0/2]  [6740/9200]  eta: 0:21:22  lr: 0.001000  loss: 167.2979 (194.0457)  time: 0.4958  data: 0.0025  max mem: 5844\n",
            "Epoch: [0/2]  [6750/9200]  eta: 0:21:17  lr: 0.001000  loss: 171.1914 (194.0368)  time: 0.5302  data: 0.0039  max mem: 5844\n",
            "Epoch: [0/2]  [6760/9200]  eta: 0:21:12  lr: 0.001000  loss: 171.1914 (193.9971)  time: 0.4964  data: 0.0015  max mem: 5844\n",
            "Epoch: [0/2]  [6770/9200]  eta: 0:21:07  lr: 0.001000  loss: 183.0865 (194.0049)  time: 0.5402  data: 0.0020  max mem: 5844\n",
            "Epoch: [0/2]  [6780/9200]  eta: 0:21:01  lr: 0.001000  loss: 184.0334 (193.9702)  time: 0.5725  data: 0.0042  max mem: 5844\n",
            "Epoch: [0/2]  [6790/9200]  eta: 0:20:56  lr: 0.001000  loss: 167.6618 (193.9683)  time: 0.4889  data: 0.0024  max mem: 5844\n",
            "Epoch: [0/2]  [6800/9200]  eta: 0:20:51  lr: 0.001000  loss: 176.5846 (193.9513)  time: 0.4727  data: 0.0006  max mem: 5844\n",
            "Epoch: [0/2]  [6810/9200]  eta: 0:20:46  lr: 0.001000  loss: 187.9724 (193.9583)  time: 0.5427  data: 0.0041  max mem: 5844\n",
            "Epoch: [0/2]  [6820/9200]  eta: 0:20:40  lr: 0.001000  loss: 170.5729 (193.9316)  time: 0.5183  data: 0.0041  max mem: 5844\n",
            "Epoch: [0/2]  [6830/9200]  eta: 0:20:35  lr: 0.001000  loss: 155.0876 (193.9049)  time: 0.4613  data: 0.0012  max mem: 5844\n",
            "Epoch: [0/2]  [6840/9200]  eta: 0:20:30  lr: 0.001000  loss: 178.4466 (193.8961)  time: 0.5149  data: 0.0036  max mem: 5844\n",
            "Epoch: [0/2]  [6850/9200]  eta: 0:20:25  lr: 0.001000  loss: 169.9474 (193.8635)  time: 0.5381  data: 0.0058  max mem: 5844\n",
            "Epoch: [0/2]  [6860/9200]  eta: 0:20:19  lr: 0.001000  loss: 173.6958 (193.8969)  time: 0.5333  data: 0.0032  max mem: 5844\n",
            "Epoch: [0/2]  [6870/9200]  eta: 0:20:14  lr: 0.001000  loss: 173.9046 (193.8927)  time: 0.5294  data: 0.0011  max mem: 5844\n",
            "Epoch: [0/2]  [6880/9200]  eta: 0:20:09  lr: 0.001000  loss: 163.8526 (193.8573)  time: 0.5289  data: 0.0045  max mem: 5844\n",
            "Epoch: [0/2]  [6890/9200]  eta: 0:20:04  lr: 0.001000  loss: 189.3788 (193.8660)  time: 0.5029  data: 0.0038  max mem: 5844\n",
            "Epoch: [0/2]  [6900/9200]  eta: 0:19:58  lr: 0.001000  loss: 192.5934 (193.9085)  time: 0.4744  data: 0.0003  max mem: 5844\n",
            "Epoch: [0/2]  [6910/9200]  eta: 0:19:53  lr: 0.001000  loss: 191.1313 (193.9154)  time: 0.5321  data: 0.0029  max mem: 5844\n",
            "Epoch: [0/2]  [6920/9200]  eta: 0:19:48  lr: 0.001000  loss: 182.4868 (193.9214)  time: 0.5616  data: 0.0036  max mem: 5844\n",
            "Epoch: [0/2]  [6930/9200]  eta: 0:19:43  lr: 0.001000  loss: 186.6270 (193.9237)  time: 0.5093  data: 0.0009  max mem: 5844\n",
            "Epoch: [0/2]  [6940/9200]  eta: 0:19:38  lr: 0.001000  loss: 202.7797 (194.0029)  time: 0.5447  data: 0.0016  max mem: 5844\n",
            "Epoch: [0/2]  [6950/9200]  eta: 0:19:33  lr: 0.001000  loss: 209.5731 (194.0118)  time: 0.5859  data: 0.0028  max mem: 5844\n",
            "Epoch: [0/2]  [6960/9200]  eta: 0:19:27  lr: 0.001000  loss: 200.9050 (194.0105)  time: 0.5159  data: 0.0014  max mem: 5844\n",
            "Epoch: [0/2]  [6970/9200]  eta: 0:19:22  lr: 0.001000  loss: 181.8694 (193.9711)  time: 0.4811  data: 0.0013  max mem: 5844\n",
            "Epoch: [0/2]  [6980/9200]  eta: 0:19:17  lr: 0.001000  loss: 181.8694 (193.9522)  time: 0.5017  data: 0.0033  max mem: 5844\n",
            "Epoch: [0/2]  [6990/9200]  eta: 0:19:12  lr: 0.001000  loss: 167.3759 (193.9357)  time: 0.5212  data: 0.0021  max mem: 5844\n",
            "Epoch: [0/2]  [7000/9200]  eta: 0:19:06  lr: 0.001000  loss: 159.1904 (193.9000)  time: 0.4878  data: 0.0012  max mem: 5844\n",
            "Epoch: [0/2]  [7010/9200]  eta: 0:19:01  lr: 0.001000  loss: 170.2655 (193.9013)  time: 0.5072  data: 0.0047  max mem: 5844\n",
            "Epoch: [0/2]  [7020/9200]  eta: 0:18:56  lr: 0.001000  loss: 206.6304 (193.9740)  time: 0.5528  data: 0.0041  max mem: 5844\n",
            "Epoch: [0/2]  [7030/9200]  eta: 0:18:51  lr: 0.001000  loss: 194.1636 (193.9584)  time: 0.5434  data: 0.0009  max mem: 5844\n",
            "Epoch: [0/2]  [7040/9200]  eta: 0:18:46  lr: 0.001000  loss: 167.1365 (193.9400)  time: 0.5443  data: 0.0038  max mem: 5844\n",
            "Epoch: [0/2]  [7050/9200]  eta: 0:18:40  lr: 0.001000  loss: 167.4536 (193.9294)  time: 0.5351  data: 0.0047  max mem: 5844\n",
            "Epoch: [0/2]  [7060/9200]  eta: 0:18:35  lr: 0.001000  loss: 193.9689 (193.9719)  time: 0.5315  data: 0.0018  max mem: 5844\n",
            "Epoch: [0/2]  [7070/9200]  eta: 0:18:30  lr: 0.001000  loss: 193.3699 (193.9487)  time: 0.5223  data: 0.0025  max mem: 5844\n",
            "Epoch: [0/2]  [7080/9200]  eta: 0:18:25  lr: 0.001000  loss: 173.5647 (193.9361)  time: 0.5006  data: 0.0043  max mem: 5844\n",
            "Epoch: [0/2]  [7090/9200]  eta: 0:18:20  lr: 0.001000  loss: 187.2964 (193.9651)  time: 0.4997  data: 0.0023  max mem: 5844\n",
            "Epoch: [0/2]  [7100/9200]  eta: 0:18:15  lr: 0.001000  loss: 189.6875 (193.9890)  time: 0.5449  data: 0.0014  max mem: 5844\n",
            "Epoch: [0/2]  [7110/9200]  eta: 0:18:09  lr: 0.001000  loss: 198.6228 (193.9907)  time: 0.5724  data: 0.0044  max mem: 5844\n",
            "Epoch: [0/2]  [7120/9200]  eta: 0:18:04  lr: 0.001000  loss: 187.2254 (194.0173)  time: 0.5211  data: 0.0031  max mem: 5844\n",
            "Epoch: [0/2]  [7130/9200]  eta: 0:17:59  lr: 0.001000  loss: 182.2184 (194.0057)  time: 0.4858  data: 0.0006  max mem: 5844\n",
            "Epoch: [0/2]  [7140/9200]  eta: 0:17:54  lr: 0.001000  loss: 161.7126 (193.9453)  time: 0.4973  data: 0.0040  max mem: 5844\n",
            "Epoch: [0/2]  [7150/9200]  eta: 0:17:48  lr: 0.001000  loss: 167.8557 (193.9257)  time: 0.4745  data: 0.0046  max mem: 5844\n",
            "Epoch: [0/2]  [7160/9200]  eta: 0:17:43  lr: 0.001000  loss: 203.7158 (193.9710)  time: 0.4820  data: 0.0012  max mem: 5844\n",
            "Epoch: [0/2]  [7170/9200]  eta: 0:17:38  lr: 0.001000  loss: 215.0090 (193.9890)  time: 0.5433  data: 0.0019  max mem: 5844\n",
            "Epoch: [0/2]  [7180/9200]  eta: 0:17:33  lr: 0.001000  loss: 194.8151 (193.9960)  time: 0.5563  data: 0.0043  max mem: 5844\n",
            "Epoch: [0/2]  [7190/9200]  eta: 0:17:27  lr: 0.001000  loss: 185.1856 (193.9711)  time: 0.4939  data: 0.0027  max mem: 5844\n",
            "Epoch: [0/2]  [7200/9200]  eta: 0:17:22  lr: 0.001000  loss: 169.5018 (193.9764)  time: 0.4767  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [7210/9200]  eta: 0:17:17  lr: 0.001000  loss: 187.0023 (193.9654)  time: 0.5572  data: 0.0035  max mem: 5844\n",
            "Epoch: [0/2]  [7220/9200]  eta: 0:17:12  lr: 0.001000  loss: 187.6755 (193.9582)  time: 0.5414  data: 0.0042  max mem: 5844\n",
            "Epoch: [0/2]  [7230/9200]  eta: 0:17:06  lr: 0.001000  loss: 189.7732 (193.9495)  time: 0.4708  data: 0.0009  max mem: 5844\n",
            "Epoch: [0/2]  [7240/9200]  eta: 0:17:01  lr: 0.001000  loss: 186.7835 (193.9216)  time: 0.5050  data: 0.0019  max mem: 5844\n",
            "Epoch: [0/2]  [7250/9200]  eta: 0:16:56  lr: 0.001000  loss: 170.2666 (193.9078)  time: 0.5348  data: 0.0049  max mem: 5844\n",
            "Epoch: [0/2]  [7260/9200]  eta: 0:16:50  lr: 0.001000  loss: 170.2666 (193.8659)  time: 0.4765  data: 0.0032  max mem: 5844\n",
            "Epoch: [0/2]  [7270/9200]  eta: 0:16:45  lr: 0.001000  loss: 170.9552 (193.8364)  time: 0.4467  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [7280/9200]  eta: 0:16:40  lr: 0.001000  loss: 179.9994 (193.8419)  time: 0.5286  data: 0.0032  max mem: 5844\n",
            "Epoch: [0/2]  [7290/9200]  eta: 0:16:35  lr: 0.001000  loss: 198.8703 (193.8521)  time: 0.5515  data: 0.0033  max mem: 5844\n",
            "Epoch: [0/2]  [7300/9200]  eta: 0:16:29  lr: 0.001000  loss: 198.5770 (193.8731)  time: 0.4911  data: 0.0004  max mem: 5844\n",
            "Epoch: [0/2]  [7310/9200]  eta: 0:16:24  lr: 0.001000  loss: 191.2175 (193.8671)  time: 0.5259  data: 0.0042  max mem: 5844\n",
            "Epoch: [0/2]  [7320/9200]  eta: 0:16:19  lr: 0.001000  loss: 182.2394 (193.8736)  time: 0.5536  data: 0.0046  max mem: 5844\n",
            "Epoch: [0/2]  [7330/9200]  eta: 0:16:14  lr: 0.001000  loss: 182.2394 (193.8879)  time: 0.5044  data: 0.0010  max mem: 5844\n",
            "Epoch: [0/2]  [7340/9200]  eta: 0:16:09  lr: 0.001000  loss: 174.6353 (193.8689)  time: 0.5199  data: 0.0028  max mem: 5844\n",
            "Epoch: [0/2]  [7350/9200]  eta: 0:16:04  lr: 0.001000  loss: 170.3727 (193.8474)  time: 0.5407  data: 0.0038  max mem: 5844\n",
            "Epoch: [0/2]  [7360/9200]  eta: 0:15:58  lr: 0.001000  loss: 178.2719 (193.8618)  time: 0.4911  data: 0.0014  max mem: 5844\n",
            "Epoch: [0/2]  [7370/9200]  eta: 0:15:53  lr: 0.001000  loss: 178.2719 (193.8758)  time: 0.5099  data: 0.0019  max mem: 5844\n",
            "Epoch: [0/2]  [7380/9200]  eta: 0:15:48  lr: 0.001000  loss: 178.3967 (193.9018)  time: 0.5555  data: 0.0043  max mem: 5844\n",
            "Epoch: [0/2]  [7390/9200]  eta: 0:15:43  lr: 0.001000  loss: 192.6934 (193.9072)  time: 0.5316  data: 0.0026  max mem: 5844\n",
            "Epoch: [0/2]  [7400/9200]  eta: 0:15:37  lr: 0.001000  loss: 173.2978 (193.8791)  time: 0.5075  data: 0.0009  max mem: 5844\n",
            "Epoch: [0/2]  [7410/9200]  eta: 0:15:32  lr: 0.001000  loss: 176.2807 (193.8913)  time: 0.5487  data: 0.0041  max mem: 5844\n",
            "Epoch: [0/2]  [7420/9200]  eta: 0:15:27  lr: 0.001000  loss: 190.5629 (193.8941)  time: 0.5417  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [7430/9200]  eta: 0:15:22  lr: 0.001000  loss: 184.5951 (193.8980)  time: 0.5018  data: 0.0008  max mem: 5844\n",
            "Epoch: [0/2]  [7440/9200]  eta: 0:15:17  lr: 0.001000  loss: 191.5156 (193.8871)  time: 0.5357  data: 0.0038  max mem: 5844\n",
            "Epoch: [0/2]  [7450/9200]  eta: 0:15:12  lr: 0.001000  loss: 206.2270 (193.9106)  time: 0.5551  data: 0.0032  max mem: 5844\n",
            "Epoch: [0/2]  [7460/9200]  eta: 0:15:06  lr: 0.001000  loss: 209.7442 (193.9489)  time: 0.5265  data: 0.0008  max mem: 5844\n",
            "Epoch: [0/2]  [7470/9200]  eta: 0:15:01  lr: 0.001000  loss: 196.8759 (193.9461)  time: 0.5423  data: 0.0036  max mem: 5844\n",
            "Epoch: [0/2]  [7480/9200]  eta: 0:14:56  lr: 0.001000  loss: 192.6985 (193.9745)  time: 0.5525  data: 0.0036  max mem: 5844\n",
            "Epoch: [0/2]  [7490/9200]  eta: 0:14:51  lr: 0.001000  loss: 198.1036 (193.9924)  time: 0.5098  data: 0.0013  max mem: 5844\n",
            "Epoch: [0/2]  [7500/9200]  eta: 0:14:46  lr: 0.001000  loss: 183.0343 (193.9730)  time: 0.4975  data: 0.0022  max mem: 5844\n",
            "Epoch: [0/2]  [7510/9200]  eta: 0:14:40  lr: 0.001000  loss: 179.0252 (193.9538)  time: 0.5010  data: 0.0043  max mem: 5844\n",
            "Epoch: [0/2]  [7520/9200]  eta: 0:14:35  lr: 0.001000  loss: 179.9328 (193.9549)  time: 0.4855  data: 0.0027  max mem: 5844\n",
            "Epoch: [0/2]  [7530/9200]  eta: 0:14:30  lr: 0.001000  loss: 203.8222 (193.9923)  time: 0.5156  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [7540/9200]  eta: 0:14:25  lr: 0.001000  loss: 203.8222 (193.9702)  time: 0.5581  data: 0.0037  max mem: 5844\n",
            "Epoch: [0/2]  [7550/9200]  eta: 0:14:20  lr: 0.001000  loss: 186.2377 (193.9843)  time: 0.5289  data: 0.0036  max mem: 5844\n",
            "Epoch: [0/2]  [7560/9200]  eta: 0:14:14  lr: 0.001000  loss: 185.9505 (193.9524)  time: 0.4775  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [7570/9200]  eta: 0:14:09  lr: 0.001000  loss: 176.8926 (193.9600)  time: 0.5065  data: 0.0035  max mem: 5844\n",
            "Epoch: [0/2]  [7580/9200]  eta: 0:14:04  lr: 0.001000  loss: 176.0707 (193.9454)  time: 0.5307  data: 0.0051  max mem: 5844\n",
            "Epoch: [0/2]  [7590/9200]  eta: 0:13:58  lr: 0.001000  loss: 175.7211 (193.9449)  time: 0.4951  data: 0.0018  max mem: 5844\n",
            "Epoch: [0/2]  [7600/9200]  eta: 0:13:53  lr: 0.001000  loss: 181.9571 (193.9295)  time: 0.5156  data: 0.0021  max mem: 5844\n",
            "Epoch: [0/2]  [7610/9200]  eta: 0:13:48  lr: 0.001000  loss: 180.2098 (193.9105)  time: 0.5353  data: 0.0051  max mem: 5844\n",
            "Epoch: [0/2]  [7620/9200]  eta: 0:13:43  lr: 0.001000  loss: 179.3409 (193.8949)  time: 0.5357  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [7630/9200]  eta: 0:13:38  lr: 0.001000  loss: 186.4140 (193.9205)  time: 0.5494  data: 0.0009  max mem: 5844\n",
            "Epoch: [0/2]  [7640/9200]  eta: 0:13:33  lr: 0.001000  loss: 181.1552 (193.9074)  time: 0.5479  data: 0.0032  max mem: 5844\n",
            "Epoch: [0/2]  [7650/9200]  eta: 0:13:27  lr: 0.001000  loss: 176.7982 (193.8823)  time: 0.5037  data: 0.0033  max mem: 5844\n",
            "Epoch: [0/2]  [7660/9200]  eta: 0:13:22  lr: 0.001000  loss: 173.5561 (193.8598)  time: 0.4566  data: 0.0007  max mem: 5844\n",
            "Epoch: [0/2]  [7670/9200]  eta: 0:13:17  lr: 0.001000  loss: 164.0750 (193.8316)  time: 0.5144  data: 0.0026  max mem: 5844\n",
            "Epoch: [0/2]  [7680/9200]  eta: 0:13:12  lr: 0.001000  loss: 167.0776 (193.8037)  time: 0.5292  data: 0.0035  max mem: 5844\n",
            "Epoch: [0/2]  [7690/9200]  eta: 0:13:06  lr: 0.001000  loss: 164.9115 (193.7727)  time: 0.4851  data: 0.0011  max mem: 5844\n",
            "Epoch: [0/2]  [7700/9200]  eta: 0:13:01  lr: 0.001000  loss: 164.9115 (193.7668)  time: 0.5178  data: 0.0018  max mem: 5844\n",
            "Epoch: [0/2]  [7710/9200]  eta: 0:12:56  lr: 0.001000  loss: 176.1862 (193.7520)  time: 0.5448  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [7720/9200]  eta: 0:12:51  lr: 0.001000  loss: 167.9921 (193.7284)  time: 0.5223  data: 0.0018  max mem: 5844\n",
            "Epoch: [0/2]  [7730/9200]  eta: 0:12:46  lr: 0.001000  loss: 152.5390 (193.7305)  time: 0.5175  data: 0.0014  max mem: 5844\n",
            "Epoch: [0/2]  [7740/9200]  eta: 0:12:40  lr: 0.001000  loss: 171.7455 (193.7255)  time: 0.5406  data: 0.0038  max mem: 5844\n",
            "Epoch: [0/2]  [7750/9200]  eta: 0:12:35  lr: 0.001000  loss: 176.9968 (193.6999)  time: 0.5075  data: 0.0026  max mem: 5844\n",
            "Epoch: [0/2]  [7760/9200]  eta: 0:12:30  lr: 0.001000  loss: 185.9464 (193.7240)  time: 0.5031  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [7770/9200]  eta: 0:12:25  lr: 0.001000  loss: 208.2845 (193.7534)  time: 0.5586  data: 0.0027  max mem: 5844\n",
            "Epoch: [0/2]  [7780/9200]  eta: 0:12:20  lr: 0.001000  loss: 203.3446 (193.7886)  time: 0.5691  data: 0.0024  max mem: 5844\n",
            "Epoch: [0/2]  [7790/9200]  eta: 0:12:14  lr: 0.001000  loss: 200.6464 (193.7968)  time: 0.5400  data: 0.0009  max mem: 5844\n",
            "Epoch: [0/2]  [7800/9200]  eta: 0:12:09  lr: 0.001000  loss: 189.9154 (193.7826)  time: 0.5439  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [7810/9200]  eta: 0:12:04  lr: 0.001000  loss: 177.8693 (193.7639)  time: 0.4985  data: 0.0027  max mem: 5844\n",
            "Epoch: [0/2]  [7820/9200]  eta: 0:11:59  lr: 0.001000  loss: 169.1303 (193.7419)  time: 0.4541  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [7830/9200]  eta: 0:11:53  lr: 0.001000  loss: 174.7295 (193.7533)  time: 0.5194  data: 0.0031  max mem: 5844\n",
            "Epoch: [0/2]  [7840/9200]  eta: 0:11:48  lr: 0.001000  loss: 201.0753 (193.7676)  time: 0.5671  data: 0.0055  max mem: 5844\n",
            "Epoch: [0/2]  [7850/9200]  eta: 0:11:43  lr: 0.001000  loss: 188.0853 (193.7310)  time: 0.5445  data: 0.0027  max mem: 5844\n",
            "Epoch: [0/2]  [7860/9200]  eta: 0:11:38  lr: 0.001000  loss: 170.7356 (193.7229)  time: 0.5358  data: 0.0022  max mem: 5844\n",
            "Epoch: [0/2]  [7870/9200]  eta: 0:11:33  lr: 0.001000  loss: 164.3979 (193.6983)  time: 0.5237  data: 0.0049  max mem: 5844\n",
            "Epoch: [0/2]  [7880/9200]  eta: 0:11:27  lr: 0.001000  loss: 160.2401 (193.6705)  time: 0.4863  data: 0.0029  max mem: 5844\n",
            "Epoch: [0/2]  [7890/9200]  eta: 0:11:22  lr: 0.001000  loss: 177.6772 (193.6597)  time: 0.5143  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [7900/9200]  eta: 0:11:17  lr: 0.001000  loss: 177.6772 (193.6458)  time: 0.5638  data: 0.0024  max mem: 5844\n",
            "Epoch: [0/2]  [7910/9200]  eta: 0:11:12  lr: 0.001000  loss: 168.7127 (193.6370)  time: 0.5376  data: 0.0032  max mem: 5844\n",
            "Epoch: [0/2]  [7920/9200]  eta: 0:11:07  lr: 0.001000  loss: 190.9441 (193.6317)  time: 0.5017  data: 0.0011  max mem: 5844\n",
            "Epoch: [0/2]  [7930/9200]  eta: 0:11:02  lr: 0.001000  loss: 177.5803 (193.6456)  time: 0.5479  data: 0.0033  max mem: 5844\n",
            "Epoch: [0/2]  [7940/9200]  eta: 0:10:56  lr: 0.001000  loss: 187.2926 (193.6614)  time: 0.5501  data: 0.0036  max mem: 5844\n",
            "Epoch: [0/2]  [7950/9200]  eta: 0:10:51  lr: 0.001000  loss: 198.0888 (193.6856)  time: 0.5020  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [7960/9200]  eta: 0:10:46  lr: 0.001000  loss: 198.3977 (193.6999)  time: 0.5366  data: 0.0028  max mem: 5844\n",
            "Epoch: [0/2]  [7970/9200]  eta: 0:10:41  lr: 0.001000  loss: 184.9347 (193.6986)  time: 0.5594  data: 0.0037  max mem: 5844\n",
            "Epoch: [0/2]  [7980/9200]  eta: 0:10:36  lr: 0.001000  loss: 179.5272 (193.7070)  time: 0.5168  data: 0.0011  max mem: 5844\n",
            "Epoch: [0/2]  [7990/9200]  eta: 0:10:30  lr: 0.001000  loss: 178.8753 (193.7095)  time: 0.5028  data: 0.0024  max mem: 5844\n",
            "Epoch: [0/2]  [8000/9200]  eta: 0:10:25  lr: 0.001000  loss: 177.9615 (193.6818)  time: 0.5111  data: 0.0038  max mem: 5844\n",
            "Epoch: [0/2]  [8010/9200]  eta: 0:10:20  lr: 0.001000  loss: 152.9808 (193.6446)  time: 0.4874  data: 0.0017  max mem: 5844\n",
            "Epoch: [0/2]  [8020/9200]  eta: 0:10:14  lr: 0.001000  loss: 179.5572 (193.6256)  time: 0.4718  data: 0.0011  max mem: 5844\n",
            "Epoch: [0/2]  [8030/9200]  eta: 0:10:09  lr: 0.001000  loss: 175.5253 (193.5951)  time: 0.5082  data: 0.0032  max mem: 5844\n",
            "Epoch: [0/2]  [8040/9200]  eta: 0:10:04  lr: 0.001000  loss: 178.0520 (193.5945)  time: 0.5057  data: 0.0024  max mem: 5844\n",
            "Epoch: [0/2]  [8050/9200]  eta: 0:09:59  lr: 0.001000  loss: 180.2927 (193.5961)  time: 0.4694  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [8060/9200]  eta: 0:09:54  lr: 0.001000  loss: 176.2283 (193.5723)  time: 0.5269  data: 0.0035  max mem: 5844\n",
            "Epoch: [0/2]  [8070/9200]  eta: 0:09:48  lr: 0.001000  loss: 179.7127 (193.5632)  time: 0.5702  data: 0.0052  max mem: 5844\n",
            "Epoch: [0/2]  [8080/9200]  eta: 0:09:43  lr: 0.001000  loss: 184.6943 (193.5656)  time: 0.5073  data: 0.0021  max mem: 5844\n",
            "Epoch: [0/2]  [8090/9200]  eta: 0:09:38  lr: 0.001000  loss: 183.3792 (193.5612)  time: 0.4783  data: 0.0016  max mem: 5844\n",
            "Epoch: [0/2]  [8100/9200]  eta: 0:09:33  lr: 0.001000  loss: 189.8994 (193.5605)  time: 0.5323  data: 0.0053  max mem: 5844\n",
            "Epoch: [0/2]  [8110/9200]  eta: 0:09:27  lr: 0.001000  loss: 192.0863 (193.5546)  time: 0.5192  data: 0.0039  max mem: 5844\n",
            "Epoch: [0/2]  [8120/9200]  eta: 0:09:22  lr: 0.001000  loss: 189.7604 (193.5457)  time: 0.4652  data: 0.0006  max mem: 5844\n",
            "Epoch: [0/2]  [8130/9200]  eta: 0:09:17  lr: 0.001000  loss: 189.7604 (193.5466)  time: 0.5130  data: 0.0042  max mem: 5844\n",
            "Epoch: [0/2]  [8140/9200]  eta: 0:09:12  lr: 0.001000  loss: 172.0414 (193.5448)  time: 0.5166  data: 0.0052  max mem: 5844\n",
            "Epoch: [0/2]  [8150/9200]  eta: 0:09:06  lr: 0.001000  loss: 166.1766 (193.5178)  time: 0.4737  data: 0.0015  max mem: 5844\n",
            "Epoch: [0/2]  [8160/9200]  eta: 0:09:01  lr: 0.001000  loss: 175.5135 (193.5453)  time: 0.5418  data: 0.0018  max mem: 5844\n",
            "Epoch: [0/2]  [8170/9200]  eta: 0:08:56  lr: 0.001000  loss: 181.3079 (193.5411)  time: 0.6070  data: 0.0039  max mem: 5844\n",
            "Epoch: [0/2]  [8180/9200]  eta: 0:08:51  lr: 0.001000  loss: 169.4096 (193.5184)  time: 0.5249  data: 0.0023  max mem: 5844\n",
            "Epoch: [0/2]  [8190/9200]  eta: 0:08:46  lr: 0.001000  loss: 172.4538 (193.5235)  time: 0.4789  data: 0.0011  max mem: 5844\n",
            "Epoch: [0/2]  [8200/9200]  eta: 0:08:41  lr: 0.001000  loss: 172.4538 (193.5207)  time: 0.5373  data: 0.0045  max mem: 5844\n",
            "Epoch: [0/2]  [8210/9200]  eta: 0:08:35  lr: 0.001000  loss: 170.7063 (193.4942)  time: 0.5150  data: 0.0036  max mem: 5844\n",
            "Epoch: [0/2]  [8220/9200]  eta: 0:08:30  lr: 0.001000  loss: 172.2225 (193.4750)  time: 0.4655  data: 0.0003  max mem: 5844\n",
            "Epoch: [0/2]  [8230/9200]  eta: 0:08:25  lr: 0.001000  loss: 180.6849 (193.4848)  time: 0.5077  data: 0.0033  max mem: 5844\n",
            "Epoch: [0/2]  [8240/9200]  eta: 0:08:20  lr: 0.001000  loss: 181.2891 (193.4725)  time: 0.5271  data: 0.0050  max mem: 5844\n",
            "Epoch: [0/2]  [8250/9200]  eta: 0:08:14  lr: 0.001000  loss: 184.2385 (193.4830)  time: 0.5160  data: 0.0020  max mem: 5844\n",
            "Epoch: [0/2]  [8260/9200]  eta: 0:08:09  lr: 0.001000  loss: 186.3183 (193.4673)  time: 0.5131  data: 0.0021  max mem: 5844\n",
            "Epoch: [0/2]  [8270/9200]  eta: 0:08:04  lr: 0.001000  loss: 172.3482 (193.4638)  time: 0.5163  data: 0.0055  max mem: 5844\n",
            "Epoch: [0/2]  [8280/9200]  eta: 0:07:59  lr: 0.001000  loss: 171.8799 (193.4336)  time: 0.5122  data: 0.0047  max mem: 5844\n",
            "Epoch: [0/2]  [8290/9200]  eta: 0:07:53  lr: 0.001000  loss: 167.8014 (193.4163)  time: 0.4694  data: 0.0013  max mem: 5844\n",
            "Epoch: [0/2]  [8300/9200]  eta: 0:07:48  lr: 0.001000  loss: 202.6533 (193.4516)  time: 0.5334  data: 0.0032  max mem: 5844\n",
            "Epoch: [0/2]  [8310/9200]  eta: 0:07:43  lr: 0.001000  loss: 202.0591 (193.4581)  time: 0.5656  data: 0.0035  max mem: 5844\n",
            "Epoch: [0/2]  [8320/9200]  eta: 0:07:38  lr: 0.001000  loss: 190.1805 (193.4536)  time: 0.4749  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [8330/9200]  eta: 0:07:33  lr: 0.001000  loss: 190.1575 (193.4391)  time: 0.4769  data: 0.0022  max mem: 5844\n",
            "Epoch: [0/2]  [8340/9200]  eta: 0:07:27  lr: 0.001000  loss: 168.8475 (193.4126)  time: 0.5267  data: 0.0050  max mem: 5844\n",
            "Epoch: [0/2]  [8350/9200]  eta: 0:07:22  lr: 0.001000  loss: 177.9200 (193.4218)  time: 0.5126  data: 0.0030  max mem: 5844\n",
            "Epoch: [0/2]  [8360/9200]  eta: 0:07:17  lr: 0.001000  loss: 175.6464 (193.3888)  time: 0.4828  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [8370/9200]  eta: 0:07:12  lr: 0.001000  loss: 169.2859 (193.4106)  time: 0.5349  data: 0.0041  max mem: 5844\n",
            "Epoch: [0/2]  [8380/9200]  eta: 0:07:07  lr: 0.001000  loss: 181.4706 (193.4173)  time: 0.5389  data: 0.0038  max mem: 5844\n",
            "Epoch: [0/2]  [8390/9200]  eta: 0:07:01  lr: 0.001000  loss: 169.5088 (193.4079)  time: 0.4641  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [8400/9200]  eta: 0:06:56  lr: 0.001000  loss: 168.7689 (193.3979)  time: 0.5116  data: 0.0020  max mem: 5844\n",
            "Epoch: [0/2]  [8410/9200]  eta: 0:06:51  lr: 0.001000  loss: 172.6884 (193.3744)  time: 0.5300  data: 0.0029  max mem: 5844\n",
            "Epoch: [0/2]  [8420/9200]  eta: 0:06:46  lr: 0.001000  loss: 174.7621 (193.3706)  time: 0.4895  data: 0.0011  max mem: 5844\n",
            "Epoch: [0/2]  [8430/9200]  eta: 0:06:41  lr: 0.001000  loss: 174.7621 (193.3590)  time: 0.5286  data: 0.0022  max mem: 5844\n",
            "Epoch: [0/2]  [8440/9200]  eta: 0:06:35  lr: 0.001000  loss: 161.5690 (193.3432)  time: 0.5355  data: 0.0035  max mem: 5844\n",
            "Epoch: [0/2]  [8450/9200]  eta: 0:06:30  lr: 0.001000  loss: 176.3725 (193.3509)  time: 0.5055  data: 0.0016  max mem: 5844\n",
            "Epoch: [0/2]  [8460/9200]  eta: 0:06:25  lr: 0.001000  loss: 188.4292 (193.3623)  time: 0.5486  data: 0.0021  max mem: 5844\n",
            "Epoch: [0/2]  [8470/9200]  eta: 0:06:20  lr: 0.001000  loss: 188.6278 (193.3550)  time: 0.5651  data: 0.0049  max mem: 5844\n",
            "Epoch: [0/2]  [8480/9200]  eta: 0:06:14  lr: 0.001000  loss: 192.3269 (193.3603)  time: 0.5109  data: 0.0030  max mem: 5844\n",
            "Epoch: [0/2]  [8490/9200]  eta: 0:06:09  lr: 0.001000  loss: 181.4819 (193.3360)  time: 0.4759  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [8500/9200]  eta: 0:06:04  lr: 0.001000  loss: 179.4791 (193.3432)  time: 0.5519  data: 0.0035  max mem: 5844\n",
            "Epoch: [0/2]  [8510/9200]  eta: 0:05:59  lr: 0.001000  loss: 182.9665 (193.3231)  time: 0.5438  data: 0.0035  max mem: 5844\n",
            "Epoch: [0/2]  [8520/9200]  eta: 0:05:54  lr: 0.001000  loss: 173.8524 (193.2763)  time: 0.4614  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [8530/9200]  eta: 0:05:48  lr: 0.001000  loss: 150.7891 (193.2645)  time: 0.5000  data: 0.0020  max mem: 5844\n",
            "Epoch: [0/2]  [8540/9200]  eta: 0:05:43  lr: 0.001000  loss: 178.9169 (193.2548)  time: 0.5309  data: 0.0028  max mem: 5844\n",
            "Epoch: [0/2]  [8550/9200]  eta: 0:05:38  lr: 0.001000  loss: 181.4601 (193.2539)  time: 0.5347  data: 0.0011  max mem: 5844\n",
            "Epoch: [0/2]  [8560/9200]  eta: 0:05:33  lr: 0.001000  loss: 186.4523 (193.2723)  time: 0.5828  data: 0.0024  max mem: 5844\n",
            "Epoch: [0/2]  [8570/9200]  eta: 0:05:28  lr: 0.001000  loss: 197.4892 (193.2839)  time: 0.5694  data: 0.0027  max mem: 5844\n",
            "Epoch: [0/2]  [8580/9200]  eta: 0:05:22  lr: 0.001000  loss: 179.9453 (193.2717)  time: 0.4741  data: 0.0006  max mem: 5844\n",
            "Epoch: [0/2]  [8590/9200]  eta: 0:05:17  lr: 0.001000  loss: 205.9635 (193.2822)  time: 0.4874  data: 0.0017  max mem: 5844\n",
            "Epoch: [0/2]  [8600/9200]  eta: 0:05:12  lr: 0.001000  loss: 206.6268 (193.3102)  time: 0.5815  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [8610/9200]  eta: 0:05:07  lr: 0.001000  loss: 185.5555 (193.2978)  time: 0.5724  data: 0.0020  max mem: 5844\n",
            "Epoch: [0/2]  [8620/9200]  eta: 0:05:02  lr: 0.001000  loss: 179.9288 (193.2739)  time: 0.5149  data: 0.0019  max mem: 5844\n",
            "Epoch: [0/2]  [8630/9200]  eta: 0:04:56  lr: 0.001000  loss: 176.5597 (193.2548)  time: 0.5260  data: 0.0040  max mem: 5844\n",
            "Epoch: [0/2]  [8640/9200]  eta: 0:04:51  lr: 0.001000  loss: 180.3847 (193.2456)  time: 0.5444  data: 0.0025  max mem: 5844\n",
            "Epoch: [0/2]  [8650/9200]  eta: 0:04:46  lr: 0.001000  loss: 168.5942 (193.2147)  time: 0.5165  data: 0.0009  max mem: 5844\n",
            "Epoch: [0/2]  [8660/9200]  eta: 0:04:41  lr: 0.001000  loss: 163.0995 (193.1904)  time: 0.5229  data: 0.0048  max mem: 5844\n",
            "Epoch: [0/2]  [8670/9200]  eta: 0:04:36  lr: 0.001000  loss: 176.2899 (193.1945)  time: 0.5250  data: 0.0043  max mem: 5844\n",
            "Epoch: [0/2]  [8680/9200]  eta: 0:04:30  lr: 0.001000  loss: 179.9146 (193.1658)  time: 0.4634  data: 0.0004  max mem: 5844\n",
            "Epoch: [0/2]  [8690/9200]  eta: 0:04:25  lr: 0.001000  loss: 166.4297 (193.1452)  time: 0.4767  data: 0.0026  max mem: 5844\n",
            "Epoch: [0/2]  [8700/9200]  eta: 0:04:20  lr: 0.001000  loss: 183.2013 (193.1370)  time: 0.5266  data: 0.0058  max mem: 5844\n",
            "Epoch: [0/2]  [8710/9200]  eta: 0:04:15  lr: 0.001000  loss: 183.8051 (193.1340)  time: 0.5108  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [8720/9200]  eta: 0:04:09  lr: 0.001000  loss: 194.4983 (193.1405)  time: 0.4755  data: 0.0005  max mem: 5844\n",
            "Epoch: [0/2]  [8730/9200]  eta: 0:04:04  lr: 0.001000  loss: 198.9662 (193.1218)  time: 0.5115  data: 0.0043  max mem: 5844\n",
            "Epoch: [0/2]  [8740/9200]  eta: 0:03:59  lr: 0.001000  loss: 182.1378 (193.1140)  time: 0.5264  data: 0.0040  max mem: 5844\n",
            "Epoch: [0/2]  [8750/9200]  eta: 0:03:54  lr: 0.001000  loss: 182.1378 (193.0940)  time: 0.4869  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [8760/9200]  eta: 0:03:49  lr: 0.001000  loss: 173.8628 (193.0811)  time: 0.5103  data: 0.0030  max mem: 5844\n",
            "Epoch: [0/2]  [8770/9200]  eta: 0:03:43  lr: 0.001000  loss: 173.8628 (193.0551)  time: 0.5334  data: 0.0041  max mem: 5844\n",
            "Epoch: [0/2]  [8780/9200]  eta: 0:03:38  lr: 0.001000  loss: 179.7562 (193.0456)  time: 0.4670  data: 0.0013  max mem: 5844\n",
            "Epoch: [0/2]  [8790/9200]  eta: 0:03:33  lr: 0.001000  loss: 181.8944 (193.0537)  time: 0.4725  data: 0.0016  max mem: 5844\n",
            "Epoch: [0/2]  [8800/9200]  eta: 0:03:28  lr: 0.001000  loss: 180.8065 (193.0495)  time: 0.5360  data: 0.0045  max mem: 5844\n",
            "Epoch: [0/2]  [8810/9200]  eta: 0:03:23  lr: 0.001000  loss: 190.5718 (193.0673)  time: 0.5038  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2]  [8820/9200]  eta: 0:03:17  lr: 0.001000  loss: 190.5718 (193.0495)  time: 0.4951  data: 0.0004  max mem: 5844\n",
            "Epoch: [0/2]  [8830/9200]  eta: 0:03:12  lr: 0.001000  loss: 180.5661 (193.0514)  time: 0.5310  data: 0.0024  max mem: 5844\n",
            "Epoch: [0/2]  [8840/9200]  eta: 0:03:07  lr: 0.001000  loss: 188.5285 (193.0563)  time: 0.5307  data: 0.0046  max mem: 5844\n",
            "Epoch: [0/2]  [8850/9200]  eta: 0:03:02  lr: 0.001000  loss: 188.5952 (193.0499)  time: 0.5053  data: 0.0024  max mem: 5844\n",
            "Epoch: [0/2]  [8860/9200]  eta: 0:02:57  lr: 0.001000  loss: 176.0597 (193.0360)  time: 0.5228  data: 0.0023  max mem: 5844\n",
            "Epoch: [0/2]  [8870/9200]  eta: 0:02:51  lr: 0.001000  loss: 171.6622 (193.0170)  time: 0.5428  data: 0.0047  max mem: 5844\n",
            "Epoch: [0/2]  [8880/9200]  eta: 0:02:46  lr: 0.001000  loss: 179.8782 (193.0189)  time: 0.4897  data: 0.0026  max mem: 5844\n",
            "Epoch: [0/2]  [8890/9200]  eta: 0:02:41  lr: 0.001000  loss: 193.3881 (193.0408)  time: 0.4834  data: 0.0013  max mem: 5844\n",
            "Epoch: [0/2]  [8900/9200]  eta: 0:02:36  lr: 0.001000  loss: 181.4811 (192.9978)  time: 0.5241  data: 0.0040  max mem: 5844\n",
            "Epoch: [0/2]  [8910/9200]  eta: 0:02:30  lr: 0.001000  loss: 179.8739 (193.0053)  time: 0.5090  data: 0.0029  max mem: 5844\n",
            "Epoch: [0/2]  [8920/9200]  eta: 0:02:25  lr: 0.001000  loss: 176.0811 (192.9886)  time: 0.4887  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [8930/9200]  eta: 0:02:20  lr: 0.001000  loss: 172.2074 (192.9749)  time: 0.5164  data: 0.0035  max mem: 5844\n",
            "Epoch: [0/2]  [8940/9200]  eta: 0:02:15  lr: 0.001000  loss: 163.9450 (192.9672)  time: 0.5395  data: 0.0047  max mem: 5844\n",
            "Epoch: [0/2]  [8950/9200]  eta: 0:02:10  lr: 0.001000  loss: 161.4212 (192.9511)  time: 0.5089  data: 0.0013  max mem: 5844\n",
            "Epoch: [0/2]  [8960/9200]  eta: 0:02:04  lr: 0.001000  loss: 181.6109 (192.9767)  time: 0.5443  data: 0.0025  max mem: 5844\n",
            "Epoch: [0/2]  [8970/9200]  eta: 0:01:59  lr: 0.001000  loss: 183.8579 (192.9830)  time: 0.6018  data: 0.0040  max mem: 5844\n",
            "Epoch: [0/2]  [8980/9200]  eta: 0:01:54  lr: 0.001000  loss: 189.9834 (193.0260)  time: 0.5647  data: 0.0017  max mem: 5844\n",
            "Epoch: [0/2]  [8990/9200]  eta: 0:01:49  lr: 0.001000  loss: 174.8301 (192.9962)  time: 0.5257  data: 0.0015  max mem: 5844\n",
            "Epoch: [0/2]  [9000/9200]  eta: 0:01:44  lr: 0.001000  loss: 181.9357 (193.0052)  time: 0.5265  data: 0.0032  max mem: 5844\n",
            "Epoch: [0/2]  [9010/9200]  eta: 0:01:38  lr: 0.001000  loss: 180.2832 (192.9719)  time: 0.4868  data: 0.0018  max mem: 5844\n",
            "Epoch: [0/2]  [9020/9200]  eta: 0:01:33  lr: 0.001000  loss: 180.2832 (192.9773)  time: 0.4612  data: 0.0011  max mem: 5844\n",
            "Epoch: [0/2]  [9030/9200]  eta: 0:01:28  lr: 0.001000  loss: 199.6586 (193.0002)  time: 0.5493  data: 0.0039  max mem: 5844\n",
            "Epoch: [0/2]  [9040/9200]  eta: 0:01:23  lr: 0.001000  loss: 189.4470 (192.9843)  time: 0.5326  data: 0.0030  max mem: 5844\n",
            "Epoch: [0/2]  [9050/9200]  eta: 0:01:18  lr: 0.001000  loss: 189.4470 (192.9959)  time: 0.4992  data: 0.0009  max mem: 5844\n",
            "Epoch: [0/2]  [9060/9200]  eta: 0:01:12  lr: 0.001000  loss: 182.2035 (192.9681)  time: 0.5540  data: 0.0037  max mem: 5844\n",
            "Epoch: [0/2]  [9070/9200]  eta: 0:01:07  lr: 0.001000  loss: 183.2154 (192.9636)  time: 0.5348  data: 0.0039  max mem: 5844\n",
            "Epoch: [0/2]  [9080/9200]  eta: 0:01:02  lr: 0.001000  loss: 183.2154 (192.9702)  time: 0.5092  data: 0.0011  max mem: 5844\n",
            "Epoch: [0/2]  [9090/9200]  eta: 0:00:57  lr: 0.001000  loss: 167.5106 (192.9393)  time: 0.5110  data: 0.0027  max mem: 5844\n",
            "Epoch: [0/2]  [9100/9200]  eta: 0:00:52  lr: 0.001000  loss: 157.2734 (192.9154)  time: 0.5164  data: 0.0048  max mem: 5844\n",
            "Epoch: [0/2]  [9110/9200]  eta: 0:00:46  lr: 0.001000  loss: 187.3647 (192.9401)  time: 0.5423  data: 0.0023  max mem: 5844\n",
            "Epoch: [0/2]  [9120/9200]  eta: 0:00:41  lr: 0.001000  loss: 198.2386 (192.9446)  time: 0.5702  data: 0.0020  max mem: 5844\n",
            "Epoch: [0/2]  [9130/9200]  eta: 0:00:36  lr: 0.001000  loss: 185.9987 (192.9382)  time: 0.5703  data: 0.0042  max mem: 5844\n",
            "Epoch: [0/2]  [9140/9200]  eta: 0:00:31  lr: 0.001000  loss: 181.3531 (192.9526)  time: 0.5461  data: 0.0025  max mem: 5844\n",
            "Epoch: [0/2]  [9150/9200]  eta: 0:00:26  lr: 0.001000  loss: 203.9438 (192.9728)  time: 0.5499  data: 0.0008  max mem: 5844\n",
            "Epoch: [0/2]  [9160/9200]  eta: 0:00:20  lr: 0.001000  loss: 190.9264 (192.9657)  time: 0.5648  data: 0.0047  max mem: 5844\n",
            "Epoch: [0/2]  [9170/9200]  eta: 0:00:15  lr: 0.001000  loss: 204.3455 (192.9787)  time: 0.5090  data: 0.0041  max mem: 5844\n",
            "Epoch: [0/2]  [9180/9200]  eta: 0:00:10  lr: 0.001000  loss: 201.0482 (192.9691)  time: 0.4795  data: 0.0002  max mem: 5844\n",
            "Epoch: [0/2]  [9190/9200]  eta: 0:00:05  lr: 0.001000  loss: 164.0431 (192.9450)  time: 0.5111  data: 0.0030  max mem: 5844\n",
            "Epoch: [0/2]  [9199/9200]  eta: 0:00:00  lr: 0.001000  loss: 161.8315 (192.9209)  time: 0.5020  data: 0.0034  max mem: 5844\n",
            "Epoch: [0/2] Total time: 1:19:52 (0.5210 s / it)\n",
            "Averaged stats: lr: 0.001000  loss: 161.8315 (192.9209)\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1735148878.874300    1386 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1735148879.148154    1386 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1735148879.148405    1386 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1735148879.151475    1386 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1735148879.151741    1386 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1735148879.151903    1386 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1735148879.152226    1386 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1735148879.152427    1386 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-12-25 17:47:59.152606: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1735148879.152739    1386 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-12-25 17:47:59.155386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5959 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Test:  [  0/539]  eta: 0:17:56  loss: 383.3461 (383.3461)  time: 1.9980  data: 0.5966  max mem: 5844\n",
            "Test:  [ 10/539]  eta: 0:08:13  loss: 221.2631 (251.9561)  time: 0.9337  data: 0.0573  max mem: 5844\n",
            "Test:  [ 20/539]  eta: 0:06:31  loss: 235.2191 (253.3300)  time: 0.6917  data: 0.0018  max mem: 5844\n",
            "Test:  [ 30/539]  eta: 0:05:58  loss: 258.1206 (253.3233)  time: 0.5796  data: 0.0006  max mem: 5844\n",
            "Test:  [ 40/539]  eta: 0:05:39  loss: 202.5221 (237.0388)  time: 0.6026  data: 0.0019  max mem: 5844\n",
            "Test:  [ 50/539]  eta: 0:05:07  loss: 192.5840 (229.7160)  time: 0.5087  data: 0.0016  max mem: 5844\n",
            "Test:  [ 60/539]  eta: 0:04:45  loss: 198.5127 (225.3531)  time: 0.4208  data: 0.0003  max mem: 5844\n",
            "Test:  [ 70/539]  eta: 0:04:42  loss: 193.7977 (221.1032)  time: 0.5395  data: 0.0031  max mem: 5844\n",
            "Test:  [ 80/539]  eta: 0:04:24  loss: 171.9571 (214.3055)  time: 0.5153  data: 0.0031  max mem: 5844\n",
            "Test:  [ 90/539]  eta: 0:04:06  loss: 164.1316 (209.7314)  time: 0.3615  data: 0.0003  max mem: 5844\n",
            "Test:  [100/539]  eta: 0:03:59  loss: 164.1316 (207.4971)  time: 0.4237  data: 0.0018  max mem: 5844\n",
            "Test:  [110/539]  eta: 0:03:52  loss: 169.3783 (205.1723)  time: 0.5022  data: 0.0033  max mem: 5844\n",
            "Test:  [120/539]  eta: 0:03:41  loss: 173.2620 (204.2586)  time: 0.4423  data: 0.0018  max mem: 5844\n",
            "Test:  [130/539]  eta: 0:03:31  loss: 214.1517 (204.8492)  time: 0.3839  data: 0.0002  max mem: 5844\n",
            "Test:  [140/539]  eta: 0:03:31  loss: 218.9886 (206.1013)  time: 0.5492  data: 0.0016  max mem: 5844\n",
            "Test:  [150/539]  eta: 0:03:23  loss: 213.1076 (206.2817)  time: 0.5639  data: 0.0016  max mem: 5844\n",
            "Test:  [160/539]  eta: 0:03:14  loss: 176.4938 (204.1500)  time: 0.3911  data: 0.0003  max mem: 5844\n",
            "Test:  [170/539]  eta: 0:03:10  loss: 158.5143 (202.0563)  time: 0.4517  data: 0.0036  max mem: 5844\n",
            "Test:  [180/539]  eta: 0:03:03  loss: 167.5738 (200.3467)  time: 0.4849  data: 0.0047  max mem: 5844\n",
            "Test:  [190/539]  eta: 0:02:59  loss: 203.3336 (205.8644)  time: 0.5097  data: 0.0014  max mem: 5844\n",
            "Test:  [200/539]  eta: 0:02:57  loss: 253.5220 (207.5605)  time: 0.6371  data: 0.0033  max mem: 5844\n",
            "Test:  [210/539]  eta: 0:02:50  loss: 202.8757 (208.1314)  time: 0.5567  data: 0.0033  max mem: 5844\n",
            "Test:  [220/539]  eta: 0:02:44  loss: 207.0222 (208.7859)  time: 0.4334  data: 0.0003  max mem: 5844\n",
            "Test:  [230/539]  eta: 0:02:40  loss: 207.0222 (208.3927)  time: 0.5369  data: 0.0009  max mem: 5844\n",
            "Test:  [240/539]  eta: 0:02:34  loss: 202.2444 (208.3101)  time: 0.5221  data: 0.0013  max mem: 5844\n",
            "Test:  [250/539]  eta: 0:02:27  loss: 201.9224 (207.9042)  time: 0.4093  data: 0.0008  max mem: 5844\n",
            "Test:  [260/539]  eta: 0:02:22  loss: 197.0416 (207.6311)  time: 0.4402  data: 0.0014  max mem: 5844\n",
            "Test:  [270/539]  eta: 0:02:17  loss: 168.3778 (206.1122)  time: 0.4977  data: 0.0025  max mem: 5844\n",
            "Test:  [280/539]  eta: 0:02:11  loss: 197.7432 (206.7382)  time: 0.4792  data: 0.0015  max mem: 5844\n",
            "Test:  [290/539]  eta: 0:02:07  loss: 217.2461 (207.5758)  time: 0.5166  data: 0.0012  max mem: 5844\n",
            "Test:  [300/539]  eta: 0:02:02  loss: 206.1822 (206.9708)  time: 0.5767  data: 0.0026  max mem: 5844\n",
            "Test:  [310/539]  eta: 0:01:56  loss: 168.4290 (205.9153)  time: 0.4614  data: 0.0017  max mem: 5844\n",
            "Test:  [320/539]  eta: 0:01:51  loss: 200.7768 (207.2889)  time: 0.4475  data: 0.0008  max mem: 5844\n",
            "Test:  [330/539]  eta: 0:01:47  loss: 237.7947 (208.5020)  time: 0.5986  data: 0.0021  max mem: 5844\n",
            "Test:  [340/539]  eta: 0:01:42  loss: 258.7923 (210.2754)  time: 0.5851  data: 0.0015  max mem: 5844\n",
            "Test:  [350/539]  eta: 0:01:37  loss: 243.5087 (210.6795)  time: 0.5282  data: 0.0011  max mem: 5844\n",
            "Test:  [360/539]  eta: 0:01:32  loss: 210.8730 (210.9978)  time: 0.5648  data: 0.0022  max mem: 5844\n",
            "Test:  [370/539]  eta: 0:01:26  loss: 196.0475 (210.6114)  time: 0.4586  data: 0.0013  max mem: 5844\n",
            "Test:  [380/539]  eta: 0:01:20  loss: 196.7336 (210.9732)  time: 0.3661  data: 0.0007  max mem: 5844\n",
            "Test:  [390/539]  eta: 0:01:16  loss: 196.7336 (210.8230)  time: 0.5048  data: 0.0029  max mem: 5844\n",
            "Test:  [400/539]  eta: 0:01:10  loss: 168.8470 (210.0173)  time: 0.4816  data: 0.0025  max mem: 5844\n",
            "Test:  [410/539]  eta: 0:01:05  loss: 187.6440 (211.0327)  time: 0.3817  data: 0.0003  max mem: 5844\n",
            "Test:  [420/539]  eta: 0:00:59  loss: 192.2354 (210.2127)  time: 0.4495  data: 0.0018  max mem: 5844\n",
            "Test:  [430/539]  eta: 0:00:54  loss: 145.1711 (208.8680)  time: 0.4778  data: 0.0032  max mem: 5844\n",
            "Test:  [440/539]  eta: 0:00:49  loss: 112.9510 (206.7983)  time: 0.4013  data: 0.0016  max mem: 5844\n",
            "Test:  [450/539]  eta: 0:00:44  loss: 127.0744 (205.7895)  time: 0.3945  data: 0.0003  max mem: 5844\n",
            "Test:  [460/539]  eta: 0:00:39  loss: 163.7858 (205.0874)  time: 0.5722  data: 0.0021  max mem: 5844\n",
            "Test:  [470/539]  eta: 0:00:34  loss: 162.8983 (204.1163)  time: 0.5775  data: 0.0021  max mem: 5844\n",
            "Test:  [480/539]  eta: 0:00:29  loss: 165.2616 (203.5728)  time: 0.5135  data: 0.0006  max mem: 5844\n",
            "Test:  [490/539]  eta: 0:00:24  loss: 181.1691 (202.9743)  time: 0.6290  data: 0.0019  max mem: 5844\n",
            "Test:  [500/539]  eta: 0:00:19  loss: 181.1691 (202.6845)  time: 0.6024  data: 0.0016  max mem: 5844\n",
            "Test:  [510/539]  eta: 0:00:14  loss: 184.8138 (202.2446)  time: 0.5537  data: 0.0012  max mem: 5844\n",
            "Test:  [520/539]  eta: 0:00:09  loss: 187.7957 (201.9367)  time: 0.6021  data: 0.0021  max mem: 5844\n",
            "Test:  [530/539]  eta: 0:00:04  loss: 191.2961 (202.6375)  time: 0.5563  data: 0.0017  max mem: 5844\n",
            "Test:  [538/539]  eta: 0:00:00  loss: 225.4755 (203.5128)  time: 0.6405  data: 0.0008  max mem: 5844\n",
            "Test: Total time: 0:04:38 (0.5167 s / it)\n",
            "* Averaged stats: loss: 225.4755 (203.5128)  wer: 96.3783 (96.3783)\n",
            "* DEV loss 203.513\n",
            "* DEV wer 96.378 Min DEV WER 96.3783188547657\n",
            "Epoch: [1/2]  [   0/9200]  eta: 3:04:01  lr: 0.000999  loss: 179.5212 (179.5212)  time: 1.2002  data: 0.5353  max mem: 5844\n",
            "Epoch: [1/2]  [  10/9200]  eta: 1:28:19  lr: 0.000999  loss: 174.5609 (174.1490)  time: 0.5767  data: 0.0489  max mem: 5844\n",
            "Epoch: [1/2]  [  20/9200]  eta: 1:27:39  lr: 0.000999  loss: 174.5609 (175.9900)  time: 0.5415  data: 0.0026  max mem: 5844\n",
            "Epoch: [1/2]  [  30/9200]  eta: 1:26:15  lr: 0.000999  loss: 184.7224 (181.1905)  time: 0.5577  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [  40/9200]  eta: 1:22:32  lr: 0.000999  loss: 178.1166 (178.8984)  time: 0.5068  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [  50/9200]  eta: 1:21:39  lr: 0.000999  loss: 174.5664 (178.9746)  time: 0.4906  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [  60/9200]  eta: 1:23:01  lr: 0.000999  loss: 187.5751 (180.3694)  time: 0.5542  data: 0.0059  max mem: 5844\n",
            "Epoch: [1/2]  [  70/9200]  eta: 1:21:42  lr: 0.000999  loss: 169.5042 (179.4580)  time: 0.5408  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [  80/9200]  eta: 1:21:48  lr: 0.000999  loss: 168.0334 (182.4415)  time: 0.5174  data: 0.0009  max mem: 5844\n",
            "Epoch: [1/2]  [  90/9200]  eta: 1:23:23  lr: 0.000999  loss: 182.7464 (182.4375)  time: 0.5927  data: 0.0045  max mem: 5844\n",
            "Epoch: [1/2]  [ 100/9200]  eta: 1:22:27  lr: 0.000999  loss: 182.1922 (183.2270)  time: 0.5659  data: 0.0039  max mem: 5844\n",
            "Epoch: [1/2]  [ 110/9200]  eta: 1:22:03  lr: 0.000999  loss: 184.6548 (183.9501)  time: 0.5073  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [ 120/9200]  eta: 1:22:03  lr: 0.000999  loss: 166.7023 (183.5601)  time: 0.5345  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [ 130/9200]  eta: 1:21:35  lr: 0.000999  loss: 162.7486 (182.8236)  time: 0.5291  data: 0.0041  max mem: 5844\n",
            "Epoch: [1/2]  [ 140/9200]  eta: 1:21:54  lr: 0.000999  loss: 173.0813 (184.9450)  time: 0.5436  data: 0.0009  max mem: 5844\n",
            "Epoch: [1/2]  [ 150/9200]  eta: 1:22:11  lr: 0.000999  loss: 186.0778 (184.8794)  time: 0.5785  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [ 160/9200]  eta: 1:22:16  lr: 0.000999  loss: 184.0454 (184.5608)  time: 0.5719  data: 0.0053  max mem: 5844\n",
            "Epoch: [1/2]  [ 170/9200]  eta: 1:21:28  lr: 0.000999  loss: 169.5037 (184.5214)  time: 0.5144  data: 0.0022  max mem: 5844\n",
            "Epoch: [1/2]  [ 180/9200]  eta: 1:21:33  lr: 0.000999  loss: 188.0762 (185.5116)  time: 0.5140  data: 0.0030  max mem: 5844\n",
            "Epoch: [1/2]  [ 190/9200]  eta: 1:21:27  lr: 0.000999  loss: 188.0762 (185.5582)  time: 0.5523  data: 0.0050  max mem: 5844\n",
            "Epoch: [1/2]  [ 200/9200]  eta: 1:20:38  lr: 0.000999  loss: 162.7144 (185.2673)  time: 0.4937  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [ 210/9200]  eta: 1:20:58  lr: 0.000999  loss: 193.9816 (187.2961)  time: 0.5214  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [ 220/9200]  eta: 1:20:57  lr: 0.000999  loss: 181.5328 (186.3276)  time: 0.5737  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [ 230/9200]  eta: 1:20:15  lr: 0.000999  loss: 181.5328 (186.8623)  time: 0.4990  data: 0.0026  max mem: 5844\n",
            "Epoch: [1/2]  [ 240/9200]  eta: 1:20:03  lr: 0.000999  loss: 185.5639 (186.8192)  time: 0.4828  data: 0.0003  max mem: 5844\n",
            "Epoch: [1/2]  [ 250/9200]  eta: 1:20:13  lr: 0.000999  loss: 185.5639 (186.9908)  time: 0.5491  data: 0.0032  max mem: 5844\n",
            "Epoch: [1/2]  [ 260/9200]  eta: 1:19:53  lr: 0.000999  loss: 177.8510 (186.2881)  time: 0.5376  data: 0.0039  max mem: 5844\n",
            "Epoch: [1/2]  [ 270/9200]  eta: 1:19:42  lr: 0.000999  loss: 169.5940 (187.2507)  time: 0.5073  data: 0.0012  max mem: 5844\n",
            "Epoch: [1/2]  [ 280/9200]  eta: 1:19:56  lr: 0.000999  loss: 172.5443 (186.9076)  time: 0.5580  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [ 290/9200]  eta: 1:20:05  lr: 0.000999  loss: 187.2521 (187.8041)  time: 0.5900  data: 0.0048  max mem: 5844\n",
            "Epoch: [1/2]  [ 300/9200]  eta: 1:19:31  lr: 0.000999  loss: 181.4636 (187.6071)  time: 0.5134  data: 0.0019  max mem: 5844\n",
            "Epoch: [1/2]  [ 310/9200]  eta: 1:19:13  lr: 0.000999  loss: 176.7386 (187.6214)  time: 0.4672  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [ 320/9200]  eta: 1:19:23  lr: 0.000999  loss: 181.3375 (187.4934)  time: 0.5412  data: 0.0054  max mem: 5844\n",
            "Epoch: [1/2]  [ 330/9200]  eta: 1:18:55  lr: 0.000999  loss: 166.5842 (187.0343)  time: 0.5218  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [ 340/9200]  eta: 1:18:37  lr: 0.000999  loss: 173.8970 (187.1376)  time: 0.4682  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [ 350/9200]  eta: 1:18:57  lr: 0.000999  loss: 198.5494 (188.2169)  time: 0.5579  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [ 360/9200]  eta: 1:18:43  lr: 0.000999  loss: 195.2733 (188.4691)  time: 0.5658  data: 0.0036  max mem: 5844\n",
            "Epoch: [1/2]  [ 370/9200]  eta: 1:18:34  lr: 0.000999  loss: 175.1893 (188.2569)  time: 0.5089  data: 0.0018  max mem: 5844\n",
            "Epoch: [1/2]  [ 380/9200]  eta: 1:18:27  lr: 0.000999  loss: 165.9405 (188.5690)  time: 0.5240  data: 0.0023  max mem: 5844\n",
            "Epoch: [1/2]  [ 390/9200]  eta: 1:18:27  lr: 0.000999  loss: 157.2786 (188.2662)  time: 0.5426  data: 0.0044  max mem: 5844\n",
            "Epoch: [1/2]  [ 400/9200]  eta: 1:18:14  lr: 0.000999  loss: 168.4794 (188.6251)  time: 0.5287  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [ 410/9200]  eta: 1:17:52  lr: 0.000999  loss: 173.4841 (187.8980)  time: 0.4777  data: 0.0004  max mem: 5844\n",
            "Epoch: [1/2]  [ 420/9200]  eta: 1:17:51  lr: 0.000999  loss: 175.9774 (187.7855)  time: 0.5027  data: 0.0037  max mem: 5844\n",
            "Epoch: [1/2]  [ 430/9200]  eta: 1:17:45  lr: 0.000999  loss: 182.5720 (187.5527)  time: 0.5397  data: 0.0060  max mem: 5844\n",
            "Epoch: [1/2]  [ 440/9200]  eta: 1:17:37  lr: 0.000999  loss: 178.1758 (187.2239)  time: 0.5246  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [ 450/9200]  eta: 1:17:42  lr: 0.000999  loss: 178.1758 (187.5151)  time: 0.5517  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [ 460/9200]  eta: 1:17:38  lr: 0.000999  loss: 203.5054 (187.9980)  time: 0.5620  data: 0.0058  max mem: 5844\n",
            "Epoch: [1/2]  [ 470/9200]  eta: 1:17:36  lr: 0.000999  loss: 204.7973 (188.3849)  time: 0.5459  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [ 480/9200]  eta: 1:17:32  lr: 0.000999  loss: 183.6076 (188.0421)  time: 0.5462  data: 0.0019  max mem: 5844\n",
            "Epoch: [1/2]  [ 490/9200]  eta: 1:17:31  lr: 0.000999  loss: 175.5576 (188.1225)  time: 0.5510  data: 0.0053  max mem: 5844\n",
            "Epoch: [1/2]  [ 500/9200]  eta: 1:17:14  lr: 0.000999  loss: 171.1764 (187.8864)  time: 0.5121  data: 0.0036  max mem: 5844\n",
            "Epoch: [1/2]  [ 510/9200]  eta: 1:16:54  lr: 0.000999  loss: 171.1764 (187.7098)  time: 0.4565  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [ 520/9200]  eta: 1:16:52  lr: 0.000999  loss: 184.2532 (187.7517)  time: 0.4979  data: 0.0039  max mem: 5844\n",
            "Epoch: [1/2]  [ 530/9200]  eta: 1:16:44  lr: 0.000999  loss: 179.3279 (187.5491)  time: 0.5305  data: 0.0054  max mem: 5844\n",
            "Epoch: [1/2]  [ 540/9200]  eta: 1:16:40  lr: 0.000999  loss: 190.1073 (188.2526)  time: 0.5274  data: 0.0017  max mem: 5844\n",
            "Epoch: [1/2]  [ 550/9200]  eta: 1:16:36  lr: 0.000999  loss: 197.1744 (187.9839)  time: 0.5394  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [ 560/9200]  eta: 1:16:31  lr: 0.000999  loss: 159.6456 (187.8193)  time: 0.5368  data: 0.0047  max mem: 5844\n",
            "Epoch: [1/2]  [ 570/9200]  eta: 1:16:19  lr: 0.000999  loss: 163.5320 (187.6513)  time: 0.5131  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [ 580/9200]  eta: 1:16:14  lr: 0.000999  loss: 178.9032 (187.6429)  time: 0.5108  data: 0.0006  max mem: 5844\n",
            "Epoch: [1/2]  [ 590/9200]  eta: 1:16:25  lr: 0.000999  loss: 192.5643 (187.6526)  time: 0.5880  data: 0.0047  max mem: 5844\n",
            "Epoch: [1/2]  [ 600/9200]  eta: 1:16:20  lr: 0.000999  loss: 179.4597 (187.6079)  time: 0.5871  data: 0.0046  max mem: 5844\n",
            "Epoch: [1/2]  [ 610/9200]  eta: 1:16:11  lr: 0.000999  loss: 180.1006 (187.9253)  time: 0.5185  data: 0.0006  max mem: 5844\n",
            "Epoch: [1/2]  [ 620/9200]  eta: 1:16:13  lr: 0.000999  loss: 176.3309 (187.5022)  time: 0.5465  data: 0.0025  max mem: 5844\n",
            "Epoch: [1/2]  [ 630/9200]  eta: 1:16:11  lr: 0.000999  loss: 164.5013 (187.4729)  time: 0.5721  data: 0.0041  max mem: 5844\n",
            "Epoch: [1/2]  [ 640/9200]  eta: 1:15:59  lr: 0.000999  loss: 197.9157 (187.7022)  time: 0.5218  data: 0.0019  max mem: 5844\n",
            "Epoch: [1/2]  [ 650/9200]  eta: 1:15:58  lr: 0.000999  loss: 195.7137 (187.8273)  time: 0.5256  data: 0.0023  max mem: 5844\n",
            "Epoch: [1/2]  [ 660/9200]  eta: 1:16:03  lr: 0.000999  loss: 193.2175 (188.1050)  time: 0.5877  data: 0.0044  max mem: 5844\n",
            "Epoch: [1/2]  [ 670/9200]  eta: 1:15:49  lr: 0.000999  loss: 175.0739 (187.8990)  time: 0.5382  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [ 680/9200]  eta: 1:15:30  lr: 0.000999  loss: 154.9668 (187.6796)  time: 0.4456  data: 0.0010  max mem: 5844\n",
            "Epoch: [1/2]  [ 690/9200]  eta: 1:15:30  lr: 0.000999  loss: 186.2765 (187.7058)  time: 0.4990  data: 0.0032  max mem: 5844\n",
            "Epoch: [1/2]  [ 700/9200]  eta: 1:15:14  lr: 0.000999  loss: 186.2765 (187.6399)  time: 0.5101  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [ 710/9200]  eta: 1:15:05  lr: 0.000999  loss: 172.6095 (187.5456)  time: 0.4746  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [ 720/9200]  eta: 1:15:11  lr: 0.000999  loss: 174.5830 (187.8355)  time: 0.5649  data: 0.0030  max mem: 5844\n",
            "Epoch: [1/2]  [ 730/9200]  eta: 1:15:08  lr: 0.000999  loss: 182.1868 (188.0910)  time: 0.5871  data: 0.0042  max mem: 5844\n",
            "Epoch: [1/2]  [ 740/9200]  eta: 1:14:55  lr: 0.000999  loss: 182.1868 (188.0257)  time: 0.5056  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [ 750/9200]  eta: 1:14:57  lr: 0.000999  loss: 181.6955 (187.8455)  time: 0.5303  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [ 760/9200]  eta: 1:14:53  lr: 0.000999  loss: 182.6204 (187.7925)  time: 0.5724  data: 0.0057  max mem: 5844\n",
            "Epoch: [1/2]  [ 770/9200]  eta: 1:14:35  lr: 0.000999  loss: 173.3068 (187.5968)  time: 0.4823  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [ 780/9200]  eta: 1:14:32  lr: 0.000999  loss: 173.4860 (187.8490)  time: 0.4829  data: 0.0006  max mem: 5844\n",
            "Epoch: [1/2]  [ 790/9200]  eta: 1:14:33  lr: 0.000999  loss: 187.3170 (187.8379)  time: 0.5713  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [ 800/9200]  eta: 1:14:24  lr: 0.000999  loss: 183.4668 (187.8372)  time: 0.5437  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [ 810/9200]  eta: 1:14:14  lr: 0.000999  loss: 187.2997 (188.1426)  time: 0.4901  data: 0.0011  max mem: 5844\n",
            "Epoch: [1/2]  [ 820/9200]  eta: 1:14:20  lr: 0.000999  loss: 211.5594 (188.4441)  time: 0.5641  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [ 830/9200]  eta: 1:14:13  lr: 0.000999  loss: 183.0369 (188.2128)  time: 0.5813  data: 0.0052  max mem: 5844\n",
            "Epoch: [1/2]  [ 840/9200]  eta: 1:14:01  lr: 0.000999  loss: 170.8564 (187.9853)  time: 0.4887  data: 0.0026  max mem: 5844\n",
            "Epoch: [1/2]  [ 850/9200]  eta: 1:13:55  lr: 0.000999  loss: 184.7046 (188.1197)  time: 0.4911  data: 0.0013  max mem: 5844\n",
            "Epoch: [1/2]  [ 860/9200]  eta: 1:13:52  lr: 0.000999  loss: 188.4485 (187.9943)  time: 0.5436  data: 0.0050  max mem: 5844\n",
            "Epoch: [1/2]  [ 870/9200]  eta: 1:13:48  lr: 0.000999  loss: 187.8795 (188.0381)  time: 0.5509  data: 0.0045  max mem: 5844\n",
            "Epoch: [1/2]  [ 880/9200]  eta: 1:13:42  lr: 0.000999  loss: 175.0597 (187.8588)  time: 0.5341  data: 0.0010  max mem: 5844\n",
            "Epoch: [1/2]  [ 890/9200]  eta: 1:13:43  lr: 0.000999  loss: 175.0597 (187.8877)  time: 0.5654  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [ 900/9200]  eta: 1:13:34  lr: 0.000999  loss: 177.5122 (187.6849)  time: 0.5422  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [ 910/9200]  eta: 1:13:24  lr: 0.000999  loss: 183.9889 (187.6392)  time: 0.4859  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [ 920/9200]  eta: 1:13:21  lr: 0.000999  loss: 154.5975 (187.4845)  time: 0.5195  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [ 930/9200]  eta: 1:13:20  lr: 0.000999  loss: 150.5229 (187.8275)  time: 0.5654  data: 0.0054  max mem: 5844\n",
            "Epoch: [1/2]  [ 940/9200]  eta: 1:13:09  lr: 0.000999  loss: 159.3464 (187.6298)  time: 0.5261  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [ 950/9200]  eta: 1:13:00  lr: 0.000999  loss: 174.8002 (187.6453)  time: 0.4811  data: 0.0010  max mem: 5844\n",
            "Epoch: [1/2]  [ 960/9200]  eta: 1:12:59  lr: 0.000999  loss: 174.8002 (187.3562)  time: 0.5318  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [ 970/9200]  eta: 1:12:55  lr: 0.000999  loss: 173.5569 (187.3835)  time: 0.5595  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [ 980/9200]  eta: 1:12:47  lr: 0.000999  loss: 177.6283 (187.1716)  time: 0.5244  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [ 990/9200]  eta: 1:12:46  lr: 0.000999  loss: 182.1045 (187.2387)  time: 0.5468  data: 0.0032  max mem: 5844\n",
            "Epoch: [1/2]  [1000/9200]  eta: 1:12:41  lr: 0.000999  loss: 193.9657 (187.2774)  time: 0.5596  data: 0.0045  max mem: 5844\n",
            "Epoch: [1/2]  [1010/9200]  eta: 1:12:35  lr: 0.000999  loss: 190.9191 (187.5735)  time: 0.5295  data: 0.0017  max mem: 5844\n",
            "Epoch: [1/2]  [1020/9200]  eta: 1:12:32  lr: 0.000999  loss: 182.2767 (187.6809)  time: 0.5463  data: 0.0013  max mem: 5844\n",
            "Epoch: [1/2]  [1030/9200]  eta: 1:12:27  lr: 0.000999  loss: 175.5605 (187.4223)  time: 0.5487  data: 0.0039  max mem: 5844\n",
            "Epoch: [1/2]  [1040/9200]  eta: 1:12:20  lr: 0.000999  loss: 156.3236 (187.4294)  time: 0.5182  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [1050/9200]  eta: 1:12:15  lr: 0.000999  loss: 185.7536 (187.4100)  time: 0.5215  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [1060/9200]  eta: 1:12:15  lr: 0.000999  loss: 189.5539 (187.5874)  time: 0.5681  data: 0.0030  max mem: 5844\n",
            "Epoch: [1/2]  [1070/9200]  eta: 1:12:07  lr: 0.000999  loss: 180.7520 (187.4823)  time: 0.5508  data: 0.0026  max mem: 5844\n",
            "Epoch: [1/2]  [1080/9200]  eta: 1:12:02  lr: 0.000999  loss: 170.6020 (187.4082)  time: 0.5213  data: 0.0008  max mem: 5844\n",
            "Epoch: [1/2]  [1090/9200]  eta: 1:12:04  lr: 0.000999  loss: 186.1784 (187.5428)  time: 0.5801  data: 0.0049  max mem: 5844\n",
            "Epoch: [1/2]  [1100/9200]  eta: 1:11:55  lr: 0.000999  loss: 200.5273 (187.5984)  time: 0.5572  data: 0.0052  max mem: 5844\n",
            "Epoch: [1/2]  [1110/9200]  eta: 1:11:45  lr: 0.000999  loss: 170.3708 (187.4662)  time: 0.4773  data: 0.0010  max mem: 5844\n",
            "Epoch: [1/2]  [1120/9200]  eta: 1:11:38  lr: 0.000999  loss: 159.4261 (187.3971)  time: 0.4873  data: 0.0020  max mem: 5844\n",
            "Epoch: [1/2]  [1130/9200]  eta: 1:11:35  lr: 0.000999  loss: 189.6078 (187.5520)  time: 0.5396  data: 0.0036  max mem: 5844\n",
            "Epoch: [1/2]  [1140/9200]  eta: 1:11:29  lr: 0.000999  loss: 189.6078 (187.6866)  time: 0.5412  data: 0.0018  max mem: 5844\n",
            "Epoch: [1/2]  [1150/9200]  eta: 1:11:22  lr: 0.000999  loss: 178.3331 (187.5728)  time: 0.5150  data: 0.0015  max mem: 5844\n",
            "Epoch: [1/2]  [1160/9200]  eta: 1:11:22  lr: 0.000999  loss: 169.9636 (187.6714)  time: 0.5589  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [1170/9200]  eta: 1:11:09  lr: 0.000999  loss: 171.9701 (187.4944)  time: 0.5130  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [1180/9200]  eta: 1:11:09  lr: 0.000999  loss: 192.1537 (187.5697)  time: 0.5154  data: 0.0008  max mem: 5844\n",
            "Epoch: [1/2]  [1190/9200]  eta: 1:11:05  lr: 0.000999  loss: 192.1537 (187.4968)  time: 0.5802  data: 0.0044  max mem: 5844\n",
            "Epoch: [1/2]  [1200/9200]  eta: 1:10:57  lr: 0.000999  loss: 173.6136 (187.4377)  time: 0.5251  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [1210/9200]  eta: 1:10:48  lr: 0.000999  loss: 173.6136 (187.4587)  time: 0.4824  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [1220/9200]  eta: 1:10:49  lr: 0.000999  loss: 188.4875 (187.5615)  time: 0.5550  data: 0.0037  max mem: 5844\n",
            "Epoch: [1/2]  [1230/9200]  eta: 1:10:42  lr: 0.000999  loss: 208.8088 (187.7977)  time: 0.5669  data: 0.0042  max mem: 5844\n",
            "Epoch: [1/2]  [1240/9200]  eta: 1:10:32  lr: 0.000999  loss: 183.9225 (187.8071)  time: 0.4769  data: 0.0013  max mem: 5844\n",
            "Epoch: [1/2]  [1250/9200]  eta: 1:10:31  lr: 0.000999  loss: 182.1383 (187.7617)  time: 0.5304  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [1260/9200]  eta: 1:10:27  lr: 0.000999  loss: 175.3930 (187.7157)  time: 0.5790  data: 0.0042  max mem: 5844\n",
            "Epoch: [1/2]  [1270/9200]  eta: 1:10:18  lr: 0.000999  loss: 155.4216 (187.5322)  time: 0.5160  data: 0.0018  max mem: 5844\n",
            "Epoch: [1/2]  [1280/9200]  eta: 1:10:10  lr: 0.000999  loss: 180.3493 (187.6372)  time: 0.4854  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [1290/9200]  eta: 1:10:07  lr: 0.000999  loss: 198.3536 (187.7713)  time: 0.5278  data: 0.0040  max mem: 5844\n",
            "Epoch: [1/2]  [1300/9200]  eta: 1:10:01  lr: 0.000999  loss: 194.7071 (187.9016)  time: 0.5392  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [1310/9200]  eta: 1:09:57  lr: 0.000999  loss: 189.3868 (187.8581)  time: 0.5386  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [1320/9200]  eta: 1:09:54  lr: 0.000999  loss: 195.0920 (187.9344)  time: 0.5681  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [1330/9200]  eta: 1:09:49  lr: 0.000999  loss: 196.7731 (188.0387)  time: 0.5529  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [1340/9200]  eta: 1:09:46  lr: 0.000999  loss: 172.9482 (188.1846)  time: 0.5534  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [1350/9200]  eta: 1:09:41  lr: 0.000999  loss: 172.9482 (188.0929)  time: 0.5565  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [1360/9200]  eta: 1:09:32  lr: 0.000999  loss: 182.2589 (188.0127)  time: 0.5048  data: 0.0020  max mem: 5844\n",
            "Epoch: [1/2]  [1370/9200]  eta: 1:09:23  lr: 0.000999  loss: 184.0838 (187.9289)  time: 0.4701  data: 0.0008  max mem: 5844\n",
            "Epoch: [1/2]  [1380/9200]  eta: 1:09:20  lr: 0.000999  loss: 168.3823 (187.7992)  time: 0.5158  data: 0.0042  max mem: 5844\n",
            "Epoch: [1/2]  [1390/9200]  eta: 1:09:12  lr: 0.000999  loss: 166.4889 (187.5980)  time: 0.5298  data: 0.0041  max mem: 5844\n",
            "Epoch: [1/2]  [1400/9200]  eta: 1:09:06  lr: 0.000999  loss: 178.4543 (187.5754)  time: 0.5023  data: 0.0007  max mem: 5844\n",
            "Epoch: [1/2]  [1410/9200]  eta: 1:09:05  lr: 0.000999  loss: 178.4543 (187.5063)  time: 0.5629  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [1420/9200]  eta: 1:09:01  lr: 0.000999  loss: 177.2866 (187.4254)  time: 0.5869  data: 0.0037  max mem: 5844\n",
            "Epoch: [1/2]  [1430/9200]  eta: 1:08:53  lr: 0.000999  loss: 173.9788 (187.2587)  time: 0.5200  data: 0.0018  max mem: 5844\n",
            "Epoch: [1/2]  [1440/9200]  eta: 1:08:48  lr: 0.000999  loss: 154.6103 (187.0518)  time: 0.5085  data: 0.0022  max mem: 5844\n",
            "Epoch: [1/2]  [1450/9200]  eta: 1:08:47  lr: 0.000999  loss: 171.7328 (187.1059)  time: 0.5769  data: 0.0055  max mem: 5844\n",
            "Epoch: [1/2]  [1460/9200]  eta: 1:08:38  lr: 0.000999  loss: 171.7328 (186.9030)  time: 0.5358  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [1470/9200]  eta: 1:08:34  lr: 0.000999  loss: 170.4827 (187.2014)  time: 0.5051  data: 0.0007  max mem: 5844\n",
            "Epoch: [1/2]  [1480/9200]  eta: 1:08:30  lr: 0.000999  loss: 168.1322 (187.1592)  time: 0.5556  data: 0.0037  max mem: 5844\n",
            "Epoch: [1/2]  [1490/9200]  eta: 1:08:21  lr: 0.000999  loss: 165.2633 (186.9381)  time: 0.5107  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [1500/9200]  eta: 1:08:12  lr: 0.000999  loss: 167.4910 (186.8574)  time: 0.4670  data: 0.0004  max mem: 5844\n",
            "Epoch: [1/2]  [1510/9200]  eta: 1:08:09  lr: 0.000999  loss: 172.8685 (186.8304)  time: 0.5166  data: 0.0030  max mem: 5844\n",
            "Epoch: [1/2]  [1520/9200]  eta: 1:08:03  lr: 0.000999  loss: 184.4078 (186.8391)  time: 0.5473  data: 0.0055  max mem: 5844\n",
            "Epoch: [1/2]  [1530/9200]  eta: 1:07:56  lr: 0.000999  loss: 173.0391 (186.7886)  time: 0.5101  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [1540/9200]  eta: 1:07:50  lr: 0.000999  loss: 183.3866 (186.8259)  time: 0.5011  data: 0.0015  max mem: 5844\n",
            "Epoch: [1/2]  [1550/9200]  eta: 1:07:46  lr: 0.000999  loss: 180.8098 (186.8020)  time: 0.5339  data: 0.0042  max mem: 5844\n",
            "Epoch: [1/2]  [1560/9200]  eta: 1:07:39  lr: 0.000999  loss: 168.3169 (186.8256)  time: 0.5283  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [1570/9200]  eta: 1:07:33  lr: 0.000999  loss: 182.9269 (186.8933)  time: 0.5102  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [1580/9200]  eta: 1:07:30  lr: 0.000999  loss: 192.5108 (186.9079)  time: 0.5553  data: 0.0030  max mem: 5844\n",
            "Epoch: [1/2]  [1590/9200]  eta: 1:07:23  lr: 0.000999  loss: 184.7085 (186.9749)  time: 0.5401  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [1600/9200]  eta: 1:07:15  lr: 0.000999  loss: 184.2474 (187.0525)  time: 0.4847  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [1610/9200]  eta: 1:07:12  lr: 0.000999  loss: 167.9165 (186.9149)  time: 0.5268  data: 0.0030  max mem: 5844\n",
            "Epoch: [1/2]  [1620/9200]  eta: 1:07:07  lr: 0.000999  loss: 170.7062 (186.9156)  time: 0.5533  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [1630/9200]  eta: 1:06:58  lr: 0.000999  loss: 181.0109 (186.8911)  time: 0.4934  data: 0.0015  max mem: 5844\n",
            "Epoch: [1/2]  [1640/9200]  eta: 1:06:52  lr: 0.000999  loss: 193.7161 (187.0838)  time: 0.4869  data: 0.0022  max mem: 5844\n",
            "Epoch: [1/2]  [1650/9200]  eta: 1:06:46  lr: 0.000999  loss: 176.3493 (187.0015)  time: 0.5188  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [1660/9200]  eta: 1:06:38  lr: 0.000999  loss: 156.3344 (186.8882)  time: 0.4918  data: 0.0015  max mem: 5844\n",
            "Epoch: [1/2]  [1670/9200]  eta: 1:06:32  lr: 0.000999  loss: 163.3123 (186.8792)  time: 0.4858  data: 0.0013  max mem: 5844\n",
            "Epoch: [1/2]  [1680/9200]  eta: 1:06:29  lr: 0.000999  loss: 176.8943 (186.8573)  time: 0.5460  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [1690/9200]  eta: 1:06:20  lr: 0.000999  loss: 174.3057 (186.7276)  time: 0.5214  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [1700/9200]  eta: 1:06:16  lr: 0.000999  loss: 179.1273 (186.9069)  time: 0.5105  data: 0.0007  max mem: 5844\n",
            "Epoch: [1/2]  [1710/9200]  eta: 1:06:15  lr: 0.000999  loss: 188.3086 (186.8798)  time: 0.5931  data: 0.0040  max mem: 5844\n",
            "Epoch: [1/2]  [1720/9200]  eta: 1:06:10  lr: 0.000999  loss: 183.3502 (186.8677)  time: 0.5775  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [1730/9200]  eta: 1:06:02  lr: 0.000999  loss: 165.2658 (186.7536)  time: 0.5038  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [1740/9200]  eta: 1:05:59  lr: 0.000999  loss: 171.1045 (186.8418)  time: 0.5263  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [1750/9200]  eta: 1:05:52  lr: 0.000999  loss: 186.6619 (186.8433)  time: 0.5327  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [1760/9200]  eta: 1:05:44  lr: 0.000999  loss: 203.0278 (186.9309)  time: 0.4836  data: 0.0010  max mem: 5844\n",
            "Epoch: [1/2]  [1770/9200]  eta: 1:05:40  lr: 0.000999  loss: 165.7105 (186.7660)  time: 0.5146  data: 0.0025  max mem: 5844\n",
            "Epoch: [1/2]  [1780/9200]  eta: 1:05:34  lr: 0.000999  loss: 139.1716 (186.5837)  time: 0.5406  data: 0.0051  max mem: 5844\n",
            "Epoch: [1/2]  [1790/9200]  eta: 1:05:27  lr: 0.000999  loss: 148.3082 (186.4177)  time: 0.5079  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [1800/9200]  eta: 1:05:21  lr: 0.000999  loss: 158.4454 (186.4411)  time: 0.4993  data: 0.0010  max mem: 5844\n",
            "Epoch: [1/2]  [1810/9200]  eta: 1:05:21  lr: 0.000999  loss: 192.6697 (186.4874)  time: 0.5773  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [1820/9200]  eta: 1:05:14  lr: 0.000999  loss: 199.9451 (186.5181)  time: 0.5725  data: 0.0030  max mem: 5844\n",
            "Epoch: [1/2]  [1830/9200]  eta: 1:05:09  lr: 0.000999  loss: 178.2901 (186.5200)  time: 0.5128  data: 0.0009  max mem: 5844\n",
            "Epoch: [1/2]  [1840/9200]  eta: 1:05:06  lr: 0.000999  loss: 177.3055 (186.5413)  time: 0.5590  data: 0.0039  max mem: 5844\n",
            "Epoch: [1/2]  [1850/9200]  eta: 1:05:00  lr: 0.000999  loss: 174.7570 (186.4920)  time: 0.5570  data: 0.0049  max mem: 5844\n",
            "Epoch: [1/2]  [1860/9200]  eta: 1:04:53  lr: 0.000999  loss: 170.2616 (186.5009)  time: 0.5035  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [1870/9200]  eta: 1:04:49  lr: 0.000999  loss: 185.0123 (186.5747)  time: 0.5301  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [1880/9200]  eta: 1:04:45  lr: 0.000999  loss: 189.8392 (186.6800)  time: 0.5576  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [1890/9200]  eta: 1:04:39  lr: 0.000999  loss: 190.6156 (186.7855)  time: 0.5287  data: 0.0019  max mem: 5844\n",
            "Epoch: [1/2]  [1900/9200]  eta: 1:04:34  lr: 0.000999  loss: 185.4376 (186.7901)  time: 0.5267  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [1910/9200]  eta: 1:04:28  lr: 0.000999  loss: 174.3133 (186.7390)  time: 0.5331  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [1920/9200]  eta: 1:04:21  lr: 0.000999  loss: 160.3680 (186.6288)  time: 0.4983  data: 0.0017  max mem: 5844\n",
            "Epoch: [1/2]  [1930/9200]  eta: 1:04:17  lr: 0.000999  loss: 162.7756 (186.7163)  time: 0.5198  data: 0.0013  max mem: 5844\n",
            "Epoch: [1/2]  [1940/9200]  eta: 1:04:13  lr: 0.000999  loss: 198.3709 (186.7342)  time: 0.5650  data: 0.0040  max mem: 5844\n",
            "Epoch: [1/2]  [1950/9200]  eta: 1:04:05  lr: 0.000999  loss: 168.3267 (186.6252)  time: 0.5200  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [1960/9200]  eta: 1:03:59  lr: 0.000999  loss: 159.9945 (186.5105)  time: 0.4897  data: 0.0015  max mem: 5844\n",
            "Epoch: [1/2]  [1970/9200]  eta: 1:03:55  lr: 0.000999  loss: 157.9876 (186.4483)  time: 0.5287  data: 0.0047  max mem: 5844\n",
            "Epoch: [1/2]  [1980/9200]  eta: 1:03:49  lr: 0.000999  loss: 159.4920 (186.4356)  time: 0.5411  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [1990/9200]  eta: 1:03:43  lr: 0.000999  loss: 167.8342 (186.4905)  time: 0.5173  data: 0.0011  max mem: 5844\n",
            "Epoch: [1/2]  [2000/9200]  eta: 1:03:40  lr: 0.000999  loss: 172.7880 (186.5487)  time: 0.5490  data: 0.0026  max mem: 5844\n",
            "Epoch: [1/2]  [2010/9200]  eta: 1:03:35  lr: 0.000999  loss: 178.4993 (186.5626)  time: 0.5724  data: 0.0036  max mem: 5844\n",
            "Epoch: [1/2]  [2020/9200]  eta: 1:03:30  lr: 0.000999  loss: 178.4993 (186.5696)  time: 0.5395  data: 0.0017  max mem: 5844\n",
            "Epoch: [1/2]  [2030/9200]  eta: 1:03:23  lr: 0.000999  loss: 158.8360 (186.5007)  time: 0.5088  data: 0.0019  max mem: 5844\n",
            "Epoch: [1/2]  [2040/9200]  eta: 1:03:20  lr: 0.000999  loss: 168.2789 (186.5189)  time: 0.5413  data: 0.0037  max mem: 5844\n",
            "Epoch: [1/2]  [2050/9200]  eta: 1:03:12  lr: 0.000999  loss: 168.2789 (186.4742)  time: 0.5175  data: 0.0025  max mem: 5844\n",
            "Epoch: [1/2]  [2060/9200]  eta: 1:03:06  lr: 0.000999  loss: 177.9489 (186.5371)  time: 0.4792  data: 0.0007  max mem: 5844\n",
            "Epoch: [1/2]  [2070/9200]  eta: 1:03:01  lr: 0.000999  loss: 191.1342 (186.4816)  time: 0.5353  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [2080/9200]  eta: 1:02:58  lr: 0.000999  loss: 179.9565 (186.5500)  time: 0.5734  data: 0.0042  max mem: 5844\n",
            "Epoch: [1/2]  [2090/9200]  eta: 1:02:53  lr: 0.000999  loss: 185.2696 (186.6377)  time: 0.5595  data: 0.0013  max mem: 5844\n",
            "Epoch: [1/2]  [2100/9200]  eta: 1:02:49  lr: 0.000999  loss: 192.7323 (186.6556)  time: 0.5533  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [2110/9200]  eta: 1:02:44  lr: 0.000999  loss: 176.5911 (186.6547)  time: 0.5621  data: 0.0044  max mem: 5844\n",
            "Epoch: [1/2]  [2120/9200]  eta: 1:02:37  lr: 0.000999  loss: 166.6975 (186.6318)  time: 0.5074  data: 0.0017  max mem: 5844\n",
            "Epoch: [1/2]  [2130/9200]  eta: 1:02:31  lr: 0.000999  loss: 168.5387 (186.5524)  time: 0.4862  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [2140/9200]  eta: 1:02:26  lr: 0.000999  loss: 166.6792 (186.4492)  time: 0.5195  data: 0.0039  max mem: 5844\n",
            "Epoch: [1/2]  [2150/9200]  eta: 1:02:21  lr: 0.000999  loss: 155.0848 (186.4081)  time: 0.5417  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [2160/9200]  eta: 1:02:16  lr: 0.000999  loss: 164.6139 (186.3989)  time: 0.5411  data: 0.0009  max mem: 5844\n",
            "Epoch: [1/2]  [2170/9200]  eta: 1:02:11  lr: 0.000999  loss: 168.4162 (186.3421)  time: 0.5499  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [2180/9200]  eta: 1:02:04  lr: 0.000999  loss: 191.4282 (186.4197)  time: 0.5079  data: 0.0036  max mem: 5844\n",
            "Epoch: [1/2]  [2190/9200]  eta: 1:01:56  lr: 0.000999  loss: 191.4282 (186.4264)  time: 0.4606  data: 0.0003  max mem: 5844\n",
            "Epoch: [1/2]  [2200/9200]  eta: 1:01:54  lr: 0.000999  loss: 170.9920 (186.4597)  time: 0.5526  data: 0.0022  max mem: 5844\n",
            "Epoch: [1/2]  [2210/9200]  eta: 1:01:48  lr: 0.000999  loss: 171.5821 (186.4856)  time: 0.5590  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [2220/9200]  eta: 1:01:41  lr: 0.000999  loss: 171.5821 (186.3664)  time: 0.4912  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [2230/9200]  eta: 1:01:38  lr: 0.000999  loss: 184.5264 (186.4829)  time: 0.5412  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [2240/9200]  eta: 1:01:33  lr: 0.000999  loss: 179.4759 (186.4326)  time: 0.5617  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [2250/9200]  eta: 1:01:27  lr: 0.000999  loss: 167.3372 (186.4340)  time: 0.5253  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [2260/9200]  eta: 1:01:24  lr: 0.000999  loss: 170.7281 (186.4033)  time: 0.5639  data: 0.0020  max mem: 5844\n",
            "Epoch: [1/2]  [2270/9200]  eta: 1:01:17  lr: 0.000999  loss: 170.7281 (186.3731)  time: 0.5532  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [2280/9200]  eta: 1:01:11  lr: 0.000999  loss: 178.6148 (186.4888)  time: 0.4866  data: 0.0013  max mem: 5844\n",
            "Epoch: [1/2]  [2290/9200]  eta: 1:01:08  lr: 0.000999  loss: 193.6091 (186.5551)  time: 0.5484  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [2300/9200]  eta: 1:01:04  lr: 0.000999  loss: 174.5805 (186.5250)  time: 0.5983  data: 0.0026  max mem: 5844\n",
            "Epoch: [1/2]  [2310/9200]  eta: 1:00:58  lr: 0.000999  loss: 174.3707 (186.5482)  time: 0.5392  data: 0.0012  max mem: 5844\n",
            "Epoch: [1/2]  [2320/9200]  eta: 1:00:55  lr: 0.000999  loss: 205.4242 (186.6656)  time: 0.5621  data: 0.0020  max mem: 5844\n",
            "Epoch: [1/2]  [2330/9200]  eta: 1:00:51  lr: 0.000999  loss: 188.1945 (186.6656)  time: 0.6016  data: 0.0041  max mem: 5844\n",
            "Epoch: [1/2]  [2340/9200]  eta: 1:00:43  lr: 0.000999  loss: 160.5915 (186.5377)  time: 0.5069  data: 0.0023  max mem: 5844\n",
            "Epoch: [1/2]  [2350/9200]  eta: 1:00:38  lr: 0.000999  loss: 153.9384 (186.5026)  time: 0.4771  data: 0.0009  max mem: 5844\n",
            "Epoch: [1/2]  [2360/9200]  eta: 1:00:33  lr: 0.000999  loss: 175.0702 (186.4179)  time: 0.5377  data: 0.0040  max mem: 5844\n",
            "Epoch: [1/2]  [2370/9200]  eta: 1:00:25  lr: 0.000999  loss: 175.0702 (186.4320)  time: 0.5055  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [2380/9200]  eta: 1:00:17  lr: 0.000999  loss: 164.4640 (186.3113)  time: 0.4432  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [2390/9200]  eta: 1:00:14  lr: 0.000999  loss: 147.7883 (186.1915)  time: 0.5105  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [2400/9200]  eta: 1:00:08  lr: 0.000999  loss: 148.1168 (186.0947)  time: 0.5452  data: 0.0046  max mem: 5844\n",
            "Epoch: [1/2]  [2410/9200]  eta: 1:00:00  lr: 0.000999  loss: 174.1343 (186.1413)  time: 0.4747  data: 0.0015  max mem: 5844\n",
            "Epoch: [1/2]  [2420/9200]  eta: 0:59:54  lr: 0.000999  loss: 185.8736 (186.1727)  time: 0.4797  data: 0.0011  max mem: 5844\n",
            "Epoch: [1/2]  [2430/9200]  eta: 0:59:50  lr: 0.000999  loss: 173.5039 (186.1347)  time: 0.5450  data: 0.0036  max mem: 5844\n",
            "Epoch: [1/2]  [2440/9200]  eta: 0:59:43  lr: 0.000999  loss: 173.1260 (186.0861)  time: 0.5176  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [2450/9200]  eta: 0:59:36  lr: 0.000999  loss: 180.9420 (186.0505)  time: 0.4657  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [2460/9200]  eta: 0:59:33  lr: 0.000999  loss: 166.4073 (186.0428)  time: 0.5402  data: 0.0047  max mem: 5844\n",
            "Epoch: [1/2]  [2470/9200]  eta: 0:59:26  lr: 0.000999  loss: 177.9263 (186.0292)  time: 0.5496  data: 0.0048  max mem: 5844\n",
            "Epoch: [1/2]  [2480/9200]  eta: 0:59:21  lr: 0.000999  loss: 176.4344 (185.9020)  time: 0.5027  data: 0.0006  max mem: 5844\n",
            "Epoch: [1/2]  [2490/9200]  eta: 0:59:15  lr: 0.000999  loss: 167.5801 (185.8093)  time: 0.5150  data: 0.0023  max mem: 5844\n",
            "Epoch: [1/2]  [2500/9200]  eta: 0:59:10  lr: 0.000999  loss: 167.8115 (185.8067)  time: 0.5274  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [2510/9200]  eta: 0:59:03  lr: 0.000999  loss: 167.8115 (185.7061)  time: 0.5001  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [2520/9200]  eta: 0:58:58  lr: 0.000999  loss: 173.3115 (185.6902)  time: 0.5083  data: 0.0015  max mem: 5844\n",
            "Epoch: [1/2]  [2530/9200]  eta: 0:58:54  lr: 0.000999  loss: 184.2465 (185.8475)  time: 0.5559  data: 0.0041  max mem: 5844\n",
            "Epoch: [1/2]  [2540/9200]  eta: 0:58:47  lr: 0.000999  loss: 192.4272 (185.8263)  time: 0.5152  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [2550/9200]  eta: 0:58:40  lr: 0.000999  loss: 156.2467 (185.7608)  time: 0.4812  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [2560/9200]  eta: 0:58:36  lr: 0.000999  loss: 178.6191 (185.8148)  time: 0.5187  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [2570/9200]  eta: 0:58:29  lr: 0.000999  loss: 178.6191 (185.7343)  time: 0.5124  data: 0.0032  max mem: 5844\n",
            "Epoch: [1/2]  [2580/9200]  eta: 0:58:23  lr: 0.000999  loss: 158.3183 (185.6793)  time: 0.4827  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [2590/9200]  eta: 0:58:19  lr: 0.000999  loss: 179.6275 (185.6663)  time: 0.5432  data: 0.0020  max mem: 5844\n",
            "Epoch: [1/2]  [2600/9200]  eta: 0:58:15  lr: 0.000999  loss: 186.5302 (185.6842)  time: 0.5859  data: 0.0025  max mem: 5844\n",
            "Epoch: [1/2]  [2610/9200]  eta: 0:58:08  lr: 0.000999  loss: 187.8819 (185.7090)  time: 0.5222  data: 0.0008  max mem: 5844\n",
            "Epoch: [1/2]  [2620/9200]  eta: 0:58:03  lr: 0.000999  loss: 177.5627 (185.6687)  time: 0.4922  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [2630/9200]  eta: 0:57:58  lr: 0.000999  loss: 179.1261 (185.6922)  time: 0.5471  data: 0.0040  max mem: 5844\n",
            "Epoch: [1/2]  [2640/9200]  eta: 0:57:52  lr: 0.000999  loss: 179.5226 (185.7093)  time: 0.5383  data: 0.0020  max mem: 5844\n",
            "Epoch: [1/2]  [2650/9200]  eta: 0:57:46  lr: 0.000999  loss: 173.3196 (185.6304)  time: 0.4996  data: 0.0019  max mem: 5844\n",
            "Epoch: [1/2]  [2660/9200]  eta: 0:57:43  lr: 0.000999  loss: 177.0552 (185.6461)  time: 0.5453  data: 0.0045  max mem: 5844\n",
            "Epoch: [1/2]  [2670/9200]  eta: 0:57:38  lr: 0.000999  loss: 180.8992 (185.7092)  time: 0.5683  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [2680/9200]  eta: 0:57:32  lr: 0.000999  loss: 202.0157 (185.8417)  time: 0.5337  data: 0.0012  max mem: 5844\n",
            "Epoch: [1/2]  [2690/9200]  eta: 0:57:29  lr: 0.000999  loss: 203.9472 (185.8862)  time: 0.5589  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [2700/9200]  eta: 0:57:21  lr: 0.000999  loss: 178.1146 (185.8446)  time: 0.5226  data: 0.0036  max mem: 5844\n",
            "Epoch: [1/2]  [2710/9200]  eta: 0:57:14  lr: 0.000999  loss: 181.2602 (185.8456)  time: 0.4449  data: 0.0009  max mem: 5844\n",
            "Epoch: [1/2]  [2720/9200]  eta: 0:57:09  lr: 0.000999  loss: 181.8646 (185.8103)  time: 0.4979  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [2730/9200]  eta: 0:57:03  lr: 0.000999  loss: 177.0963 (185.7784)  time: 0.5272  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [2740/9200]  eta: 0:56:58  lr: 0.000999  loss: 183.9792 (185.8805)  time: 0.5260  data: 0.0020  max mem: 5844\n",
            "Epoch: [1/2]  [2750/9200]  eta: 0:56:54  lr: 0.000999  loss: 183.9792 (185.8623)  time: 0.5485  data: 0.0026  max mem: 5844\n",
            "Epoch: [1/2]  [2760/9200]  eta: 0:56:49  lr: 0.000999  loss: 168.5958 (185.8373)  time: 0.5480  data: 0.0051  max mem: 5844\n",
            "Epoch: [1/2]  [2770/9200]  eta: 0:56:43  lr: 0.000999  loss: 169.1735 (185.8498)  time: 0.5218  data: 0.0030  max mem: 5844\n",
            "Epoch: [1/2]  [2780/9200]  eta: 0:56:36  lr: 0.000999  loss: 182.0808 (185.8345)  time: 0.4934  data: 0.0012  max mem: 5844\n",
            "Epoch: [1/2]  [2790/9200]  eta: 0:56:32  lr: 0.000999  loss: 179.2830 (185.7633)  time: 0.5223  data: 0.0042  max mem: 5844\n",
            "Epoch: [1/2]  [2800/9200]  eta: 0:56:25  lr: 0.000999  loss: 179.7575 (185.8089)  time: 0.5046  data: 0.0032  max mem: 5844\n",
            "Epoch: [1/2]  [2810/9200]  eta: 0:56:18  lr: 0.000999  loss: 174.5111 (185.6719)  time: 0.4670  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [2820/9200]  eta: 0:56:15  lr: 0.000999  loss: 149.1599 (185.6151)  time: 0.5410  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [2830/9200]  eta: 0:56:09  lr: 0.000999  loss: 169.6655 (185.5577)  time: 0.5493  data: 0.0044  max mem: 5844\n",
            "Epoch: [1/2]  [2840/9200]  eta: 0:56:03  lr: 0.000999  loss: 173.1025 (185.5530)  time: 0.5122  data: 0.0009  max mem: 5844\n",
            "Epoch: [1/2]  [2850/9200]  eta: 0:56:01  lr: 0.000999  loss: 191.7079 (185.6834)  time: 0.5928  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [2860/9200]  eta: 0:55:56  lr: 0.000999  loss: 205.8263 (185.7133)  time: 0.6041  data: 0.0041  max mem: 5844\n",
            "Epoch: [1/2]  [2870/9200]  eta: 0:55:49  lr: 0.000999  loss: 170.6828 (185.6173)  time: 0.4979  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [2880/9200]  eta: 0:55:44  lr: 0.000999  loss: 160.7229 (185.6536)  time: 0.4931  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [2890/9200]  eta: 0:55:38  lr: 0.000999  loss: 167.4536 (185.5421)  time: 0.5308  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [2900/9200]  eta: 0:55:34  lr: 0.000999  loss: 167.4536 (185.5039)  time: 0.5359  data: 0.0019  max mem: 5844\n",
            "Epoch: [1/2]  [2910/9200]  eta: 0:55:29  lr: 0.000999  loss: 175.5955 (185.4829)  time: 0.5659  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [2920/9200]  eta: 0:55:25  lr: 0.000999  loss: 193.7838 (185.5815)  time: 0.5814  data: 0.0036  max mem: 5844\n",
            "Epoch: [1/2]  [2930/9200]  eta: 0:55:18  lr: 0.000999  loss: 193.7838 (185.5685)  time: 0.5139  data: 0.0023  max mem: 5844\n",
            "Epoch: [1/2]  [2940/9200]  eta: 0:55:13  lr: 0.000999  loss: 156.7632 (185.4605)  time: 0.4778  data: 0.0009  max mem: 5844\n",
            "Epoch: [1/2]  [2950/9200]  eta: 0:55:09  lr: 0.000999  loss: 166.5079 (185.4916)  time: 0.5703  data: 0.0032  max mem: 5844\n",
            "Epoch: [1/2]  [2960/9200]  eta: 0:55:04  lr: 0.000999  loss: 190.1937 (185.5003)  time: 0.5833  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [2970/9200]  eta: 0:55:00  lr: 0.000999  loss: 191.7799 (185.5423)  time: 0.5519  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [2980/9200]  eta: 0:54:55  lr: 0.000999  loss: 191.9492 (185.5180)  time: 0.5597  data: 0.0044  max mem: 5844\n",
            "Epoch: [1/2]  [2990/9200]  eta: 0:54:48  lr: 0.000999  loss: 163.4383 (185.4580)  time: 0.5117  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [3000/9200]  eta: 0:54:42  lr: 0.000999  loss: 161.8509 (185.4410)  time: 0.4755  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [3010/9200]  eta: 0:54:38  lr: 0.000999  loss: 168.7738 (185.4364)  time: 0.5282  data: 0.0041  max mem: 5844\n",
            "Epoch: [1/2]  [3020/9200]  eta: 0:54:33  lr: 0.000999  loss: 180.2747 (185.4393)  time: 0.5575  data: 0.0061  max mem: 5844\n",
            "Epoch: [1/2]  [3030/9200]  eta: 0:54:27  lr: 0.000999  loss: 179.2757 (185.4601)  time: 0.5298  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [3040/9200]  eta: 0:54:24  lr: 0.000999  loss: 179.2757 (185.5729)  time: 0.5731  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [3050/9200]  eta: 0:54:18  lr: 0.000999  loss: 173.6730 (185.5186)  time: 0.5736  data: 0.0055  max mem: 5844\n",
            "Epoch: [1/2]  [3060/9200]  eta: 0:54:13  lr: 0.000999  loss: 184.6087 (185.6061)  time: 0.5214  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [3070/9200]  eta: 0:54:08  lr: 0.000999  loss: 195.0357 (185.6102)  time: 0.5370  data: 0.0015  max mem: 5844\n",
            "Epoch: [1/2]  [3080/9200]  eta: 0:54:03  lr: 0.000999  loss: 173.4925 (185.5540)  time: 0.5569  data: 0.0045  max mem: 5844\n",
            "Epoch: [1/2]  [3090/9200]  eta: 0:53:56  lr: 0.000999  loss: 176.0264 (185.5239)  time: 0.4972  data: 0.0036  max mem: 5844\n",
            "Epoch: [1/2]  [3100/9200]  eta: 0:53:51  lr: 0.000999  loss: 182.9484 (185.6194)  time: 0.4808  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [3110/9200]  eta: 0:53:46  lr: 0.000999  loss: 182.9484 (185.5954)  time: 0.5429  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [3120/9200]  eta: 0:53:40  lr: 0.000999  loss: 163.2526 (185.6203)  time: 0.5283  data: 0.0045  max mem: 5844\n",
            "Epoch: [1/2]  [3130/9200]  eta: 0:53:34  lr: 0.000999  loss: 170.1602 (185.6253)  time: 0.4935  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [3140/9200]  eta: 0:53:30  lr: 0.000999  loss: 165.6795 (185.6040)  time: 0.5464  data: 0.0026  max mem: 5844\n",
            "Epoch: [1/2]  [3150/9200]  eta: 0:53:25  lr: 0.000999  loss: 165.6795 (185.5981)  time: 0.5824  data: 0.0037  max mem: 5844\n",
            "Epoch: [1/2]  [3160/9200]  eta: 0:53:20  lr: 0.000999  loss: 184.8232 (185.5803)  time: 0.5397  data: 0.0013  max mem: 5844\n",
            "Epoch: [1/2]  [3170/9200]  eta: 0:53:16  lr: 0.000999  loss: 175.6011 (185.5785)  time: 0.5509  data: 0.0030  max mem: 5844\n",
            "Epoch: [1/2]  [3180/9200]  eta: 0:53:11  lr: 0.000999  loss: 175.6011 (185.5925)  time: 0.5842  data: 0.0050  max mem: 5844\n",
            "Epoch: [1/2]  [3190/9200]  eta: 0:53:05  lr: 0.000999  loss: 177.7764 (185.5586)  time: 0.5311  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [3200/9200]  eta: 0:53:00  lr: 0.000999  loss: 193.1999 (185.6135)  time: 0.5148  data: 0.0022  max mem: 5844\n",
            "Epoch: [1/2]  [3210/9200]  eta: 0:52:56  lr: 0.000999  loss: 193.1999 (185.6391)  time: 0.5582  data: 0.0040  max mem: 5844\n",
            "Epoch: [1/2]  [3220/9200]  eta: 0:52:51  lr: 0.000999  loss: 184.7717 (185.7202)  time: 0.5629  data: 0.0019  max mem: 5844\n",
            "Epoch: [1/2]  [3230/9200]  eta: 0:52:46  lr: 0.000999  loss: 181.8611 (185.6819)  time: 0.5555  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [3240/9200]  eta: 0:52:42  lr: 0.000999  loss: 163.1415 (185.7000)  time: 0.5811  data: 0.0048  max mem: 5844\n",
            "Epoch: [1/2]  [3250/9200]  eta: 0:52:37  lr: 0.000999  loss: 188.2726 (185.7374)  time: 0.5652  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [3260/9200]  eta: 0:52:32  lr: 0.000999  loss: 196.4127 (185.7995)  time: 0.5432  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [3270/9200]  eta: 0:52:28  lr: 0.000999  loss: 187.9140 (185.7888)  time: 0.5777  data: 0.0041  max mem: 5844\n",
            "Epoch: [1/2]  [3280/9200]  eta: 0:52:21  lr: 0.000999  loss: 163.2259 (185.7934)  time: 0.5210  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [3290/9200]  eta: 0:52:15  lr: 0.000999  loss: 163.2259 (185.7836)  time: 0.4762  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [3300/9200]  eta: 0:52:09  lr: 0.000999  loss: 161.3290 (185.6508)  time: 0.5038  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [3310/9200]  eta: 0:52:05  lr: 0.000999  loss: 166.4727 (185.6789)  time: 0.5486  data: 0.0046  max mem: 5844\n",
            "Epoch: [1/2]  [3320/9200]  eta: 0:51:58  lr: 0.000999  loss: 190.5274 (185.7593)  time: 0.5183  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [3330/9200]  eta: 0:51:53  lr: 0.000999  loss: 191.5423 (185.7874)  time: 0.5006  data: 0.0013  max mem: 5844\n",
            "Epoch: [1/2]  [3340/9200]  eta: 0:51:49  lr: 0.000999  loss: 195.5590 (185.8773)  time: 0.5683  data: 0.0046  max mem: 5844\n",
            "Epoch: [1/2]  [3350/9200]  eta: 0:51:42  lr: 0.000999  loss: 176.9218 (185.8235)  time: 0.5049  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [3360/9200]  eta: 0:51:37  lr: 0.000999  loss: 167.4475 (185.9054)  time: 0.4806  data: 0.0003  max mem: 5844\n",
            "Epoch: [1/2]  [3370/9200]  eta: 0:51:32  lr: 0.000999  loss: 183.8755 (185.9527)  time: 0.5609  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [3380/9200]  eta: 0:51:27  lr: 0.000999  loss: 177.7900 (185.9496)  time: 0.5414  data: 0.0046  max mem: 5844\n",
            "Epoch: [1/2]  [3390/9200]  eta: 0:51:20  lr: 0.000999  loss: 185.1982 (185.9612)  time: 0.4908  data: 0.0015  max mem: 5844\n",
            "Epoch: [1/2]  [3400/9200]  eta: 0:51:15  lr: 0.000999  loss: 173.1870 (185.9453)  time: 0.5071  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [3410/9200]  eta: 0:51:11  lr: 0.000999  loss: 192.5993 (186.0501)  time: 0.5740  data: 0.0054  max mem: 5844\n",
            "Epoch: [1/2]  [3420/9200]  eta: 0:51:05  lr: 0.000999  loss: 176.8258 (185.9858)  time: 0.5359  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [3430/9200]  eta: 0:51:00  lr: 0.000999  loss: 166.6464 (186.0303)  time: 0.5022  data: 0.0023  max mem: 5844\n",
            "Epoch: [1/2]  [3440/9200]  eta: 0:50:55  lr: 0.000999  loss: 188.6206 (186.0808)  time: 0.5689  data: 0.0044  max mem: 5844\n",
            "Epoch: [1/2]  [3450/9200]  eta: 0:50:50  lr: 0.000999  loss: 188.6206 (186.0914)  time: 0.5630  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [3460/9200]  eta: 0:50:45  lr: 0.000999  loss: 188.2822 (186.0725)  time: 0.5387  data: 0.0020  max mem: 5844\n",
            "Epoch: [1/2]  [3470/9200]  eta: 0:50:40  lr: 0.000999  loss: 183.3971 (186.0427)  time: 0.5557  data: 0.0044  max mem: 5844\n",
            "Epoch: [1/2]  [3480/9200]  eta: 0:50:33  lr: 0.000999  loss: 184.4442 (186.0252)  time: 0.4982  data: 0.0026  max mem: 5844\n",
            "Epoch: [1/2]  [3490/9200]  eta: 0:50:27  lr: 0.000999  loss: 186.8814 (186.0143)  time: 0.4490  data: 0.0006  max mem: 5844\n",
            "Epoch: [1/2]  [3500/9200]  eta: 0:50:22  lr: 0.000999  loss: 189.2591 (186.0813)  time: 0.5156  data: 0.0045  max mem: 5844\n",
            "Epoch: [1/2]  [3510/9200]  eta: 0:50:17  lr: 0.000999  loss: 189.0819 (186.0824)  time: 0.5482  data: 0.0054  max mem: 5844\n",
            "Epoch: [1/2]  [3520/9200]  eta: 0:50:11  lr: 0.000999  loss: 170.8820 (186.0361)  time: 0.5136  data: 0.0015  max mem: 5844\n",
            "Epoch: [1/2]  [3530/9200]  eta: 0:50:06  lr: 0.000999  loss: 160.4906 (185.9238)  time: 0.5044  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [3540/9200]  eta: 0:50:01  lr: 0.000999  loss: 171.1648 (185.9375)  time: 0.5394  data: 0.0055  max mem: 5844\n",
            "Epoch: [1/2]  [3550/9200]  eta: 0:49:55  lr: 0.000999  loss: 178.6895 (185.9719)  time: 0.5434  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [3560/9200]  eta: 0:49:49  lr: 0.000999  loss: 172.4322 (185.9076)  time: 0.5009  data: 0.0009  max mem: 5844\n",
            "Epoch: [1/2]  [3570/9200]  eta: 0:49:45  lr: 0.000999  loss: 179.5265 (185.9361)  time: 0.5490  data: 0.0048  max mem: 5844\n",
            "Epoch: [1/2]  [3580/9200]  eta: 0:49:39  lr: 0.000999  loss: 184.0061 (185.9281)  time: 0.5396  data: 0.0047  max mem: 5844\n",
            "Epoch: [1/2]  [3590/9200]  eta: 0:49:33  lr: 0.000999  loss: 178.6765 (185.9187)  time: 0.4567  data: 0.0008  max mem: 5844\n",
            "Epoch: [1/2]  [3600/9200]  eta: 0:49:29  lr: 0.000999  loss: 178.6765 (185.9652)  time: 0.5370  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [3610/9200]  eta: 0:49:23  lr: 0.000999  loss: 176.8333 (185.9181)  time: 0.5607  data: 0.0052  max mem: 5844\n",
            "Epoch: [1/2]  [3620/9200]  eta: 0:49:17  lr: 0.000999  loss: 161.8647 (185.9023)  time: 0.5026  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [3630/9200]  eta: 0:49:11  lr: 0.000999  loss: 173.1917 (185.8678)  time: 0.4959  data: 0.0008  max mem: 5844\n",
            "Epoch: [1/2]  [3640/9200]  eta: 0:49:07  lr: 0.000999  loss: 174.0434 (185.8268)  time: 0.5303  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [3650/9200]  eta: 0:49:00  lr: 0.000999  loss: 171.7139 (185.7892)  time: 0.5066  data: 0.0030  max mem: 5844\n",
            "Epoch: [1/2]  [3660/9200]  eta: 0:48:53  lr: 0.000999  loss: 171.7139 (185.7570)  time: 0.4414  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [3670/9200]  eta: 0:48:49  lr: 0.000999  loss: 182.0881 (185.8106)  time: 0.5257  data: 0.0020  max mem: 5844\n",
            "Epoch: [1/2]  [3680/9200]  eta: 0:48:44  lr: 0.000999  loss: 172.6879 (185.7928)  time: 0.5679  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [3690/9200]  eta: 0:48:38  lr: 0.000999  loss: 164.9608 (185.7502)  time: 0.5099  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [3700/9200]  eta: 0:48:33  lr: 0.000999  loss: 171.3764 (185.6911)  time: 0.5175  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [3710/9200]  eta: 0:48:28  lr: 0.000999  loss: 173.7768 (185.7246)  time: 0.5543  data: 0.0047  max mem: 5844\n",
            "Epoch: [1/2]  [3720/9200]  eta: 0:48:22  lr: 0.000999  loss: 158.0565 (185.6328)  time: 0.5319  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [3730/9200]  eta: 0:48:18  lr: 0.000999  loss: 173.8546 (185.6786)  time: 0.5540  data: 0.0023  max mem: 5844\n",
            "Epoch: [1/2]  [3740/9200]  eta: 0:48:14  lr: 0.000999  loss: 190.7631 (185.7595)  time: 0.6036  data: 0.0051  max mem: 5844\n",
            "Epoch: [1/2]  [3750/9200]  eta: 0:48:09  lr: 0.000999  loss: 182.2779 (185.8239)  time: 0.5620  data: 0.0030  max mem: 5844\n",
            "Epoch: [1/2]  [3760/9200]  eta: 0:48:03  lr: 0.000999  loss: 153.6275 (185.7674)  time: 0.5085  data: 0.0010  max mem: 5844\n",
            "Epoch: [1/2]  [3770/9200]  eta: 0:47:58  lr: 0.000999  loss: 146.4760 (185.6837)  time: 0.5312  data: 0.0044  max mem: 5844\n",
            "Epoch: [1/2]  [3780/9200]  eta: 0:47:52  lr: 0.000999  loss: 167.6500 (185.6554)  time: 0.5433  data: 0.0039  max mem: 5844\n",
            "Epoch: [1/2]  [3790/9200]  eta: 0:47:47  lr: 0.000999  loss: 183.7041 (185.7021)  time: 0.5134  data: 0.0006  max mem: 5844\n",
            "Epoch: [1/2]  [3800/9200]  eta: 0:47:43  lr: 0.000999  loss: 197.8722 (185.7424)  time: 0.5721  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [3810/9200]  eta: 0:47:38  lr: 0.000999  loss: 195.2220 (185.7542)  time: 0.5714  data: 0.0036  max mem: 5844\n",
            "Epoch: [1/2]  [3820/9200]  eta: 0:47:32  lr: 0.000999  loss: 178.6045 (185.7431)  time: 0.5216  data: 0.0009  max mem: 5844\n",
            "Epoch: [1/2]  [3830/9200]  eta: 0:47:28  lr: 0.000999  loss: 178.6045 (185.7759)  time: 0.5580  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [3840/9200]  eta: 0:47:23  lr: 0.000999  loss: 189.2782 (185.7587)  time: 0.5783  data: 0.0046  max mem: 5844\n",
            "Epoch: [1/2]  [3850/9200]  eta: 0:47:17  lr: 0.000999  loss: 182.9356 (185.7517)  time: 0.5229  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [3860/9200]  eta: 0:47:11  lr: 0.000999  loss: 182.9356 (185.7545)  time: 0.4818  data: 0.0012  max mem: 5844\n",
            "Epoch: [1/2]  [3870/9200]  eta: 0:47:06  lr: 0.000999  loss: 188.0035 (185.7379)  time: 0.5260  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [3880/9200]  eta: 0:47:00  lr: 0.000999  loss: 182.4803 (185.7541)  time: 0.5264  data: 0.0025  max mem: 5844\n",
            "Epoch: [1/2]  [3890/9200]  eta: 0:46:55  lr: 0.000999  loss: 181.8564 (185.7518)  time: 0.4973  data: 0.0023  max mem: 5844\n",
            "Epoch: [1/2]  [3900/9200]  eta: 0:46:50  lr: 0.000999  loss: 179.7077 (185.7509)  time: 0.5437  data: 0.0056  max mem: 5844\n",
            "Epoch: [1/2]  [3910/9200]  eta: 0:46:44  lr: 0.000999  loss: 176.9739 (185.7646)  time: 0.5425  data: 0.0039  max mem: 5844\n",
            "Epoch: [1/2]  [3920/9200]  eta: 0:46:39  lr: 0.000999  loss: 201.0423 (185.7864)  time: 0.5036  data: 0.0003  max mem: 5844\n",
            "Epoch: [1/2]  [3930/9200]  eta: 0:46:34  lr: 0.000999  loss: 187.6787 (185.7780)  time: 0.5441  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [3940/9200]  eta: 0:46:29  lr: 0.000999  loss: 172.2946 (185.7959)  time: 0.5577  data: 0.0045  max mem: 5844\n",
            "Epoch: [1/2]  [3950/9200]  eta: 0:46:23  lr: 0.000999  loss: 183.3926 (185.8256)  time: 0.5201  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [3960/9200]  eta: 0:46:18  lr: 0.000999  loss: 183.3926 (185.8142)  time: 0.5162  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [3970/9200]  eta: 0:46:13  lr: 0.000999  loss: 168.4137 (185.8056)  time: 0.5288  data: 0.0039  max mem: 5844\n",
            "Epoch: [1/2]  [3980/9200]  eta: 0:46:06  lr: 0.000999  loss: 155.8057 (185.7449)  time: 0.4947  data: 0.0017  max mem: 5844\n",
            "Epoch: [1/2]  [3990/9200]  eta: 0:46:01  lr: 0.000999  loss: 176.7225 (185.7490)  time: 0.5077  data: 0.0007  max mem: 5844\n",
            "Epoch: [1/2]  [4000/9200]  eta: 0:45:57  lr: 0.000999  loss: 197.8479 (185.7502)  time: 0.5780  data: 0.0039  max mem: 5844\n",
            "Epoch: [1/2]  [4010/9200]  eta: 0:45:52  lr: 0.000999  loss: 179.6210 (185.7383)  time: 0.5609  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [4020/9200]  eta: 0:45:46  lr: 0.000999  loss: 180.0977 (185.7598)  time: 0.5198  data: 0.0008  max mem: 5844\n",
            "Epoch: [1/2]  [4030/9200]  eta: 0:45:41  lr: 0.000999  loss: 190.3759 (185.8108)  time: 0.5484  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [4040/9200]  eta: 0:45:36  lr: 0.000999  loss: 176.4524 (185.7801)  time: 0.5447  data: 0.0056  max mem: 5844\n",
            "Epoch: [1/2]  [4050/9200]  eta: 0:45:30  lr: 0.000999  loss: 166.7518 (185.7077)  time: 0.4830  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [4060/9200]  eta: 0:45:24  lr: 0.000999  loss: 185.4030 (185.7325)  time: 0.4977  data: 0.0017  max mem: 5844\n",
            "Epoch: [1/2]  [4070/9200]  eta: 0:45:20  lr: 0.000999  loss: 185.4030 (185.7329)  time: 0.5688  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [4080/9200]  eta: 0:45:14  lr: 0.000999  loss: 147.6202 (185.6542)  time: 0.5333  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [4090/9200]  eta: 0:45:08  lr: 0.000999  loss: 147.6202 (185.6547)  time: 0.4885  data: 0.0006  max mem: 5844\n",
            "Epoch: [1/2]  [4100/9200]  eta: 0:45:04  lr: 0.000999  loss: 167.9529 (185.6503)  time: 0.5531  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [4110/9200]  eta: 0:44:58  lr: 0.000999  loss: 162.7688 (185.5763)  time: 0.5194  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [4120/9200]  eta: 0:44:52  lr: 0.000999  loss: 161.3931 (185.5533)  time: 0.4734  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [4130/9200]  eta: 0:44:47  lr: 0.000999  loss: 171.0155 (185.5592)  time: 0.5401  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [4140/9200]  eta: 0:44:42  lr: 0.000999  loss: 175.0917 (185.5215)  time: 0.5661  data: 0.0044  max mem: 5844\n",
            "Epoch: [1/2]  [4150/9200]  eta: 0:44:36  lr: 0.000999  loss: 175.0917 (185.5572)  time: 0.5190  data: 0.0017  max mem: 5844\n",
            "Epoch: [1/2]  [4160/9200]  eta: 0:44:31  lr: 0.000999  loss: 161.8497 (185.5000)  time: 0.5162  data: 0.0019  max mem: 5844\n",
            "Epoch: [1/2]  [4170/9200]  eta: 0:44:26  lr: 0.000999  loss: 169.6615 (185.4976)  time: 0.5359  data: 0.0039  max mem: 5844\n",
            "Epoch: [1/2]  [4180/9200]  eta: 0:44:21  lr: 0.000999  loss: 205.6387 (185.6030)  time: 0.5326  data: 0.0022  max mem: 5844\n",
            "Epoch: [1/2]  [4190/9200]  eta: 0:44:16  lr: 0.000999  loss: 190.9922 (185.6328)  time: 0.5728  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [4200/9200]  eta: 0:44:11  lr: 0.000999  loss: 164.8581 (185.6114)  time: 0.5847  data: 0.0050  max mem: 5844\n",
            "Epoch: [1/2]  [4210/9200]  eta: 0:44:05  lr: 0.000999  loss: 168.4487 (185.5752)  time: 0.5038  data: 0.0032  max mem: 5844\n",
            "Epoch: [1/2]  [4220/9200]  eta: 0:44:00  lr: 0.000999  loss: 171.0373 (185.5517)  time: 0.4785  data: 0.0003  max mem: 5844\n",
            "Epoch: [1/2]  [4230/9200]  eta: 0:43:55  lr: 0.000999  loss: 169.2713 (185.5078)  time: 0.5683  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [4240/9200]  eta: 0:43:50  lr: 0.000999  loss: 183.7016 (185.5486)  time: 0.5953  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [4250/9200]  eta: 0:43:44  lr: 0.000999  loss: 183.7016 (185.5777)  time: 0.5117  data: 0.0006  max mem: 5844\n",
            "Epoch: [1/2]  [4260/9200]  eta: 0:43:40  lr: 0.000999  loss: 178.4716 (185.5912)  time: 0.5212  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [4270/9200]  eta: 0:43:34  lr: 0.000999  loss: 166.8490 (185.6126)  time: 0.5660  data: 0.0053  max mem: 5844\n",
            "Epoch: [1/2]  [4280/9200]  eta: 0:43:29  lr: 0.000999  loss: 178.3620 (185.6798)  time: 0.5153  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [4290/9200]  eta: 0:43:23  lr: 0.000999  loss: 184.1305 (185.6733)  time: 0.5013  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [4300/9200]  eta: 0:43:19  lr: 0.000999  loss: 176.3358 (185.7003)  time: 0.5622  data: 0.0040  max mem: 5844\n",
            "Epoch: [1/2]  [4310/9200]  eta: 0:43:13  lr: 0.000999  loss: 192.9411 (185.6636)  time: 0.5353  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [4320/9200]  eta: 0:43:07  lr: 0.000999  loss: 160.4005 (185.6216)  time: 0.4744  data: 0.0008  max mem: 5844\n",
            "Epoch: [1/2]  [4330/9200]  eta: 0:43:02  lr: 0.000999  loss: 176.9216 (185.6917)  time: 0.5421  data: 0.0048  max mem: 5844\n",
            "Epoch: [1/2]  [4340/9200]  eta: 0:42:56  lr: 0.000999  loss: 184.4311 (185.6808)  time: 0.5318  data: 0.0042  max mem: 5844\n",
            "Epoch: [1/2]  [4350/9200]  eta: 0:42:50  lr: 0.000999  loss: 163.7655 (185.6119)  time: 0.4586  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [4360/9200]  eta: 0:42:46  lr: 0.000999  loss: 170.0385 (185.6172)  time: 0.5191  data: 0.0036  max mem: 5844\n",
            "Epoch: [1/2]  [4370/9200]  eta: 0:42:41  lr: 0.000999  loss: 172.2119 (185.6406)  time: 0.5834  data: 0.0046  max mem: 5844\n",
            "Epoch: [1/2]  [4380/9200]  eta: 0:42:35  lr: 0.000999  loss: 172.2119 (185.6178)  time: 0.5356  data: 0.0013  max mem: 5844\n",
            "Epoch: [1/2]  [4390/9200]  eta: 0:42:30  lr: 0.000999  loss: 173.3856 (185.6053)  time: 0.5444  data: 0.0025  max mem: 5844\n",
            "Epoch: [1/2]  [4400/9200]  eta: 0:42:25  lr: 0.000999  loss: 168.7234 (185.5648)  time: 0.5610  data: 0.0051  max mem: 5844\n",
            "Epoch: [1/2]  [4410/9200]  eta: 0:42:19  lr: 0.000999  loss: 143.9848 (185.5341)  time: 0.4981  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [4420/9200]  eta: 0:42:14  lr: 0.000999  loss: 156.9432 (185.5737)  time: 0.5017  data: 0.0008  max mem: 5844\n",
            "Epoch: [1/2]  [4430/9200]  eta: 0:42:09  lr: 0.000999  loss: 188.0471 (185.5895)  time: 0.5742  data: 0.0044  max mem: 5844\n",
            "Epoch: [1/2]  [4440/9200]  eta: 0:42:04  lr: 0.000999  loss: 177.9714 (185.6008)  time: 0.5710  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [4450/9200]  eta: 0:41:58  lr: 0.000999  loss: 160.4130 (185.5847)  time: 0.4987  data: 0.0006  max mem: 5844\n",
            "Epoch: [1/2]  [4460/9200]  eta: 0:41:53  lr: 0.000999  loss: 162.8182 (185.5802)  time: 0.5172  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [4470/9200]  eta: 0:41:48  lr: 0.000999  loss: 182.3127 (185.6685)  time: 0.5696  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [4480/9200]  eta: 0:41:42  lr: 0.000999  loss: 225.0588 (185.7193)  time: 0.5236  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [4490/9200]  eta: 0:41:38  lr: 0.000999  loss: 198.3262 (185.7692)  time: 0.5607  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [4500/9200]  eta: 0:41:32  lr: 0.000999  loss: 185.0304 (185.7758)  time: 0.5567  data: 0.0041  max mem: 5844\n",
            "Epoch: [1/2]  [4510/9200]  eta: 0:41:27  lr: 0.000999  loss: 159.5984 (185.7679)  time: 0.4929  data: 0.0008  max mem: 5844\n",
            "Epoch: [1/2]  [4520/9200]  eta: 0:41:23  lr: 0.000999  loss: 173.3139 (185.7527)  time: 0.5667  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [4530/9200]  eta: 0:41:17  lr: 0.000999  loss: 154.3723 (185.6523)  time: 0.5635  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [4540/9200]  eta: 0:41:11  lr: 0.000999  loss: 145.5019 (185.6551)  time: 0.4968  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [4550/9200]  eta: 0:41:06  lr: 0.000999  loss: 155.1203 (185.5821)  time: 0.4940  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [4560/9200]  eta: 0:41:01  lr: 0.000999  loss: 148.0516 (185.5403)  time: 0.5432  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [4570/9200]  eta: 0:40:55  lr: 0.000999  loss: 168.9166 (185.4982)  time: 0.5190  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [4580/9200]  eta: 0:40:49  lr: 0.000999  loss: 169.3077 (185.4511)  time: 0.4818  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [4590/9200]  eta: 0:40:45  lr: 0.000999  loss: 196.3001 (185.5199)  time: 0.5804  data: 0.0041  max mem: 5844\n",
            "Epoch: [1/2]  [4600/9200]  eta: 0:40:40  lr: 0.000999  loss: 174.8308 (185.4882)  time: 0.5906  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [4610/9200]  eta: 0:40:34  lr: 0.000999  loss: 163.4587 (185.4818)  time: 0.5121  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [4620/9200]  eta: 0:40:30  lr: 0.000999  loss: 157.8098 (185.4415)  time: 0.5407  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [4630/9200]  eta: 0:40:24  lr: 0.000999  loss: 162.2884 (185.4611)  time: 0.5587  data: 0.0051  max mem: 5844\n",
            "Epoch: [1/2]  [4640/9200]  eta: 0:40:18  lr: 0.000999  loss: 167.7966 (185.4230)  time: 0.5055  data: 0.0019  max mem: 5844\n",
            "Epoch: [1/2]  [4650/9200]  eta: 0:40:13  lr: 0.000999  loss: 171.0640 (185.4442)  time: 0.5077  data: 0.0015  max mem: 5844\n",
            "Epoch: [1/2]  [4660/9200]  eta: 0:40:08  lr: 0.000999  loss: 163.2442 (185.4113)  time: 0.5279  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [4670/9200]  eta: 0:40:02  lr: 0.000999  loss: 159.5000 (185.3780)  time: 0.4947  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [4680/9200]  eta: 0:39:56  lr: 0.000999  loss: 177.5782 (185.3638)  time: 0.4934  data: 0.0010  max mem: 5844\n",
            "Epoch: [1/2]  [4690/9200]  eta: 0:39:52  lr: 0.000999  loss: 170.9192 (185.3219)  time: 0.5501  data: 0.0048  max mem: 5844\n",
            "Epoch: [1/2]  [4700/9200]  eta: 0:39:46  lr: 0.000999  loss: 171.3874 (185.3298)  time: 0.5531  data: 0.0047  max mem: 5844\n",
            "Epoch: [1/2]  [4710/9200]  eta: 0:39:41  lr: 0.000999  loss: 179.7568 (185.3601)  time: 0.5011  data: 0.0009  max mem: 5844\n",
            "Epoch: [1/2]  [4720/9200]  eta: 0:39:35  lr: 0.000999  loss: 171.4428 (185.3306)  time: 0.4985  data: 0.0030  max mem: 5844\n",
            "Epoch: [1/2]  [4730/9200]  eta: 0:39:31  lr: 0.000999  loss: 158.2451 (185.3291)  time: 0.5644  data: 0.0040  max mem: 5844\n",
            "Epoch: [1/2]  [4740/9200]  eta: 0:39:24  lr: 0.000999  loss: 159.3488 (185.2986)  time: 0.5322  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [4750/9200]  eta: 0:39:19  lr: 0.000999  loss: 163.8030 (185.2589)  time: 0.4523  data: 0.0017  max mem: 5844\n",
            "Epoch: [1/2]  [4760/9200]  eta: 0:39:14  lr: 0.000999  loss: 159.4128 (185.2567)  time: 0.5271  data: 0.0052  max mem: 5844\n",
            "Epoch: [1/2]  [4770/9200]  eta: 0:39:08  lr: 0.000999  loss: 186.1512 (185.2567)  time: 0.5384  data: 0.0044  max mem: 5844\n",
            "Epoch: [1/2]  [4780/9200]  eta: 0:39:02  lr: 0.000999  loss: 194.6854 (185.2475)  time: 0.4765  data: 0.0007  max mem: 5844\n",
            "Epoch: [1/2]  [4790/9200]  eta: 0:38:58  lr: 0.000999  loss: 196.3876 (185.3496)  time: 0.5411  data: 0.0012  max mem: 5844\n",
            "Epoch: [1/2]  [4800/9200]  eta: 0:38:53  lr: 0.000999  loss: 196.5754 (185.3292)  time: 0.5780  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [4810/9200]  eta: 0:38:47  lr: 0.000999  loss: 187.6777 (185.3304)  time: 0.5193  data: 0.0011  max mem: 5844\n",
            "Epoch: [1/2]  [4820/9200]  eta: 0:38:42  lr: 0.000999  loss: 185.3097 (185.3317)  time: 0.5397  data: 0.0020  max mem: 5844\n",
            "Epoch: [1/2]  [4830/9200]  eta: 0:38:37  lr: 0.000999  loss: 185.3097 (185.3901)  time: 0.5786  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [4840/9200]  eta: 0:38:32  lr: 0.000999  loss: 197.4264 (185.4144)  time: 0.5520  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [4850/9200]  eta: 0:38:27  lr: 0.000999  loss: 180.1364 (185.4164)  time: 0.5460  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [4860/9200]  eta: 0:38:22  lr: 0.000999  loss: 172.5884 (185.4190)  time: 0.5550  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [4870/9200]  eta: 0:38:16  lr: 0.000999  loss: 175.2112 (185.4049)  time: 0.5297  data: 0.0022  max mem: 5844\n",
            "Epoch: [1/2]  [4880/9200]  eta: 0:38:11  lr: 0.000999  loss: 175.2112 (185.3851)  time: 0.5358  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [4890/9200]  eta: 0:38:06  lr: 0.000999  loss: 177.2575 (185.3888)  time: 0.5529  data: 0.0053  max mem: 5844\n",
            "Epoch: [1/2]  [4900/9200]  eta: 0:38:01  lr: 0.000999  loss: 188.9557 (185.4139)  time: 0.5282  data: 0.0037  max mem: 5844\n",
            "Epoch: [1/2]  [4910/9200]  eta: 0:37:55  lr: 0.000999  loss: 158.6291 (185.3566)  time: 0.4865  data: 0.0006  max mem: 5844\n",
            "Epoch: [1/2]  [4920/9200]  eta: 0:37:50  lr: 0.000999  loss: 176.9538 (185.3912)  time: 0.5396  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [4930/9200]  eta: 0:37:44  lr: 0.000999  loss: 179.6247 (185.3589)  time: 0.5452  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [4940/9200]  eta: 0:37:39  lr: 0.000999  loss: 168.4106 (185.3510)  time: 0.4827  data: 0.0013  max mem: 5844\n",
            "Epoch: [1/2]  [4950/9200]  eta: 0:37:33  lr: 0.000999  loss: 168.4106 (185.3268)  time: 0.4992  data: 0.0019  max mem: 5844\n",
            "Epoch: [1/2]  [4960/9200]  eta: 0:37:28  lr: 0.000999  loss: 166.1346 (185.3018)  time: 0.5307  data: 0.0040  max mem: 5844\n",
            "Epoch: [1/2]  [4970/9200]  eta: 0:37:22  lr: 0.000999  loss: 165.3840 (185.2696)  time: 0.5117  data: 0.0023  max mem: 5844\n",
            "Epoch: [1/2]  [4980/9200]  eta: 0:37:17  lr: 0.000999  loss: 165.3840 (185.2500)  time: 0.4844  data: 0.0006  max mem: 5844\n",
            "Epoch: [1/2]  [4990/9200]  eta: 0:37:12  lr: 0.000999  loss: 174.9218 (185.2421)  time: 0.5479  data: 0.0032  max mem: 5844\n",
            "Epoch: [1/2]  [5000/9200]  eta: 0:37:06  lr: 0.000999  loss: 180.8631 (185.2428)  time: 0.5492  data: 0.0037  max mem: 5844\n",
            "Epoch: [1/2]  [5010/9200]  eta: 0:37:01  lr: 0.000999  loss: 188.8887 (185.2658)  time: 0.5083  data: 0.0012  max mem: 5844\n",
            "Epoch: [1/2]  [5020/9200]  eta: 0:36:56  lr: 0.000999  loss: 181.4631 (185.2593)  time: 0.5277  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [5030/9200]  eta: 0:36:51  lr: 0.000999  loss: 175.5870 (185.2831)  time: 0.5476  data: 0.0040  max mem: 5844\n",
            "Epoch: [1/2]  [5040/9200]  eta: 0:36:45  lr: 0.000999  loss: 181.6402 (185.2904)  time: 0.5123  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [5050/9200]  eta: 0:36:39  lr: 0.000999  loss: 167.8684 (185.3462)  time: 0.5000  data: 0.0012  max mem: 5844\n",
            "Epoch: [1/2]  [5060/9200]  eta: 0:36:34  lr: 0.000999  loss: 174.5519 (185.3348)  time: 0.5460  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [5070/9200]  eta: 0:36:29  lr: 0.000999  loss: 182.8543 (185.3455)  time: 0.5459  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [5080/9200]  eta: 0:36:24  lr: 0.000999  loss: 198.4413 (185.3821)  time: 0.5429  data: 0.0011  max mem: 5844\n",
            "Epoch: [1/2]  [5090/9200]  eta: 0:36:19  lr: 0.000999  loss: 181.0445 (185.3889)  time: 0.5852  data: 0.0051  max mem: 5844\n",
            "Epoch: [1/2]  [5100/9200]  eta: 0:36:13  lr: 0.000999  loss: 158.9655 (185.3292)  time: 0.5282  data: 0.0042  max mem: 5844\n",
            "Epoch: [1/2]  [5110/9200]  eta: 0:36:08  lr: 0.000999  loss: 158.9655 (185.3712)  time: 0.4508  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [5120/9200]  eta: 0:36:02  lr: 0.000999  loss: 183.5927 (185.3312)  time: 0.4773  data: 0.0018  max mem: 5844\n",
            "Epoch: [1/2]  [5130/9200]  eta: 0:35:57  lr: 0.000999  loss: 178.5645 (185.3436)  time: 0.5192  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [5140/9200]  eta: 0:35:51  lr: 0.000999  loss: 193.3952 (185.3027)  time: 0.4767  data: 0.0023  max mem: 5844\n",
            "Epoch: [1/2]  [5150/9200]  eta: 0:35:46  lr: 0.000999  loss: 157.1535 (185.3116)  time: 0.4996  data: 0.0015  max mem: 5844\n",
            "Epoch: [1/2]  [5160/9200]  eta: 0:35:41  lr: 0.000999  loss: 157.1535 (185.2905)  time: 0.5728  data: 0.0053  max mem: 5844\n",
            "Epoch: [1/2]  [5170/9200]  eta: 0:35:35  lr: 0.000999  loss: 165.7610 (185.2846)  time: 0.5011  data: 0.0041  max mem: 5844\n",
            "Epoch: [1/2]  [5180/9200]  eta: 0:35:29  lr: 0.000999  loss: 168.6911 (185.2643)  time: 0.4414  data: 0.0003  max mem: 5844\n",
            "Epoch: [1/2]  [5190/9200]  eta: 0:35:24  lr: 0.000999  loss: 184.7547 (185.2730)  time: 0.5128  data: 0.0017  max mem: 5844\n",
            "Epoch: [1/2]  [5200/9200]  eta: 0:35:19  lr: 0.000999  loss: 179.9050 (185.2596)  time: 0.5709  data: 0.0040  max mem: 5844\n",
            "Epoch: [1/2]  [5210/9200]  eta: 0:35:13  lr: 0.000999  loss: 179.9050 (185.2688)  time: 0.5163  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [5220/9200]  eta: 0:35:08  lr: 0.000999  loss: 189.9614 (185.2779)  time: 0.5025  data: 0.0017  max mem: 5844\n",
            "Epoch: [1/2]  [5230/9200]  eta: 0:35:03  lr: 0.000999  loss: 174.8747 (185.2659)  time: 0.5680  data: 0.0044  max mem: 5844\n",
            "Epoch: [1/2]  [5240/9200]  eta: 0:34:57  lr: 0.000999  loss: 166.5122 (185.2853)  time: 0.5556  data: 0.0032  max mem: 5844\n",
            "Epoch: [1/2]  [5250/9200]  eta: 0:34:53  lr: 0.000999  loss: 177.6533 (185.3112)  time: 0.5394  data: 0.0008  max mem: 5844\n",
            "Epoch: [1/2]  [5260/9200]  eta: 0:34:48  lr: 0.000999  loss: 165.8711 (185.2790)  time: 0.5753  data: 0.0039  max mem: 5844\n",
            "Epoch: [1/2]  [5270/9200]  eta: 0:34:42  lr: 0.000999  loss: 154.2751 (185.2499)  time: 0.5082  data: 0.0032  max mem: 5844\n",
            "Epoch: [1/2]  [5280/9200]  eta: 0:34:36  lr: 0.000999  loss: 177.6534 (185.2679)  time: 0.4432  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [5290/9200]  eta: 0:34:31  lr: 0.000999  loss: 180.9309 (185.2764)  time: 0.5092  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [5300/9200]  eta: 0:34:26  lr: 0.000999  loss: 164.4610 (185.2236)  time: 0.5594  data: 0.0048  max mem: 5844\n",
            "Epoch: [1/2]  [5310/9200]  eta: 0:34:20  lr: 0.000999  loss: 150.3155 (185.1728)  time: 0.4945  data: 0.0022  max mem: 5844\n",
            "Epoch: [1/2]  [5320/9200]  eta: 0:34:14  lr: 0.000999  loss: 175.9375 (185.1887)  time: 0.4894  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [5330/9200]  eta: 0:34:10  lr: 0.000999  loss: 174.6204 (185.1713)  time: 0.5727  data: 0.0049  max mem: 5844\n",
            "Epoch: [1/2]  [5340/9200]  eta: 0:34:04  lr: 0.000999  loss: 174.6204 (185.1886)  time: 0.5770  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [5350/9200]  eta: 0:33:59  lr: 0.000999  loss: 196.1066 (185.2280)  time: 0.5244  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [5360/9200]  eta: 0:33:54  lr: 0.000999  loss: 170.6695 (185.2305)  time: 0.5625  data: 0.0032  max mem: 5844\n",
            "Epoch: [1/2]  [5370/9200]  eta: 0:33:49  lr: 0.000999  loss: 165.2692 (185.2364)  time: 0.5583  data: 0.0036  max mem: 5844\n",
            "Epoch: [1/2]  [5380/9200]  eta: 0:33:44  lr: 0.000999  loss: 175.6997 (185.2382)  time: 0.5210  data: 0.0011  max mem: 5844\n",
            "Epoch: [1/2]  [5390/9200]  eta: 0:33:39  lr: 0.000999  loss: 153.3098 (185.2000)  time: 0.6056  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [5400/9200]  eta: 0:33:34  lr: 0.000999  loss: 182.1047 (185.2136)  time: 0.5872  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [5410/9200]  eta: 0:33:29  lr: 0.000999  loss: 182.5051 (185.2293)  time: 0.5209  data: 0.0008  max mem: 5844\n",
            "Epoch: [1/2]  [5420/9200]  eta: 0:33:24  lr: 0.000999  loss: 181.6619 (185.2567)  time: 0.5688  data: 0.0019  max mem: 5844\n",
            "Epoch: [1/2]  [5430/9200]  eta: 0:33:18  lr: 0.000999  loss: 170.2196 (185.2494)  time: 0.5476  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [5440/9200]  eta: 0:33:12  lr: 0.000999  loss: 176.7897 (185.2672)  time: 0.4723  data: 0.0011  max mem: 5844\n",
            "Epoch: [1/2]  [5450/9200]  eta: 0:33:07  lr: 0.000999  loss: 183.1293 (185.2809)  time: 0.5222  data: 0.0015  max mem: 5844\n",
            "Epoch: [1/2]  [5460/9200]  eta: 0:33:02  lr: 0.000999  loss: 179.1089 (185.2652)  time: 0.5762  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [5470/9200]  eta: 0:32:57  lr: 0.000999  loss: 174.3245 (185.2412)  time: 0.5112  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [5480/9200]  eta: 0:32:51  lr: 0.000999  loss: 179.3760 (185.2711)  time: 0.4901  data: 0.0013  max mem: 5844\n",
            "Epoch: [1/2]  [5490/9200]  eta: 0:32:46  lr: 0.000999  loss: 184.4281 (185.2672)  time: 0.5484  data: 0.0048  max mem: 5844\n",
            "Epoch: [1/2]  [5500/9200]  eta: 0:32:41  lr: 0.000999  loss: 170.2230 (185.2540)  time: 0.5426  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [5510/9200]  eta: 0:32:35  lr: 0.000999  loss: 183.5504 (185.2597)  time: 0.5018  data: 0.0003  max mem: 5844\n",
            "Epoch: [1/2]  [5520/9200]  eta: 0:32:30  lr: 0.000999  loss: 178.4831 (185.2359)  time: 0.5449  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [5530/9200]  eta: 0:32:25  lr: 0.000999  loss: 178.4831 (185.2630)  time: 0.5550  data: 0.0040  max mem: 5844\n",
            "Epoch: [1/2]  [5540/9200]  eta: 0:32:19  lr: 0.000999  loss: 181.0424 (185.2470)  time: 0.5058  data: 0.0004  max mem: 5844\n",
            "Epoch: [1/2]  [5550/9200]  eta: 0:32:14  lr: 0.000999  loss: 160.9869 (185.1870)  time: 0.5313  data: 0.0022  max mem: 5844\n",
            "Epoch: [1/2]  [5560/9200]  eta: 0:32:09  lr: 0.000999  loss: 160.9869 (185.1904)  time: 0.5685  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [5570/9200]  eta: 0:32:04  lr: 0.000999  loss: 176.2117 (185.1798)  time: 0.5108  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [5580/9200]  eta: 0:31:59  lr: 0.000999  loss: 198.0128 (185.2484)  time: 0.5283  data: 0.0023  max mem: 5844\n",
            "Epoch: [1/2]  [5590/9200]  eta: 0:31:53  lr: 0.000999  loss: 195.2022 (185.2326)  time: 0.5521  data: 0.0052  max mem: 5844\n",
            "Epoch: [1/2]  [5600/9200]  eta: 0:31:47  lr: 0.000999  loss: 178.4219 (185.2406)  time: 0.4809  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [5610/9200]  eta: 0:31:42  lr: 0.000999  loss: 190.3271 (185.2391)  time: 0.4781  data: 0.0006  max mem: 5844\n",
            "Epoch: [1/2]  [5620/9200]  eta: 0:31:37  lr: 0.000999  loss: 175.2116 (185.2493)  time: 0.5441  data: 0.0041  max mem: 5844\n",
            "Epoch: [1/2]  [5630/9200]  eta: 0:31:31  lr: 0.000999  loss: 175.2116 (185.2412)  time: 0.5369  data: 0.0039  max mem: 5844\n",
            "Epoch: [1/2]  [5640/9200]  eta: 0:31:26  lr: 0.000999  loss: 181.7773 (185.2519)  time: 0.4755  data: 0.0003  max mem: 5844\n",
            "Epoch: [1/2]  [5650/9200]  eta: 0:31:21  lr: 0.000999  loss: 183.8979 (185.2283)  time: 0.5202  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [5660/9200]  eta: 0:31:16  lr: 0.000999  loss: 183.8979 (185.2579)  time: 0.5584  data: 0.0047  max mem: 5844\n",
            "Epoch: [1/2]  [5670/9200]  eta: 0:31:10  lr: 0.000999  loss: 173.1278 (185.2723)  time: 0.5281  data: 0.0017  max mem: 5844\n",
            "Epoch: [1/2]  [5680/9200]  eta: 0:31:05  lr: 0.000999  loss: 177.1220 (185.2966)  time: 0.5394  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [5690/9200]  eta: 0:31:00  lr: 0.000999  loss: 192.5962 (185.3039)  time: 0.5601  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [5700/9200]  eta: 0:30:54  lr: 0.000999  loss: 166.0504 (185.2682)  time: 0.4936  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [5710/9200]  eta: 0:30:48  lr: 0.000999  loss: 166.0504 (185.2769)  time: 0.4610  data: 0.0004  max mem: 5844\n",
            "Epoch: [1/2]  [5720/9200]  eta: 0:30:43  lr: 0.000999  loss: 181.2464 (185.2902)  time: 0.5260  data: 0.0042  max mem: 5844\n",
            "Epoch: [1/2]  [5730/9200]  eta: 0:30:38  lr: 0.000999  loss: 174.9911 (185.2624)  time: 0.5252  data: 0.0045  max mem: 5844\n",
            "Epoch: [1/2]  [5740/9200]  eta: 0:30:32  lr: 0.000999  loss: 179.7339 (185.2873)  time: 0.4884  data: 0.0013  max mem: 5844\n",
            "Epoch: [1/2]  [5750/9200]  eta: 0:30:27  lr: 0.000999  loss: 179.7339 (185.2886)  time: 0.5246  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [5760/9200]  eta: 0:30:22  lr: 0.000999  loss: 174.0609 (185.2742)  time: 0.5425  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [5770/9200]  eta: 0:30:16  lr: 0.000999  loss: 186.1230 (185.2783)  time: 0.5129  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [5780/9200]  eta: 0:30:11  lr: 0.000999  loss: 175.4765 (185.2580)  time: 0.4989  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [5790/9200]  eta: 0:30:06  lr: 0.000999  loss: 149.8402 (185.2308)  time: 0.5314  data: 0.0049  max mem: 5844\n",
            "Epoch: [1/2]  [5800/9200]  eta: 0:30:00  lr: 0.000999  loss: 155.0276 (185.1909)  time: 0.5314  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [5810/9200]  eta: 0:29:55  lr: 0.000999  loss: 199.2250 (185.2572)  time: 0.5536  data: 0.0009  max mem: 5844\n",
            "Epoch: [1/2]  [5820/9200]  eta: 0:29:50  lr: 0.000999  loss: 197.1685 (185.2358)  time: 0.5891  data: 0.0030  max mem: 5844\n",
            "Epoch: [1/2]  [5830/9200]  eta: 0:29:45  lr: 0.000999  loss: 161.9125 (185.2210)  time: 0.5220  data: 0.0026  max mem: 5844\n",
            "Epoch: [1/2]  [5840/9200]  eta: 0:29:40  lr: 0.000999  loss: 175.1107 (185.2173)  time: 0.5041  data: 0.0004  max mem: 5844\n",
            "Epoch: [1/2]  [5850/9200]  eta: 0:29:35  lr: 0.000999  loss: 175.1107 (185.1879)  time: 0.5751  data: 0.0036  max mem: 5844\n",
            "Epoch: [1/2]  [5860/9200]  eta: 0:29:29  lr: 0.000999  loss: 176.3922 (185.1784)  time: 0.5382  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [5870/9200]  eta: 0:29:23  lr: 0.000999  loss: 169.4546 (185.1393)  time: 0.4672  data: 0.0004  max mem: 5844\n",
            "Epoch: [1/2]  [5880/9200]  eta: 0:29:19  lr: 0.000999  loss: 169.4546 (185.1310)  time: 0.5381  data: 0.0025  max mem: 5844\n",
            "Epoch: [1/2]  [5890/9200]  eta: 0:29:13  lr: 0.000999  loss: 181.5488 (185.1333)  time: 0.5536  data: 0.0032  max mem: 5844\n",
            "Epoch: [1/2]  [5900/9200]  eta: 0:29:08  lr: 0.000999  loss: 181.3865 (185.1409)  time: 0.5204  data: 0.0011  max mem: 5844\n",
            "Epoch: [1/2]  [5910/9200]  eta: 0:29:03  lr: 0.000999  loss: 181.3865 (185.1431)  time: 0.5469  data: 0.0020  max mem: 5844\n",
            "Epoch: [1/2]  [5920/9200]  eta: 0:28:57  lr: 0.000999  loss: 186.3025 (185.1524)  time: 0.5458  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [5930/9200]  eta: 0:28:52  lr: 0.000999  loss: 182.5031 (185.1113)  time: 0.4986  data: 0.0025  max mem: 5844\n",
            "Epoch: [1/2]  [5940/9200]  eta: 0:28:46  lr: 0.000999  loss: 149.2969 (185.0570)  time: 0.4803  data: 0.0007  max mem: 5844\n",
            "Epoch: [1/2]  [5950/9200]  eta: 0:28:41  lr: 0.000999  loss: 142.3081 (185.0100)  time: 0.5563  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [5960/9200]  eta: 0:28:36  lr: 0.000999  loss: 139.0405 (184.9497)  time: 0.5390  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [5970/9200]  eta: 0:28:31  lr: 0.000999  loss: 173.0423 (184.9798)  time: 0.5160  data: 0.0009  max mem: 5844\n",
            "Epoch: [1/2]  [5980/9200]  eta: 0:28:25  lr: 0.000999  loss: 167.6280 (184.9100)  time: 0.5481  data: 0.0046  max mem: 5844\n",
            "Epoch: [1/2]  [5990/9200]  eta: 0:28:20  lr: 0.000999  loss: 153.0739 (184.8806)  time: 0.5064  data: 0.0047  max mem: 5844\n",
            "Epoch: [1/2]  [6000/9200]  eta: 0:28:14  lr: 0.000999  loss: 145.3092 (184.8279)  time: 0.4808  data: 0.0011  max mem: 5844\n",
            "Epoch: [1/2]  [6010/9200]  eta: 0:28:09  lr: 0.000999  loss: 167.4425 (184.8019)  time: 0.5218  data: 0.0023  max mem: 5844\n",
            "Epoch: [1/2]  [6020/9200]  eta: 0:28:04  lr: 0.000999  loss: 177.4185 (184.8192)  time: 0.5681  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [6030/9200]  eta: 0:27:58  lr: 0.000999  loss: 187.0089 (184.8136)  time: 0.5222  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [6040/9200]  eta: 0:27:53  lr: 0.000999  loss: 167.8881 (184.7851)  time: 0.4915  data: 0.0015  max mem: 5844\n",
            "Epoch: [1/2]  [6050/9200]  eta: 0:27:48  lr: 0.000999  loss: 172.6161 (184.7823)  time: 0.5700  data: 0.0037  max mem: 5844\n",
            "Epoch: [1/2]  [6060/9200]  eta: 0:27:42  lr: 0.000999  loss: 153.7889 (184.7382)  time: 0.5272  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [6070/9200]  eta: 0:27:37  lr: 0.000999  loss: 155.8220 (184.7474)  time: 0.4439  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [6080/9200]  eta: 0:27:32  lr: 0.000999  loss: 189.5458 (184.7413)  time: 0.5407  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [6090/9200]  eta: 0:27:26  lr: 0.000999  loss: 171.9833 (184.7132)  time: 0.5403  data: 0.0054  max mem: 5844\n",
            "Epoch: [1/2]  [6100/9200]  eta: 0:27:21  lr: 0.000999  loss: 168.4531 (184.6774)  time: 0.4630  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [6110/9200]  eta: 0:27:15  lr: 0.000999  loss: 149.0481 (184.6269)  time: 0.4746  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [6120/9200]  eta: 0:27:11  lr: 0.000999  loss: 183.3019 (184.6560)  time: 0.5695  data: 0.0044  max mem: 5844\n",
            "Epoch: [1/2]  [6130/9200]  eta: 0:27:05  lr: 0.000999  loss: 193.2443 (184.6428)  time: 0.5764  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [6140/9200]  eta: 0:27:00  lr: 0.000999  loss: 161.6070 (184.6233)  time: 0.5388  data: 0.0011  max mem: 5844\n",
            "Epoch: [1/2]  [6150/9200]  eta: 0:26:55  lr: 0.000999  loss: 164.1117 (184.5939)  time: 0.5780  data: 0.0040  max mem: 5844\n",
            "Epoch: [1/2]  [6160/9200]  eta: 0:26:50  lr: 0.000999  loss: 175.1469 (184.5920)  time: 0.5545  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [6170/9200]  eta: 0:26:44  lr: 0.000999  loss: 163.8758 (184.5503)  time: 0.5263  data: 0.0017  max mem: 5844\n",
            "Epoch: [1/2]  [6180/9200]  eta: 0:26:39  lr: 0.000999  loss: 151.2099 (184.5027)  time: 0.5397  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [6190/9200]  eta: 0:26:34  lr: 0.000999  loss: 173.7467 (184.5651)  time: 0.5499  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [6200/9200]  eta: 0:26:28  lr: 0.000999  loss: 168.0100 (184.5249)  time: 0.5160  data: 0.0008  max mem: 5844\n",
            "Epoch: [1/2]  [6210/9200]  eta: 0:26:24  lr: 0.000999  loss: 164.2835 (184.5572)  time: 0.5628  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [6220/9200]  eta: 0:26:18  lr: 0.000999  loss: 168.8633 (184.5384)  time: 0.5426  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [6230/9200]  eta: 0:26:13  lr: 0.000999  loss: 166.3657 (184.5378)  time: 0.4888  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [6240/9200]  eta: 0:26:08  lr: 0.000999  loss: 176.7000 (184.5347)  time: 0.5711  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [6250/9200]  eta: 0:26:03  lr: 0.000999  loss: 167.3679 (184.4976)  time: 0.5802  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [6260/9200]  eta: 0:25:57  lr: 0.000999  loss: 163.1990 (184.4927)  time: 0.5053  data: 0.0009  max mem: 5844\n",
            "Epoch: [1/2]  [6270/9200]  eta: 0:25:52  lr: 0.000999  loss: 176.6051 (184.4864)  time: 0.5038  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [6280/9200]  eta: 0:25:46  lr: 0.000999  loss: 176.6051 (184.4740)  time: 0.5437  data: 0.0058  max mem: 5844\n",
            "Epoch: [1/2]  [6290/9200]  eta: 0:25:41  lr: 0.000999  loss: 172.7646 (184.4601)  time: 0.4965  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [6300/9200]  eta: 0:25:36  lr: 0.000999  loss: 172.8314 (184.4589)  time: 0.5025  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [6310/9200]  eta: 0:25:31  lr: 0.000999  loss: 181.3151 (184.4845)  time: 0.5764  data: 0.0040  max mem: 5844\n",
            "Epoch: [1/2]  [6320/9200]  eta: 0:25:25  lr: 0.000999  loss: 195.5624 (184.4808)  time: 0.5334  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [6330/9200]  eta: 0:25:19  lr: 0.000999  loss: 165.8549 (184.4473)  time: 0.4483  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [6340/9200]  eta: 0:25:14  lr: 0.000999  loss: 180.4169 (184.4594)  time: 0.5136  data: 0.0030  max mem: 5844\n",
            "Epoch: [1/2]  [6350/9200]  eta: 0:25:09  lr: 0.000999  loss: 179.9048 (184.4347)  time: 0.5600  data: 0.0036  max mem: 5844\n",
            "Epoch: [1/2]  [6360/9200]  eta: 0:25:04  lr: 0.000999  loss: 169.9325 (184.4459)  time: 0.5135  data: 0.0008  max mem: 5844\n",
            "Epoch: [1/2]  [6370/9200]  eta: 0:24:59  lr: 0.000999  loss: 184.0347 (184.4634)  time: 0.5472  data: 0.0022  max mem: 5844\n",
            "Epoch: [1/2]  [6380/9200]  eta: 0:24:53  lr: 0.000999  loss: 183.3163 (184.4496)  time: 0.5268  data: 0.0032  max mem: 5844\n",
            "Epoch: [1/2]  [6390/9200]  eta: 0:24:47  lr: 0.000999  loss: 182.2072 (184.4493)  time: 0.4604  data: 0.0013  max mem: 5844\n",
            "Epoch: [1/2]  [6400/9200]  eta: 0:24:42  lr: 0.000999  loss: 177.4597 (184.4448)  time: 0.4812  data: 0.0015  max mem: 5844\n",
            "Epoch: [1/2]  [6410/9200]  eta: 0:24:37  lr: 0.000999  loss: 174.6509 (184.4405)  time: 0.5288  data: 0.0039  max mem: 5844\n",
            "Epoch: [1/2]  [6420/9200]  eta: 0:24:31  lr: 0.000999  loss: 164.1152 (184.4326)  time: 0.5291  data: 0.0025  max mem: 5844\n",
            "Epoch: [1/2]  [6430/9200]  eta: 0:24:26  lr: 0.000999  loss: 197.4939 (184.4601)  time: 0.5132  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [6440/9200]  eta: 0:24:21  lr: 0.000999  loss: 189.2818 (184.4618)  time: 0.5827  data: 0.0026  max mem: 5844\n",
            "Epoch: [1/2]  [6450/9200]  eta: 0:24:16  lr: 0.000999  loss: 173.2310 (184.4628)  time: 0.5903  data: 0.0023  max mem: 5844\n",
            "Epoch: [1/2]  [6460/9200]  eta: 0:24:11  lr: 0.000999  loss: 171.4164 (184.4660)  time: 0.5338  data: 0.0007  max mem: 5844\n",
            "Epoch: [1/2]  [6470/9200]  eta: 0:24:06  lr: 0.000999  loss: 171.4164 (184.4715)  time: 0.5656  data: 0.0048  max mem: 5844\n",
            "Epoch: [1/2]  [6480/9200]  eta: 0:24:00  lr: 0.000999  loss: 167.9694 (184.4464)  time: 0.5517  data: 0.0057  max mem: 5844\n",
            "Epoch: [1/2]  [6490/9200]  eta: 0:23:55  lr: 0.000999  loss: 168.0074 (184.4871)  time: 0.5133  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [6500/9200]  eta: 0:23:50  lr: 0.000999  loss: 184.8157 (184.4825)  time: 0.5178  data: 0.0015  max mem: 5844\n",
            "Epoch: [1/2]  [6510/9200]  eta: 0:23:44  lr: 0.000999  loss: 172.9238 (184.4988)  time: 0.5282  data: 0.0025  max mem: 5844\n",
            "Epoch: [1/2]  [6520/9200]  eta: 0:23:39  lr: 0.000999  loss: 176.2474 (184.5045)  time: 0.5345  data: 0.0012  max mem: 5844\n",
            "Epoch: [1/2]  [6530/9200]  eta: 0:23:34  lr: 0.000999  loss: 182.9537 (184.5086)  time: 0.5272  data: 0.0013  max mem: 5844\n",
            "Epoch: [1/2]  [6540/9200]  eta: 0:23:28  lr: 0.000999  loss: 164.5622 (184.5148)  time: 0.5323  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [6550/9200]  eta: 0:23:23  lr: 0.000999  loss: 164.5622 (184.4856)  time: 0.4995  data: 0.0019  max mem: 5844\n",
            "Epoch: [1/2]  [6560/9200]  eta: 0:23:17  lr: 0.000999  loss: 159.7283 (184.4499)  time: 0.4771  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [6570/9200]  eta: 0:23:12  lr: 0.000999  loss: 158.0914 (184.4568)  time: 0.5422  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [6580/9200]  eta: 0:23:07  lr: 0.000999  loss: 168.6174 (184.4608)  time: 0.5343  data: 0.0040  max mem: 5844\n",
            "Epoch: [1/2]  [6590/9200]  eta: 0:23:01  lr: 0.000999  loss: 184.9880 (184.4549)  time: 0.4702  data: 0.0009  max mem: 5844\n",
            "Epoch: [1/2]  [6600/9200]  eta: 0:22:56  lr: 0.000999  loss: 167.8627 (184.4163)  time: 0.5035  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [6610/9200]  eta: 0:22:51  lr: 0.000999  loss: 145.4357 (184.3984)  time: 0.5528  data: 0.0052  max mem: 5844\n",
            "Epoch: [1/2]  [6620/9200]  eta: 0:22:46  lr: 0.000999  loss: 146.0298 (184.3567)  time: 0.5354  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [6630/9200]  eta: 0:22:40  lr: 0.000999  loss: 147.3661 (184.3375)  time: 0.5170  data: 0.0010  max mem: 5844\n",
            "Epoch: [1/2]  [6640/9200]  eta: 0:22:35  lr: 0.000999  loss: 178.7008 (184.3136)  time: 0.5542  data: 0.0044  max mem: 5844\n",
            "Epoch: [1/2]  [6650/9200]  eta: 0:22:30  lr: 0.000999  loss: 177.3290 (184.3107)  time: 0.5221  data: 0.0036  max mem: 5844\n",
            "Epoch: [1/2]  [6660/9200]  eta: 0:22:24  lr: 0.000999  loss: 170.3030 (184.2911)  time: 0.4554  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [6670/9200]  eta: 0:22:19  lr: 0.000999  loss: 171.5392 (184.2885)  time: 0.5130  data: 0.0023  max mem: 5844\n",
            "Epoch: [1/2]  [6680/9200]  eta: 0:22:14  lr: 0.000999  loss: 179.0465 (184.3196)  time: 0.5848  data: 0.0044  max mem: 5844\n",
            "Epoch: [1/2]  [6690/9200]  eta: 0:22:08  lr: 0.000999  loss: 173.3239 (184.2855)  time: 0.5160  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [6700/9200]  eta: 0:22:03  lr: 0.000999  loss: 163.2195 (184.2635)  time: 0.4702  data: 0.0018  max mem: 5844\n",
            "Epoch: [1/2]  [6710/9200]  eta: 0:21:58  lr: 0.000999  loss: 177.6128 (184.2629)  time: 0.5445  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [6720/9200]  eta: 0:21:52  lr: 0.000999  loss: 178.8633 (184.2668)  time: 0.5414  data: 0.0022  max mem: 5844\n",
            "Epoch: [1/2]  [6730/9200]  eta: 0:21:47  lr: 0.000999  loss: 168.6430 (184.2500)  time: 0.5147  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [6740/9200]  eta: 0:21:42  lr: 0.000999  loss: 168.6430 (184.2457)  time: 0.5518  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [6750/9200]  eta: 0:21:37  lr: 0.000999  loss: 174.9095 (184.2558)  time: 0.5491  data: 0.0025  max mem: 5844\n",
            "Epoch: [1/2]  [6760/9200]  eta: 0:21:31  lr: 0.000999  loss: 168.9538 (184.2436)  time: 0.5453  data: 0.0017  max mem: 5844\n",
            "Epoch: [1/2]  [6770/9200]  eta: 0:21:26  lr: 0.000999  loss: 176.4898 (184.2514)  time: 0.5713  data: 0.0042  max mem: 5844\n",
            "Epoch: [1/2]  [6780/9200]  eta: 0:21:21  lr: 0.000999  loss: 176.4898 (184.2656)  time: 0.5599  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [6790/9200]  eta: 0:21:15  lr: 0.000999  loss: 183.7849 (184.2470)  time: 0.4996  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [6800/9200]  eta: 0:21:10  lr: 0.000999  loss: 177.2540 (184.2324)  time: 0.4924  data: 0.0054  max mem: 5844\n",
            "Epoch: [1/2]  [6810/9200]  eta: 0:21:05  lr: 0.000999  loss: 164.5616 (184.2093)  time: 0.5123  data: 0.0045  max mem: 5844\n",
            "Epoch: [1/2]  [6820/9200]  eta: 0:20:59  lr: 0.000999  loss: 155.2611 (184.2050)  time: 0.4971  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [6830/9200]  eta: 0:20:54  lr: 0.000999  loss: 178.6994 (184.1917)  time: 0.5319  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [6840/9200]  eta: 0:20:49  lr: 0.000999  loss: 178.6994 (184.1970)  time: 0.5729  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [6850/9200]  eta: 0:20:44  lr: 0.000999  loss: 174.2308 (184.1740)  time: 0.5149  data: 0.0013  max mem: 5844\n",
            "Epoch: [1/2]  [6860/9200]  eta: 0:20:38  lr: 0.000999  loss: 171.1628 (184.1563)  time: 0.5153  data: 0.0018  max mem: 5844\n",
            "Epoch: [1/2]  [6870/9200]  eta: 0:20:33  lr: 0.000999  loss: 163.6030 (184.1247)  time: 0.5509  data: 0.0041  max mem: 5844\n",
            "Epoch: [1/2]  [6880/9200]  eta: 0:20:28  lr: 0.000999  loss: 131.3784 (184.0787)  time: 0.4930  data: 0.0026  max mem: 5844\n",
            "Epoch: [1/2]  [6890/9200]  eta: 0:20:22  lr: 0.000999  loss: 146.1677 (184.0552)  time: 0.4907  data: 0.0008  max mem: 5844\n",
            "Epoch: [1/2]  [6900/9200]  eta: 0:20:17  lr: 0.000999  loss: 170.2990 (184.0438)  time: 0.5556  data: 0.0037  max mem: 5844\n",
            "Epoch: [1/2]  [6910/9200]  eta: 0:20:12  lr: 0.000999  loss: 158.6193 (184.0138)  time: 0.5364  data: 0.0041  max mem: 5844\n",
            "Epoch: [1/2]  [6920/9200]  eta: 0:20:06  lr: 0.000999  loss: 158.6193 (183.9928)  time: 0.4937  data: 0.0012  max mem: 5844\n",
            "Epoch: [1/2]  [6930/9200]  eta: 0:20:01  lr: 0.000999  loss: 177.2757 (184.0005)  time: 0.5514  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [6940/9200]  eta: 0:19:56  lr: 0.000999  loss: 218.5674 (184.0776)  time: 0.6196  data: 0.0041  max mem: 5844\n",
            "Epoch: [1/2]  [6950/9200]  eta: 0:19:51  lr: 0.000999  loss: 199.4309 (184.0819)  time: 0.5565  data: 0.0022  max mem: 5844\n",
            "Epoch: [1/2]  [6960/9200]  eta: 0:19:46  lr: 0.000999  loss: 177.5787 (184.0986)  time: 0.5252  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [6970/9200]  eta: 0:19:41  lr: 0.000999  loss: 194.3022 (184.1153)  time: 0.5710  data: 0.0030  max mem: 5844\n",
            "Epoch: [1/2]  [6980/9200]  eta: 0:19:35  lr: 0.000999  loss: 184.9770 (184.1023)  time: 0.5699  data: 0.0008  max mem: 5844\n",
            "Epoch: [1/2]  [6990/9200]  eta: 0:19:30  lr: 0.000999  loss: 161.2487 (184.0668)  time: 0.5864  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [7000/9200]  eta: 0:19:25  lr: 0.000999  loss: 167.9190 (184.0726)  time: 0.5482  data: 0.0039  max mem: 5844\n",
            "Epoch: [1/2]  [7010/9200]  eta: 0:19:19  lr: 0.000999  loss: 166.6706 (184.0480)  time: 0.4816  data: 0.0008  max mem: 5844\n",
            "Epoch: [1/2]  [7020/9200]  eta: 0:19:14  lr: 0.000999  loss: 191.3100 (184.0768)  time: 0.5092  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [7030/9200]  eta: 0:19:09  lr: 0.000999  loss: 215.6123 (184.0942)  time: 0.5475  data: 0.0055  max mem: 5844\n",
            "Epoch: [1/2]  [7040/9200]  eta: 0:19:03  lr: 0.000999  loss: 172.2361 (184.0585)  time: 0.4812  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [7050/9200]  eta: 0:18:58  lr: 0.000999  loss: 172.2361 (184.0502)  time: 0.4447  data: 0.0008  max mem: 5844\n",
            "Epoch: [1/2]  [7060/9200]  eta: 0:18:53  lr: 0.000999  loss: 182.4915 (184.0641)  time: 0.5402  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [7070/9200]  eta: 0:18:47  lr: 0.000999  loss: 183.8774 (184.0759)  time: 0.5667  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [7080/9200]  eta: 0:18:42  lr: 0.000999  loss: 179.7673 (184.0728)  time: 0.5134  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [7090/9200]  eta: 0:18:37  lr: 0.000999  loss: 166.4159 (184.0317)  time: 0.5436  data: 0.0025  max mem: 5844\n",
            "Epoch: [1/2]  [7100/9200]  eta: 0:18:32  lr: 0.000999  loss: 171.2383 (184.0543)  time: 0.5342  data: 0.0026  max mem: 5844\n",
            "Epoch: [1/2]  [7110/9200]  eta: 0:18:26  lr: 0.000999  loss: 192.1003 (184.0687)  time: 0.4698  data: 0.0003  max mem: 5844\n",
            "Epoch: [1/2]  [7120/9200]  eta: 0:18:21  lr: 0.000999  loss: 178.3016 (184.0219)  time: 0.4941  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [7130/9200]  eta: 0:18:16  lr: 0.000999  loss: 152.1745 (184.0090)  time: 0.5535  data: 0.0047  max mem: 5844\n",
            "Epoch: [1/2]  [7140/9200]  eta: 0:18:10  lr: 0.000999  loss: 181.8757 (184.0203)  time: 0.5444  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [7150/9200]  eta: 0:18:05  lr: 0.000999  loss: 203.4949 (184.0439)  time: 0.5497  data: 0.0020  max mem: 5844\n",
            "Epoch: [1/2]  [7160/9200]  eta: 0:18:00  lr: 0.000999  loss: 202.4092 (184.0447)  time: 0.5530  data: 0.0036  max mem: 5844\n",
            "Epoch: [1/2]  [7170/9200]  eta: 0:17:54  lr: 0.000999  loss: 176.5556 (184.0338)  time: 0.5139  data: 0.0019  max mem: 5844\n",
            "Epoch: [1/2]  [7180/9200]  eta: 0:17:49  lr: 0.000999  loss: 173.6753 (184.0245)  time: 0.5114  data: 0.0013  max mem: 5844\n",
            "Epoch: [1/2]  [7190/9200]  eta: 0:17:44  lr: 0.000999  loss: 170.1948 (184.0044)  time: 0.5513  data: 0.0042  max mem: 5844\n",
            "Epoch: [1/2]  [7200/9200]  eta: 0:17:39  lr: 0.000999  loss: 170.1948 (184.0168)  time: 0.5538  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [7210/9200]  eta: 0:17:33  lr: 0.000999  loss: 171.8850 (184.0241)  time: 0.5463  data: 0.0009  max mem: 5844\n",
            "Epoch: [1/2]  [7220/9200]  eta: 0:17:28  lr: 0.000999  loss: 156.4395 (184.0117)  time: 0.5753  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [7230/9200]  eta: 0:17:23  lr: 0.000999  loss: 156.4395 (183.9899)  time: 0.5338  data: 0.0022  max mem: 5844\n",
            "Epoch: [1/2]  [7240/9200]  eta: 0:17:18  lr: 0.000999  loss: 163.5573 (184.0055)  time: 0.5014  data: 0.0007  max mem: 5844\n",
            "Epoch: [1/2]  [7250/9200]  eta: 0:17:12  lr: 0.000999  loss: 163.9293 (184.0012)  time: 0.5698  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [7260/9200]  eta: 0:17:07  lr: 0.000999  loss: 163.9293 (183.9870)  time: 0.5433  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [7270/9200]  eta: 0:17:02  lr: 0.000999  loss: 157.7458 (183.9854)  time: 0.4833  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [7280/9200]  eta: 0:16:57  lr: 0.000999  loss: 157.1421 (183.9535)  time: 0.5595  data: 0.0037  max mem: 5844\n",
            "Epoch: [1/2]  [7290/9200]  eta: 0:16:51  lr: 0.000999  loss: 151.2421 (183.9366)  time: 0.5672  data: 0.0047  max mem: 5844\n",
            "Epoch: [1/2]  [7300/9200]  eta: 0:16:46  lr: 0.000999  loss: 178.0367 (183.9521)  time: 0.5130  data: 0.0012  max mem: 5844\n",
            "Epoch: [1/2]  [7310/9200]  eta: 0:16:41  lr: 0.000999  loss: 180.9265 (183.9522)  time: 0.5617  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [7320/9200]  eta: 0:16:35  lr: 0.000999  loss: 157.7683 (183.9033)  time: 0.5373  data: 0.0046  max mem: 5844\n",
            "Epoch: [1/2]  [7330/9200]  eta: 0:16:30  lr: 0.000999  loss: 162.4357 (183.9187)  time: 0.4826  data: 0.0017  max mem: 5844\n",
            "Epoch: [1/2]  [7340/9200]  eta: 0:16:25  lr: 0.000999  loss: 169.4556 (183.8978)  time: 0.5153  data: 0.0009  max mem: 5844\n",
            "Epoch: [1/2]  [7350/9200]  eta: 0:16:19  lr: 0.000999  loss: 162.2175 (183.8715)  time: 0.5262  data: 0.0023  max mem: 5844\n",
            "Epoch: [1/2]  [7360/9200]  eta: 0:16:14  lr: 0.000999  loss: 163.1081 (183.8718)  time: 0.5328  data: 0.0017  max mem: 5844\n",
            "Epoch: [1/2]  [7370/9200]  eta: 0:16:09  lr: 0.000999  loss: 166.7879 (183.8873)  time: 0.5712  data: 0.0015  max mem: 5844\n",
            "Epoch: [1/2]  [7380/9200]  eta: 0:16:04  lr: 0.000999  loss: 161.2088 (183.8497)  time: 0.5792  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [7390/9200]  eta: 0:15:58  lr: 0.000999  loss: 163.5168 (183.8486)  time: 0.5187  data: 0.0018  max mem: 5844\n",
            "Epoch: [1/2]  [7400/9200]  eta: 0:15:53  lr: 0.000999  loss: 171.0394 (183.8585)  time: 0.5214  data: 0.0015  max mem: 5844\n",
            "Epoch: [1/2]  [7410/9200]  eta: 0:15:48  lr: 0.000999  loss: 174.3776 (183.8518)  time: 0.5680  data: 0.0042  max mem: 5844\n",
            "Epoch: [1/2]  [7420/9200]  eta: 0:15:43  lr: 0.000999  loss: 171.9749 (183.8361)  time: 0.5383  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [7430/9200]  eta: 0:15:37  lr: 0.000999  loss: 165.8613 (183.8533)  time: 0.5418  data: 0.0009  max mem: 5844\n",
            "Epoch: [1/2]  [7440/9200]  eta: 0:15:32  lr: 0.000999  loss: 175.4287 (183.8402)  time: 0.5583  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [7450/9200]  eta: 0:15:27  lr: 0.000999  loss: 175.4287 (183.8504)  time: 0.5042  data: 0.0022  max mem: 5844\n",
            "Epoch: [1/2]  [7460/9200]  eta: 0:15:21  lr: 0.000999  loss: 183.8296 (183.8595)  time: 0.4912  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [7470/9200]  eta: 0:15:16  lr: 0.000999  loss: 183.8296 (183.8727)  time: 0.5609  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [7480/9200]  eta: 0:15:11  lr: 0.000999  loss: 174.4752 (183.8667)  time: 0.5477  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [7490/9200]  eta: 0:15:06  lr: 0.000999  loss: 177.6143 (183.8794)  time: 0.5282  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [7500/9200]  eta: 0:15:00  lr: 0.000999  loss: 181.7182 (183.8710)  time: 0.5747  data: 0.0036  max mem: 5844\n",
            "Epoch: [1/2]  [7510/9200]  eta: 0:14:55  lr: 0.000999  loss: 170.1813 (183.8613)  time: 0.5189  data: 0.0048  max mem: 5844\n",
            "Epoch: [1/2]  [7520/9200]  eta: 0:14:49  lr: 0.000999  loss: 168.9326 (183.8222)  time: 0.4453  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [7530/9200]  eta: 0:14:44  lr: 0.000999  loss: 150.8259 (183.8437)  time: 0.5095  data: 0.0017  max mem: 5844\n",
            "Epoch: [1/2]  [7540/9200]  eta: 0:14:39  lr: 0.000999  loss: 173.5596 (183.8456)  time: 0.5707  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [7550/9200]  eta: 0:14:34  lr: 0.000999  loss: 171.6352 (183.8298)  time: 0.5129  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [7560/9200]  eta: 0:14:28  lr: 0.000999  loss: 163.1888 (183.8036)  time: 0.5008  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [7570/9200]  eta: 0:14:23  lr: 0.000999  loss: 175.1512 (183.7883)  time: 0.5656  data: 0.0051  max mem: 5844\n",
            "Epoch: [1/2]  [7580/9200]  eta: 0:14:18  lr: 0.000999  loss: 175.1512 (183.8062)  time: 0.5606  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [7590/9200]  eta: 0:14:13  lr: 0.000999  loss: 174.7780 (183.8007)  time: 0.5254  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [7600/9200]  eta: 0:14:07  lr: 0.000999  loss: 180.8289 (183.8284)  time: 0.5786  data: 0.0041  max mem: 5844\n",
            "Epoch: [1/2]  [7610/9200]  eta: 0:14:02  lr: 0.000999  loss: 175.6056 (183.8247)  time: 0.5487  data: 0.0047  max mem: 5844\n",
            "Epoch: [1/2]  [7620/9200]  eta: 0:13:57  lr: 0.000999  loss: 152.2251 (183.7795)  time: 0.4599  data: 0.0007  max mem: 5844\n",
            "Epoch: [1/2]  [7630/9200]  eta: 0:13:51  lr: 0.000999  loss: 157.3526 (183.7929)  time: 0.5220  data: 0.0032  max mem: 5844\n",
            "Epoch: [1/2]  [7640/9200]  eta: 0:13:46  lr: 0.000999  loss: 171.7690 (183.7758)  time: 0.5469  data: 0.0054  max mem: 5844\n",
            "Epoch: [1/2]  [7650/9200]  eta: 0:13:41  lr: 0.000999  loss: 166.7474 (183.7773)  time: 0.5023  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [7660/9200]  eta: 0:13:35  lr: 0.000999  loss: 169.2162 (183.7765)  time: 0.5042  data: 0.0019  max mem: 5844\n",
            "Epoch: [1/2]  [7670/9200]  eta: 0:13:30  lr: 0.000999  loss: 166.3697 (183.7289)  time: 0.5260  data: 0.0051  max mem: 5844\n",
            "Epoch: [1/2]  [7680/9200]  eta: 0:13:25  lr: 0.000999  loss: 158.2691 (183.6998)  time: 0.5099  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [7690/9200]  eta: 0:13:19  lr: 0.000999  loss: 159.3934 (183.6926)  time: 0.4594  data: 0.0006  max mem: 5844\n",
            "Epoch: [1/2]  [7700/9200]  eta: 0:13:14  lr: 0.000999  loss: 166.9721 (183.6727)  time: 0.4921  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [7710/9200]  eta: 0:13:09  lr: 0.000999  loss: 160.9773 (183.6406)  time: 0.5303  data: 0.0044  max mem: 5844\n",
            "Epoch: [1/2]  [7720/9200]  eta: 0:13:03  lr: 0.000999  loss: 156.1272 (183.6254)  time: 0.4928  data: 0.0022  max mem: 5844\n",
            "Epoch: [1/2]  [7730/9200]  eta: 0:12:58  lr: 0.000999  loss: 177.3444 (183.6366)  time: 0.4769  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [7740/9200]  eta: 0:12:53  lr: 0.000999  loss: 187.7882 (183.6496)  time: 0.5374  data: 0.0032  max mem: 5844\n",
            "Epoch: [1/2]  [7750/9200]  eta: 0:12:47  lr: 0.000999  loss: 187.7882 (183.6628)  time: 0.5325  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [7760/9200]  eta: 0:12:42  lr: 0.000999  loss: 202.9435 (183.6905)  time: 0.5162  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [7770/9200]  eta: 0:12:37  lr: 0.000999  loss: 209.8315 (183.7058)  time: 0.5892  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [7780/9200]  eta: 0:12:31  lr: 0.000999  loss: 177.9752 (183.7030)  time: 0.5248  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [7790/9200]  eta: 0:12:26  lr: 0.000999  loss: 173.2134 (183.6908)  time: 0.4365  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [7800/9200]  eta: 0:12:21  lr: 0.000999  loss: 164.2433 (183.6972)  time: 0.5040  data: 0.0029  max mem: 5844\n",
            "Epoch: [1/2]  [7810/9200]  eta: 0:12:15  lr: 0.000999  loss: 172.5190 (183.6884)  time: 0.5132  data: 0.0048  max mem: 5844\n",
            "Epoch: [1/2]  [7820/9200]  eta: 0:12:10  lr: 0.000999  loss: 173.5095 (183.7402)  time: 0.5073  data: 0.0022  max mem: 5844\n",
            "Epoch: [1/2]  [7830/9200]  eta: 0:12:05  lr: 0.000999  loss: 173.5095 (183.7015)  time: 0.5328  data: 0.0017  max mem: 5844\n",
            "Epoch: [1/2]  [7840/9200]  eta: 0:12:00  lr: 0.000999  loss: 172.3810 (183.7186)  time: 0.5522  data: 0.0042  max mem: 5844\n",
            "Epoch: [1/2]  [7850/9200]  eta: 0:11:54  lr: 0.000999  loss: 181.9309 (183.7410)  time: 0.5563  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [7860/9200]  eta: 0:11:49  lr: 0.000999  loss: 177.8754 (183.7373)  time: 0.5389  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [7870/9200]  eta: 0:11:44  lr: 0.000999  loss: 168.0586 (183.7350)  time: 0.5579  data: 0.0052  max mem: 5844\n",
            "Epoch: [1/2]  [7880/9200]  eta: 0:11:38  lr: 0.000999  loss: 211.3092 (183.7709)  time: 0.5478  data: 0.0049  max mem: 5844\n",
            "Epoch: [1/2]  [7890/9200]  eta: 0:11:33  lr: 0.000999  loss: 188.8658 (183.7630)  time: 0.5058  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [7900/9200]  eta: 0:11:28  lr: 0.000999  loss: 169.8660 (183.7486)  time: 0.5126  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [7910/9200]  eta: 0:11:22  lr: 0.000999  loss: 166.8301 (183.7432)  time: 0.5232  data: 0.0049  max mem: 5844\n",
            "Epoch: [1/2]  [7920/9200]  eta: 0:11:17  lr: 0.000999  loss: 192.5764 (183.7504)  time: 0.4953  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [7930/9200]  eta: 0:11:12  lr: 0.000999  loss: 169.8409 (183.7392)  time: 0.5033  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [7940/9200]  eta: 0:11:07  lr: 0.000999  loss: 168.2371 (183.7354)  time: 0.5580  data: 0.0046  max mem: 5844\n",
            "Epoch: [1/2]  [7950/9200]  eta: 0:11:01  lr: 0.000999  loss: 169.1561 (183.7362)  time: 0.5589  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [7960/9200]  eta: 0:10:56  lr: 0.000999  loss: 178.8326 (183.7387)  time: 0.5222  data: 0.0004  max mem: 5844\n",
            "Epoch: [1/2]  [7970/9200]  eta: 0:10:51  lr: 0.000999  loss: 171.0274 (183.7119)  time: 0.5302  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [7980/9200]  eta: 0:10:45  lr: 0.000999  loss: 152.1355 (183.7315)  time: 0.5478  data: 0.0048  max mem: 5844\n",
            "Epoch: [1/2]  [7990/9200]  eta: 0:10:40  lr: 0.000999  loss: 180.8002 (183.7538)  time: 0.5222  data: 0.0008  max mem: 5844\n",
            "Epoch: [1/2]  [8000/9200]  eta: 0:10:35  lr: 0.000999  loss: 191.8136 (183.7942)  time: 0.5525  data: 0.0030  max mem: 5844\n",
            "Epoch: [1/2]  [8010/9200]  eta: 0:10:30  lr: 0.000999  loss: 173.3122 (183.7637)  time: 0.5396  data: 0.0051  max mem: 5844\n",
            "Epoch: [1/2]  [8020/9200]  eta: 0:10:24  lr: 0.000999  loss: 159.7235 (183.7569)  time: 0.4938  data: 0.0023  max mem: 5844\n",
            "Epoch: [1/2]  [8030/9200]  eta: 0:10:19  lr: 0.000999  loss: 154.3256 (183.7151)  time: 0.5321  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [8040/9200]  eta: 0:10:14  lr: 0.000999  loss: 166.1405 (183.7205)  time: 0.5485  data: 0.0039  max mem: 5844\n",
            "Epoch: [1/2]  [8050/9200]  eta: 0:10:08  lr: 0.000999  loss: 198.2644 (183.7679)  time: 0.5427  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [8060/9200]  eta: 0:10:03  lr: 0.000999  loss: 198.2644 (183.7847)  time: 0.5134  data: 0.0010  max mem: 5844\n",
            "Epoch: [1/2]  [8070/9200]  eta: 0:09:58  lr: 0.000999  loss: 161.7558 (183.7944)  time: 0.5272  data: 0.0042  max mem: 5844\n",
            "Epoch: [1/2]  [8080/9200]  eta: 0:09:52  lr: 0.000999  loss: 170.5230 (183.7901)  time: 0.5117  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [8090/9200]  eta: 0:09:47  lr: 0.000999  loss: 172.6693 (183.7965)  time: 0.4851  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [8100/9200]  eta: 0:09:42  lr: 0.000999  loss: 184.7154 (183.8097)  time: 0.5771  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [8110/9200]  eta: 0:09:37  lr: 0.000999  loss: 167.1519 (183.7703)  time: 0.5552  data: 0.0041  max mem: 5844\n",
            "Epoch: [1/2]  [8120/9200]  eta: 0:09:31  lr: 0.000999  loss: 149.8361 (183.7603)  time: 0.4721  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [8130/9200]  eta: 0:09:26  lr: 0.000999  loss: 189.1837 (183.7892)  time: 0.5462  data: 0.0025  max mem: 5844\n",
            "Epoch: [1/2]  [8140/9200]  eta: 0:09:21  lr: 0.000999  loss: 195.1925 (183.7821)  time: 0.5781  data: 0.0054  max mem: 5844\n",
            "Epoch: [1/2]  [8150/9200]  eta: 0:09:15  lr: 0.000999  loss: 187.4347 (183.7835)  time: 0.5319  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [8160/9200]  eta: 0:09:10  lr: 0.000999  loss: 192.7074 (183.7888)  time: 0.5352  data: 0.0011  max mem: 5844\n",
            "Epoch: [1/2]  [8170/9200]  eta: 0:09:05  lr: 0.000999  loss: 177.5673 (183.7633)  time: 0.5752  data: 0.0037  max mem: 5844\n",
            "Epoch: [1/2]  [8180/9200]  eta: 0:09:00  lr: 0.000999  loss: 172.8523 (183.7476)  time: 0.5313  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [8190/9200]  eta: 0:08:54  lr: 0.000999  loss: 164.2248 (183.7296)  time: 0.4509  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [8200/9200]  eta: 0:08:49  lr: 0.000999  loss: 165.0405 (183.7172)  time: 0.5078  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [8210/9200]  eta: 0:08:44  lr: 0.000999  loss: 175.0887 (183.7406)  time: 0.5454  data: 0.0045  max mem: 5844\n",
            "Epoch: [1/2]  [8220/9200]  eta: 0:08:38  lr: 0.000999  loss: 170.4794 (183.7047)  time: 0.4997  data: 0.0013  max mem: 5844\n",
            "Epoch: [1/2]  [8230/9200]  eta: 0:08:33  lr: 0.000999  loss: 156.2211 (183.6982)  time: 0.5404  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [8240/9200]  eta: 0:08:28  lr: 0.000999  loss: 184.0161 (183.6876)  time: 0.5334  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [8250/9200]  eta: 0:08:22  lr: 0.000999  loss: 164.5686 (183.6624)  time: 0.4653  data: 0.0011  max mem: 5844\n",
            "Epoch: [1/2]  [8260/9200]  eta: 0:08:17  lr: 0.000999  loss: 153.1423 (183.6219)  time: 0.4836  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [8270/9200]  eta: 0:08:12  lr: 0.000999  loss: 142.9053 (183.5933)  time: 0.5239  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [8280/9200]  eta: 0:08:06  lr: 0.000999  loss: 163.0018 (183.5933)  time: 0.5172  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [8290/9200]  eta: 0:08:01  lr: 0.000999  loss: 163.0558 (183.5824)  time: 0.5486  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [8300/9200]  eta: 0:07:56  lr: 0.000999  loss: 170.8441 (183.5771)  time: 0.5895  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [8310/9200]  eta: 0:07:51  lr: 0.000999  loss: 175.9940 (183.5854)  time: 0.5412  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [8320/9200]  eta: 0:07:45  lr: 0.000999  loss: 161.4151 (183.5911)  time: 0.5118  data: 0.0011  max mem: 5844\n",
            "Epoch: [1/2]  [8330/9200]  eta: 0:07:40  lr: 0.000999  loss: 161.4151 (183.5661)  time: 0.5431  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [8340/9200]  eta: 0:07:35  lr: 0.000999  loss: 177.2348 (183.5674)  time: 0.5445  data: 0.0025  max mem: 5844\n",
            "Epoch: [1/2]  [8350/9200]  eta: 0:07:29  lr: 0.000999  loss: 175.3116 (183.5484)  time: 0.5365  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [8360/9200]  eta: 0:07:24  lr: 0.000999  loss: 161.4310 (183.5467)  time: 0.5903  data: 0.0037  max mem: 5844\n",
            "Epoch: [1/2]  [8370/9200]  eta: 0:07:19  lr: 0.000999  loss: 181.2827 (183.5665)  time: 0.5796  data: 0.0036  max mem: 5844\n",
            "Epoch: [1/2]  [8380/9200]  eta: 0:07:14  lr: 0.000999  loss: 192.0212 (183.5711)  time: 0.5404  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [8390/9200]  eta: 0:07:09  lr: 0.000999  loss: 195.9674 (183.6092)  time: 0.5925  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [8400/9200]  eta: 0:07:03  lr: 0.000999  loss: 184.0998 (183.6043)  time: 0.5812  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [8410/9200]  eta: 0:06:58  lr: 0.000999  loss: 174.6476 (183.6044)  time: 0.5221  data: 0.0018  max mem: 5844\n",
            "Epoch: [1/2]  [8420/9200]  eta: 0:06:53  lr: 0.000999  loss: 182.8310 (183.6314)  time: 0.5534  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [8430/9200]  eta: 0:06:47  lr: 0.000999  loss: 167.9805 (183.6189)  time: 0.5726  data: 0.0040  max mem: 5844\n",
            "Epoch: [1/2]  [8440/9200]  eta: 0:06:42  lr: 0.000999  loss: 167.9404 (183.6180)  time: 0.5621  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [8450/9200]  eta: 0:06:37  lr: 0.000999  loss: 169.1066 (183.5998)  time: 0.5750  data: 0.0019  max mem: 5844\n",
            "Epoch: [1/2]  [8460/9200]  eta: 0:06:32  lr: 0.000999  loss: 175.3109 (183.6118)  time: 0.5445  data: 0.0039  max mem: 5844\n",
            "Epoch: [1/2]  [8470/9200]  eta: 0:06:26  lr: 0.000999  loss: 174.9977 (183.5795)  time: 0.4879  data: 0.0022  max mem: 5844\n",
            "Epoch: [1/2]  [8480/9200]  eta: 0:06:21  lr: 0.000999  loss: 155.9603 (183.5624)  time: 0.5133  data: 0.0009  max mem: 5844\n",
            "Epoch: [1/2]  [8490/9200]  eta: 0:06:16  lr: 0.000999  loss: 156.3659 (183.5343)  time: 0.5565  data: 0.0032  max mem: 5844\n",
            "Epoch: [1/2]  [8500/9200]  eta: 0:06:10  lr: 0.000999  loss: 159.7797 (183.5077)  time: 0.4901  data: 0.0026  max mem: 5844\n",
            "Epoch: [1/2]  [8510/9200]  eta: 0:06:05  lr: 0.000999  loss: 167.3539 (183.4858)  time: 0.4653  data: 0.0007  max mem: 5844\n",
            "Epoch: [1/2]  [8520/9200]  eta: 0:06:00  lr: 0.000999  loss: 167.3539 (183.4613)  time: 0.5298  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [8530/9200]  eta: 0:05:54  lr: 0.000999  loss: 159.4039 (183.4588)  time: 0.5346  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [8540/9200]  eta: 0:05:49  lr: 0.000999  loss: 168.3723 (183.4558)  time: 0.4778  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [8550/9200]  eta: 0:05:44  lr: 0.000999  loss: 156.2194 (183.4247)  time: 0.5253  data: 0.0023  max mem: 5844\n",
            "Epoch: [1/2]  [8560/9200]  eta: 0:05:39  lr: 0.000999  loss: 156.2194 (183.4499)  time: 0.6049  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [8570/9200]  eta: 0:05:33  lr: 0.000999  loss: 168.2148 (183.4350)  time: 0.5500  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [8580/9200]  eta: 0:05:28  lr: 0.000999  loss: 156.5488 (183.4261)  time: 0.5372  data: 0.0021  max mem: 5844\n",
            "Epoch: [1/2]  [8590/9200]  eta: 0:05:23  lr: 0.000999  loss: 159.3910 (183.4124)  time: 0.5468  data: 0.0034  max mem: 5844\n",
            "Epoch: [1/2]  [8600/9200]  eta: 0:05:17  lr: 0.000999  loss: 152.1382 (183.3776)  time: 0.5021  data: 0.0018  max mem: 5844\n",
            "Epoch: [1/2]  [8610/9200]  eta: 0:05:12  lr: 0.000999  loss: 150.6866 (183.3442)  time: 0.5005  data: 0.0015  max mem: 5844\n",
            "Epoch: [1/2]  [8620/9200]  eta: 0:05:07  lr: 0.000999  loss: 173.5952 (183.3440)  time: 0.5342  data: 0.0054  max mem: 5844\n",
            "Epoch: [1/2]  [8630/9200]  eta: 0:05:01  lr: 0.000999  loss: 178.4394 (183.3580)  time: 0.5390  data: 0.0043  max mem: 5844\n",
            "Epoch: [1/2]  [8640/9200]  eta: 0:04:56  lr: 0.000999  loss: 178.4394 (183.3519)  time: 0.5095  data: 0.0007  max mem: 5844\n",
            "Epoch: [1/2]  [8650/9200]  eta: 0:04:51  lr: 0.000999  loss: 166.7182 (183.3362)  time: 0.5311  data: 0.0047  max mem: 5844\n",
            "Epoch: [1/2]  [8660/9200]  eta: 0:04:46  lr: 0.000999  loss: 166.7182 (183.3311)  time: 0.5395  data: 0.0051  max mem: 5844\n",
            "Epoch: [1/2]  [8670/9200]  eta: 0:04:40  lr: 0.000999  loss: 177.6691 (183.3310)  time: 0.5299  data: 0.0012  max mem: 5844\n",
            "Epoch: [1/2]  [8680/9200]  eta: 0:04:35  lr: 0.000999  loss: 167.2918 (183.3246)  time: 0.5733  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [8690/9200]  eta: 0:04:30  lr: 0.000999  loss: 166.8949 (183.3149)  time: 0.5613  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [8700/9200]  eta: 0:04:24  lr: 0.000999  loss: 157.8241 (183.3131)  time: 0.5304  data: 0.0010  max mem: 5844\n",
            "Epoch: [1/2]  [8710/9200]  eta: 0:04:19  lr: 0.000999  loss: 163.2507 (183.3080)  time: 0.5721  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [8720/9200]  eta: 0:04:14  lr: 0.000999  loss: 167.4062 (183.2925)  time: 0.5648  data: 0.0056  max mem: 5844\n",
            "Epoch: [1/2]  [8730/9200]  eta: 0:04:09  lr: 0.000999  loss: 162.8257 (183.2781)  time: 0.5051  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [8740/9200]  eta: 0:04:03  lr: 0.000999  loss: 188.4403 (183.3398)  time: 0.5624  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [8750/9200]  eta: 0:03:58  lr: 0.000999  loss: 194.7033 (183.3464)  time: 0.6163  data: 0.0044  max mem: 5844\n",
            "Epoch: [1/2]  [8760/9200]  eta: 0:03:53  lr: 0.000999  loss: 189.5582 (183.3485)  time: 0.5319  data: 0.0030  max mem: 5844\n",
            "Epoch: [1/2]  [8770/9200]  eta: 0:03:47  lr: 0.000999  loss: 186.0782 (183.3791)  time: 0.4978  data: 0.0010  max mem: 5844\n",
            "Epoch: [1/2]  [8780/9200]  eta: 0:03:42  lr: 0.000999  loss: 173.6180 (183.3576)  time: 0.5463  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [8790/9200]  eta: 0:03:37  lr: 0.000999  loss: 171.5627 (183.3554)  time: 0.5607  data: 0.0044  max mem: 5844\n",
            "Epoch: [1/2]  [8800/9200]  eta: 0:03:31  lr: 0.000999  loss: 175.4333 (183.3334)  time: 0.5148  data: 0.0017  max mem: 5844\n",
            "Epoch: [1/2]  [8810/9200]  eta: 0:03:26  lr: 0.000999  loss: 175.4333 (183.3433)  time: 0.5234  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [8820/9200]  eta: 0:03:21  lr: 0.000999  loss: 184.6859 (183.3307)  time: 0.5360  data: 0.0045  max mem: 5844\n",
            "Epoch: [1/2]  [8830/9200]  eta: 0:03:16  lr: 0.000999  loss: 148.4332 (183.2941)  time: 0.4926  data: 0.0020  max mem: 5844\n",
            "Epoch: [1/2]  [8840/9200]  eta: 0:03:10  lr: 0.000999  loss: 151.6840 (183.2631)  time: 0.4784  data: 0.0018  max mem: 5844\n",
            "Epoch: [1/2]  [8850/9200]  eta: 0:03:05  lr: 0.000999  loss: 162.0828 (183.2868)  time: 0.5453  data: 0.0042  max mem: 5844\n",
            "Epoch: [1/2]  [8860/9200]  eta: 0:03:00  lr: 0.000999  loss: 182.1853 (183.2931)  time: 0.5412  data: 0.0026  max mem: 5844\n",
            "Epoch: [1/2]  [8870/9200]  eta: 0:02:54  lr: 0.000999  loss: 182.1853 (183.2938)  time: 0.4910  data: 0.0013  max mem: 5844\n",
            "Epoch: [1/2]  [8880/9200]  eta: 0:02:49  lr: 0.000999  loss: 185.6024 (183.3171)  time: 0.5542  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [8890/9200]  eta: 0:02:44  lr: 0.000999  loss: 188.3823 (183.3192)  time: 0.5274  data: 0.0026  max mem: 5844\n",
            "Epoch: [1/2]  [8900/9200]  eta: 0:02:38  lr: 0.000999  loss: 188.3823 (183.3507)  time: 0.5275  data: 0.0016  max mem: 5844\n",
            "Epoch: [1/2]  [8910/9200]  eta: 0:02:33  lr: 0.000999  loss: 176.7334 (183.3471)  time: 0.5793  data: 0.0038  max mem: 5844\n",
            "Epoch: [1/2]  [8920/9200]  eta: 0:02:28  lr: 0.000999  loss: 162.7424 (183.3249)  time: 0.5281  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [8930/9200]  eta: 0:02:23  lr: 0.000999  loss: 183.5596 (183.3327)  time: 0.5213  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [8940/9200]  eta: 0:02:17  lr: 0.000999  loss: 176.1727 (183.3411)  time: 0.5985  data: 0.0035  max mem: 5844\n",
            "Epoch: [1/2]  [8950/9200]  eta: 0:02:12  lr: 0.000999  loss: 172.0033 (183.3393)  time: 0.5679  data: 0.0032  max mem: 5844\n",
            "Epoch: [1/2]  [8960/9200]  eta: 0:02:07  lr: 0.000999  loss: 192.2446 (183.3611)  time: 0.5184  data: 0.0006  max mem: 5844\n",
            "Epoch: [1/2]  [8970/9200]  eta: 0:02:01  lr: 0.000999  loss: 181.3559 (183.3719)  time: 0.5789  data: 0.0031  max mem: 5844\n",
            "Epoch: [1/2]  [8980/9200]  eta: 0:01:56  lr: 0.000999  loss: 168.5583 (183.3688)  time: 0.5482  data: 0.0027  max mem: 5844\n",
            "Epoch: [1/2]  [8990/9200]  eta: 0:01:51  lr: 0.000999  loss: 168.5583 (183.3704)  time: 0.4998  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [9000/9200]  eta: 0:01:46  lr: 0.000999  loss: 175.4191 (183.3731)  time: 0.5493  data: 0.0036  max mem: 5844\n",
            "Epoch: [1/2]  [9010/9200]  eta: 0:01:40  lr: 0.000999  loss: 164.5858 (183.3480)  time: 0.5252  data: 0.0048  max mem: 5844\n",
            "Epoch: [1/2]  [9020/9200]  eta: 0:01:35  lr: 0.000999  loss: 155.0782 (183.3413)  time: 0.4764  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2]  [9030/9200]  eta: 0:01:30  lr: 0.000999  loss: 160.5909 (183.3204)  time: 0.4782  data: 0.0007  max mem: 5844\n",
            "Epoch: [1/2]  [9040/9200]  eta: 0:01:24  lr: 0.000999  loss: 165.2702 (183.3002)  time: 0.5291  data: 0.0033  max mem: 5844\n",
            "Epoch: [1/2]  [9050/9200]  eta: 0:01:19  lr: 0.000999  loss: 169.4247 (183.2896)  time: 0.5189  data: 0.0028  max mem: 5844\n",
            "Epoch: [1/2]  [9060/9200]  eta: 0:01:14  lr: 0.000999  loss: 167.0632 (183.2663)  time: 0.4631  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [9070/9200]  eta: 0:01:08  lr: 0.000999  loss: 167.0632 (183.2735)  time: 0.5759  data: 0.0020  max mem: 5844\n",
            "Epoch: [1/2]  [9080/9200]  eta: 0:01:03  lr: 0.000999  loss: 183.6277 (183.2679)  time: 0.6036  data: 0.0025  max mem: 5844\n",
            "Epoch: [1/2]  [9090/9200]  eta: 0:00:58  lr: 0.000999  loss: 183.6277 (183.2737)  time: 0.5503  data: 0.0010  max mem: 5844\n",
            "Epoch: [1/2]  [9100/9200]  eta: 0:00:53  lr: 0.000999  loss: 193.3396 (183.2889)  time: 0.5775  data: 0.0044  max mem: 5844\n",
            "Epoch: [1/2]  [9110/9200]  eta: 0:00:47  lr: 0.000999  loss: 179.8331 (183.2824)  time: 0.5441  data: 0.0040  max mem: 5844\n",
            "Epoch: [1/2]  [9120/9200]  eta: 0:00:42  lr: 0.000999  loss: 178.0473 (183.2796)  time: 0.5083  data: 0.0005  max mem: 5844\n",
            "Epoch: [1/2]  [9130/9200]  eta: 0:00:37  lr: 0.000999  loss: 161.2674 (183.2491)  time: 0.5399  data: 0.0036  max mem: 5844\n",
            "Epoch: [1/2]  [9140/9200]  eta: 0:00:31  lr: 0.000999  loss: 161.2674 (183.2341)  time: 0.5063  data: 0.0032  max mem: 5844\n",
            "Epoch: [1/2]  [9150/9200]  eta: 0:00:26  lr: 0.000999  loss: 177.5842 (183.2257)  time: 0.4559  data: 0.0002  max mem: 5844\n",
            "Epoch: [1/2]  [9160/9200]  eta: 0:00:21  lr: 0.000999  loss: 177.5842 (183.2214)  time: 0.5009  data: 0.0024  max mem: 5844\n",
            "Epoch: [1/2]  [9170/9200]  eta: 0:00:15  lr: 0.000999  loss: 158.0310 (183.1813)  time: 0.5183  data: 0.0047  max mem: 5844\n",
            "Epoch: [1/2]  [9180/9200]  eta: 0:00:10  lr: 0.000999  loss: 151.1703 (183.1789)  time: 0.4980  data: 0.0026  max mem: 5844\n",
            "Epoch: [1/2]  [9190/9200]  eta: 0:00:05  lr: 0.000999  loss: 184.2424 (183.1708)  time: 0.4941  data: 0.0010  max mem: 5844\n",
            "Epoch: [1/2]  [9199/9200]  eta: 0:00:00  lr: 0.000999  loss: 170.3945 (183.1827)  time: 0.5501  data: 0.0014  max mem: 5844\n",
            "Epoch: [1/2] Total time: 1:21:17 (0.5301 s / it)\n",
            "Averaged stats: lr: 0.000999  loss: 170.3945 (183.1827)\n",
            "Test:  [  0/539]  eta: 0:14:44  loss: 358.7986 (358.7986)  time: 1.6404  data: 0.5589  max mem: 5844\n",
            "Test:  [ 10/539]  eta: 0:07:06  loss: 215.3751 (236.5669)  time: 0.8053  data: 0.0522  max mem: 5844\n",
            "Test:  [ 20/539]  eta: 0:06:36  loss: 223.5795 (236.9522)  time: 0.7193  data: 0.0016  max mem: 5844\n",
            "Test:  [ 30/539]  eta: 0:05:55  loss: 242.3798 (237.1828)  time: 0.6389  data: 0.0010  max mem: 5844\n",
            "Test:  [ 40/539]  eta: 0:05:46  loss: 188.6736 (221.3124)  time: 0.6236  data: 0.0024  max mem: 5844\n",
            "Test:  [ 50/539]  eta: 0:05:15  loss: 178.7144 (214.1121)  time: 0.5629  data: 0.0024  max mem: 5844\n",
            "Test:  [ 60/539]  eta: 0:04:53  loss: 186.1992 (209.6611)  time: 0.4409  data: 0.0002  max mem: 5844\n",
            "Test:  [ 70/539]  eta: 0:04:50  loss: 178.5206 (204.4583)  time: 0.5508  data: 0.0018  max mem: 5844\n",
            "Test:  [ 80/539]  eta: 0:04:31  loss: 159.3006 (198.3373)  time: 0.5261  data: 0.0018  max mem: 5844\n",
            "Test:  [ 90/539]  eta: 0:04:14  loss: 153.3902 (194.3214)  time: 0.3839  data: 0.0002  max mem: 5844\n",
            "Test:  [100/539]  eta: 0:04:06  loss: 153.3902 (191.9859)  time: 0.4467  data: 0.0009  max mem: 5844\n",
            "Test:  [110/539]  eta: 0:03:59  loss: 155.6280 (189.5873)  time: 0.5164  data: 0.0018  max mem: 5844\n",
            "Test:  [120/539]  eta: 0:03:48  loss: 162.4857 (188.6278)  time: 0.4544  data: 0.0012  max mem: 5844\n",
            "Test:  [130/539]  eta: 0:03:40  loss: 196.4372 (189.2522)  time: 0.4297  data: 0.0008  max mem: 5844\n",
            "Test:  [140/539]  eta: 0:03:38  loss: 201.5607 (190.1744)  time: 0.5725  data: 0.0023  max mem: 5844\n",
            "Test:  [150/539]  eta: 0:03:30  loss: 188.1438 (190.2756)  time: 0.5563  data: 0.0018  max mem: 5844\n",
            "Test:  [160/539]  eta: 0:03:21  loss: 161.6469 (188.1330)  time: 0.4181  data: 0.0004  max mem: 5844\n",
            "Test:  [170/539]  eta: 0:03:16  loss: 146.4373 (186.1464)  time: 0.4824  data: 0.0025  max mem: 5844\n",
            "Test:  [180/539]  eta: 0:03:09  loss: 154.7533 (184.5538)  time: 0.4896  data: 0.0023  max mem: 5844\n",
            "Test:  [190/539]  eta: 0:03:07  loss: 177.8853 (189.4140)  time: 0.5539  data: 0.0008  max mem: 5844\n",
            "Test:  [200/539]  eta: 0:03:02  loss: 230.0831 (190.9802)  time: 0.6472  data: 0.0022  max mem: 5844\n",
            "Test:  [210/539]  eta: 0:02:55  loss: 189.7949 (191.2551)  time: 0.5240  data: 0.0016  max mem: 5844\n",
            "Test:  [220/539]  eta: 0:02:51  loss: 190.2711 (191.9457)  time: 0.5146  data: 0.0016  max mem: 5844\n",
            "Test:  [230/539]  eta: 0:02:46  loss: 187.8773 (191.5084)  time: 0.5716  data: 0.0030  max mem: 5844\n",
            "Test:  [240/539]  eta: 0:02:39  loss: 182.1062 (191.4084)  time: 0.4865  data: 0.0020  max mem: 5844\n",
            "Test:  [250/539]  eta: 0:02:34  loss: 179.2688 (190.9292)  time: 0.4809  data: 0.0015  max mem: 5844\n",
            "Test:  [260/539]  eta: 0:02:28  loss: 176.7838 (190.6734)  time: 0.5367  data: 0.0021  max mem: 5844\n",
            "Test:  [270/539]  eta: 0:02:21  loss: 154.1756 (189.3607)  time: 0.4582  data: 0.0011  max mem: 5844\n",
            "Test:  [280/539]  eta: 0:02:16  loss: 185.2039 (189.9480)  time: 0.4442  data: 0.0005  max mem: 5844\n",
            "Test:  [290/539]  eta: 0:02:12  loss: 203.7741 (190.6718)  time: 0.6180  data: 0.0017  max mem: 5844\n",
            "Test:  [300/539]  eta: 0:02:06  loss: 189.0201 (190.0744)  time: 0.5761  data: 0.0014  max mem: 5844\n",
            "Test:  [310/539]  eta: 0:02:00  loss: 153.1924 (189.0491)  time: 0.4282  data: 0.0006  max mem: 5844\n",
            "Test:  [320/539]  eta: 0:01:56  loss: 188.9577 (190.3554)  time: 0.5803  data: 0.0021  max mem: 5844\n",
            "Test:  [330/539]  eta: 0:01:51  loss: 218.1136 (191.5288)  time: 0.6014  data: 0.0017  max mem: 5844\n",
            "Test:  [340/539]  eta: 0:01:46  loss: 236.4043 (192.9154)  time: 0.5970  data: 0.0016  max mem: 5844\n",
            "Test:  [350/539]  eta: 0:01:41  loss: 219.2680 (193.2276)  time: 0.6266  data: 0.0020  max mem: 5844\n",
            "Test:  [360/539]  eta: 0:01:35  loss: 191.1808 (193.6226)  time: 0.4988  data: 0.0006  max mem: 5844\n",
            "Test:  [370/539]  eta: 0:01:30  loss: 180.7102 (193.3672)  time: 0.4728  data: 0.0017  max mem: 5844\n",
            "Test:  [380/539]  eta: 0:01:24  loss: 174.3364 (193.6362)  time: 0.5103  data: 0.0030  max mem: 5844\n",
            "Test:  [390/539]  eta: 0:01:18  loss: 171.7872 (193.4161)  time: 0.4612  data: 0.0015  max mem: 5844\n",
            "Test:  [400/539]  eta: 0:01:13  loss: 157.8886 (192.6938)  time: 0.3931  data: 0.0006  max mem: 5844\n",
            "Test:  [410/539]  eta: 0:01:08  loss: 163.8512 (193.5797)  time: 0.5322  data: 0.0028  max mem: 5844\n",
            "Test:  [420/539]  eta: 0:01:02  loss: 183.5762 (193.0262)  time: 0.5135  data: 0.0027  max mem: 5844\n",
            "Test:  [430/539]  eta: 0:00:56  loss: 140.1735 (191.8426)  time: 0.3573  data: 0.0005  max mem: 5844\n",
            "Test:  [440/539]  eta: 0:00:51  loss: 99.0946 (189.8938)  time: 0.4181  data: 0.0019  max mem: 5844\n",
            "Test:  [450/539]  eta: 0:00:46  loss: 115.4485 (188.9835)  time: 0.5479  data: 0.0026  max mem: 5844\n",
            "Test:  [460/539]  eta: 0:00:41  loss: 146.1604 (188.4008)  time: 0.5302  data: 0.0010  max mem: 5844\n",
            "Test:  [470/539]  eta: 0:00:36  loss: 144.8988 (187.4198)  time: 0.5638  data: 0.0015  max mem: 5844\n",
            "Test:  [480/539]  eta: 0:00:31  loss: 145.5615 (186.9154)  time: 0.6312  data: 0.0021  max mem: 5844\n",
            "Test:  [490/539]  eta: 0:00:25  loss: 162.0320 (186.3485)  time: 0.5319  data: 0.0009  max mem: 5844\n",
            "Test:  [500/539]  eta: 0:00:20  loss: 161.4060 (185.9894)  time: 0.6379  data: 0.0018  max mem: 5844\n",
            "Test:  [510/539]  eta: 0:00:15  loss: 162.9941 (185.5493)  time: 0.6386  data: 0.0018  max mem: 5844\n",
            "Test:  [520/539]  eta: 0:00:10  loss: 171.0307 (185.2470)  time: 0.5234  data: 0.0009  max mem: 5844\n",
            "Test:  [530/539]  eta: 0:00:04  loss: 179.8360 (185.9931)  time: 0.6459  data: 0.0017  max mem: 5844\n",
            "Test:  [538/539]  eta: 0:00:00  loss: 214.9265 (186.7556)  time: 0.6673  data: 0.0013  max mem: 5844\n",
            "Test: Total time: 0:04:48 (0.5353 s / it)\n",
            "* Averaged stats: loss: 214.9265 (186.7556)  wer: 94.3228 (94.3228)\n",
            "* DEV loss 186.756\n",
            "* DEV wer 94.323 Min DEV WER 94.32277009665974\n",
            "/content/MSKA/train.py:219: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(str(output_dir) + '/best_checkpoint.pth', map_location='cpu')\n",
            "Test:  [  0/539]  eta: 0:59:08  loss: 358.7986 (358.7986)  time: 6.5842  data: 0.9113  max mem: 5844\n",
            "Test:  [ 10/539]  eta: 0:26:27  loss: 215.3751 (236.5669)  time: 3.0017  data: 0.0844  max mem: 5844\n",
            "Test:  [ 20/539]  eta: 0:24:59  loss: 223.5795 (236.9522)  time: 2.7040  data: 0.0021  max mem: 5844\n",
            "Test:  [ 30/539]  eta: 0:23:53  loss: 242.3798 (237.1828)  time: 2.7128  data: 0.0021  max mem: 5844\n",
            "Test:  [ 40/539]  eta: 0:21:30  loss: 188.6736 (221.3124)  time: 2.2666  data: 0.0017  max mem: 5844\n",
            "Test:  [ 50/539]  eta: 0:20:03  loss: 178.7144 (214.1121)  time: 1.9104  data: 0.0018  max mem: 5844\n",
            "Test:  [ 60/539]  eta: 0:18:56  loss: 186.1992 (209.6611)  time: 1.9384  data: 0.0016  max mem: 5844\n",
            "Test:  [ 70/539]  eta: 0:17:58  loss: 178.5206 (204.4583)  time: 1.8856  data: 0.0014  max mem: 5844\n",
            "Test:  [ 80/539]  eta: 0:16:59  loss: 159.3006 (198.3373)  time: 1.7535  data: 0.0017  max mem: 5844\n",
            "Test:  [ 90/539]  eta: 0:16:01  loss: 153.3902 (194.3214)  time: 1.5882  data: 0.0015  max mem: 5844\n",
            "Test:  [100/539]  eta: 0:15:20  loss: 153.3902 (191.9859)  time: 1.5965  data: 0.0015  max mem: 5844\n",
            "Test:  [110/539]  eta: 0:14:44  loss: 155.6280 (189.5873)  time: 1.6935  data: 0.0016  max mem: 5844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/MSKA/train.py --config /content/drive/MyDrive/ColabNotebooks/MSKA-main/configs/phoenix-2014t_s2g.yaml --resume /content/drive/MyDrive/ColabNotebooks/MSKA-main/pretrained_models/Phoenix2014T/best.pth --eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6etRYN6mJBMT",
        "outputId": "a34462f8-0b7a-43d5-be3a-1105398a7ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-05 07:38:01.582112: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-05 07:38:01.601433: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-05 07:38:01.607615: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-05 07:38:01.621145: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-05 07:38:02.754207: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "environ({'SHELL': '/bin/bash', 'NV_LIBCUBLAS_VERSION': '12.2.5.6-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'COLAB_JUPYTER_TRANSPORT': 'ipc', 'NV_NVML_DEV_VERSION': '12.2.140-1', 'NV_CUDNN_PACKAGE_NAME': 'libcudnn8', 'CGROUP_MEMORY_EVENTS': '/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events', 'NV_LIBNCCL_DEV_PACKAGE': 'libnccl-dev=2.19.3-1+cuda12.2', 'NV_LIBNCCL_DEV_PACKAGE_VERSION': '2.19.3-1', 'VM_GCE_METADATA_HOST': '169.254.169.253', 'HOSTNAME': '41953ffbeb55', 'LANGUAGE': 'en_US', 'TBE_RUNTIME_ADDR': '172.28.0.1:8011', 'COLAB_TPU_1VM': '', 'GCE_METADATA_TIMEOUT': '3', 'NVIDIA_REQUIRE_CUDA': 'cuda>=12.2 brand=tesla,driver>=470,driver<471 brand=unknown,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=geforce,driver>=470,driver<471 brand=geforcertx,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=titan,driver>=470,driver<471 brand=titanrtx,driver>=470,driver<471 brand=tesla,driver>=525,driver<526 brand=unknown,driver>=525,driver<526 brand=nvidia,driver>=525,driver<526 brand=nvidiartx,driver>=525,driver<526 brand=geforce,driver>=525,driver<526 brand=geforcertx,driver>=525,driver<526 brand=quadro,driver>=525,driver<526 brand=quadrortx,driver>=525,driver<526 brand=titan,driver>=525,driver<526 brand=titanrtx,driver>=525,driver<526', 'NV_LIBCUBLAS_DEV_PACKAGE': 'libcublas-dev-12-2=12.2.5.6-1', 'NV_NVTX_VERSION': '12.2.140-1', 'COLAB_JUPYTER_IP': '172.28.0.12', 'NV_CUDA_CUDART_DEV_VERSION': '12.2.140-1', 'NV_LIBCUSPARSE_VERSION': '12.1.2.141-1', 'COLAB_LANGUAGE_SERVER_PROXY_ROOT_URL': 'http://172.28.0.1:8013/', 'NV_LIBNPP_VERSION': '12.2.1.4-1', 'NCCL_VERSION': '2.19.3-1', 'KMP_LISTEN_PORT': '6000', 'TF_FORCE_GPU_ALLOW_GROWTH': 'true', 'ENV': '/root/.bashrc', 'PWD': '/content', 'TBE_EPHEM_CREDS_ADDR': '172.28.0.1:8009', 'COLAB_LANGUAGE_SERVER_PROXY_REQUEST_TIMEOUT': '30s', 'TBE_CREDS_ADDR': '172.28.0.1:8008', 'NV_CUDNN_PACKAGE': 'libcudnn8=8.9.6.50-1+cuda12.2', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'COLAB_JUPYTER_TOKEN': '', 'LAST_FORCED_REBUILD': '20241028', 'NV_NVPROF_DEV_PACKAGE': 'cuda-nvprof-12-2=12.2.142-1', 'NV_LIBNPP_PACKAGE': 'libnpp-12-2=12.2.1.4-1', 'NV_LIBNCCL_DEV_PACKAGE_NAME': 'libnccl-dev', 'TCLLIBPATH': '/usr/share/tcltk/tcllib1.20', '_': '/usr/local/bin/python', 'NV_LIBCUBLAS_DEV_VERSION': '12.2.5.6-1', 'NVIDIA_PRODUCT_NAME': 'CUDA', 'COLAB_KERNEL_MANAGER_PROXY_HOST': '172.28.0.12', 'NV_LIBCUBLAS_DEV_PACKAGE_NAME': 'libcublas-dev-12-2', 'USE_AUTH_EPHEM': '1', 'NV_CUDA_CUDART_VERSION': '12.2.140-1', 'COLAB_WARMUP_DEFAULTS': '1', 'HOME': '/root', 'LANG': 'en_US.UTF-8', 'COLUMNS': '100', 'CUDA_VERSION': '12.2.2', 'CLOUDSDK_CONFIG': '/content/.config', 'NV_LIBCUBLAS_PACKAGE': 'libcublas-12-2=12.2.5.6-1', 'NV_CUDA_NSIGHT_COMPUTE_DEV_PACKAGE': 'cuda-nsight-compute-12-2=12.2.2-1', 'COLAB_RELEASE_TAG': 'release-colab_20241203-060126_RC01', 'PYDEVD_USE_FRAME_EVAL': 'NO', 'KMP_TARGET_PORT': '9000', 'CLICOLOR': '1', 'KMP_EXTRA_ARGS': '--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https://colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-14rkndzj9e26h --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true', 'NV_LIBNPP_DEV_PACKAGE': 'libnpp-dev-12-2=12.2.1.4-1', 'COLAB_LANGUAGE_SERVER_PROXY_LSP_DIRS': '/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages', 'NV_LIBCUBLAS_PACKAGE_NAME': 'libcublas-12-2', 'COLAB_KERNEL_MANAGER_PROXY_PORT': '6000', 'CLOUDSDK_PYTHON': 'python3', 'NV_LIBNPP_DEV_VERSION': '12.2.1.4-1', 'ENABLE_DIRECTORYPREFETCHER': '1', 'NO_GCE_CHECK': 'False', 'JPY_PARENT_PID': '116', 'PYTHONPATH': '/env/python', 'TERM': 'xterm-color', 'NV_LIBCUSPARSE_DEV_VERSION': '12.1.2.141-1', 'GIT_PAGER': 'cat', 'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs', 'NV_CUDNN_VERSION': '8.9.6.50', 'SHLVL': '0', 'PAGER': 'cat', 'NV_CUDA_LIB_VERSION': '12.2.2-1', 'COLAB_LANGUAGE_SERVER_PROXY': '/usr/colab/bin/language_service', 'NVARCH': 'x86_64', 'NV_CUDNN_PACKAGE_DEV': 'libcudnn8-dev=8.9.6.50-1+cuda12.2', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-12-2', 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline', 'NV_LIBNCCL_PACKAGE': 'libnccl2=2.19.3-1+cuda12.2', 'LD_LIBRARY_PATH': '/usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia', 'COLAB_GPU': '1', 'NV_CUDA_NSIGHT_COMPUTE_VERSION': '12.2.2-1', 'GCS_READ_CACHE_BLOCK_SIZE_MB': '16', 'NV_NVPROF_VERSION': '12.2.142-1', 'LC_ALL': 'en_US.UTF-8', 'COLAB_FILE_HANDLER_ADDR': 'localhost:3453', 'PATH': '/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin', 'NV_LIBNCCL_PACKAGE_NAME': 'libnccl2', 'COLAB_DEBUG_ADAPTER_MUX_PATH': '/usr/local/bin/dap_multiplexer', 'NV_LIBNCCL_PACKAGE_VERSION': '2.19.3-1', 'PYTHONWARNINGS': 'ignore:::pip._internal.cli.base_command', 'DEBIAN_FRONTEND': 'noninteractive', 'COLAB_BACKEND_VERSION': 'next', 'OLDPWD': '/', 'TF2_BEHAVIOR': '1', 'TPU_ML_PLATFORM': 'Tensorflow', 'TPU_ML_PLATFORM_VERSION': '2.17.1', 'TF_CPP_MIN_LOG_LEVEL': '1', 'QT_QPA_PLATFORM_PLUGIN_PATH': '/usr/local/lib/python3.10/dist-packages/cv2/qt/plugins', 'QT_QPA_FONTDIR': '/usr/local/lib/python3.10/dist-packages/cv2/qt/fonts', 'TOKENIZERS_PARALLELISM': 'false', 'WANDB_MODE': 'disabled'})\n",
            "Not using distributed mode\n",
            "Namespace(batch_size=8, epochs=100, world_size=2, dist_url='env://', local_rank=0, finetune='', device='cuda', seed=0, resume='/content/drive/MyDrive/ColabNotebooks/MSKA-main/pretrained_models/Phoenix2014T/best.pth', start_epoch=0, eval=True, num_workers=4, pin_mem=True, config='/content/drive/MyDrive/ColabNotebooks/MSKA-main/configs/phoenix-2014t_s2g.yaml', log_all=False, entity=None, project='VLP', run=<wandb.sdk.wandb_run.Run object at 0x7a88c2769630>, distributed=False)\n",
            "Creating dataset:\n",
            "1\n",
            "#total train set: 7096.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "#total val set: 519.\n",
            "#total test set: 642.\n",
            "Creating model:\n",
            "SignLanguageModel(\n",
            "  (recognition_network): Recognition(\n",
            "    (visual_backbone_keypoint): DSTA(\n",
            "      (left_input_map): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): LeakyReLU(negative_slope=0.1)\n",
            "      )\n",
            "      (right_input_map): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): LeakyReLU(negative_slope=0.1)\n",
            "      )\n",
            "      (body_input_map): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): LeakyReLU(negative_slope=0.1)\n",
            "      )\n",
            "      (face_input_map): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): LeakyReLU(negative_slope=0.1)\n",
            "      )\n",
            "      (face_graph_layers): ModuleList(\n",
            "        (0): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(7, 1), stride=(2, 1), padding=(3, 0))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (1): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (2): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (3): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (4): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (5-7): 3 x STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (left_graph_layers): ModuleList(\n",
            "        (0): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(7, 1), stride=(2, 1), padding=(3, 0))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (1): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (2): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (3): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (4): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (5-7): 3 x STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (right_graph_layers): ModuleList(\n",
            "        (0): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(7, 1), stride=(2, 1), padding=(3, 0))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (1): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (2): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (3): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (4): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (5-7): 3 x STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (body_graph_layers): ModuleList(\n",
            "        (0): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(7, 1), stride=(2, 1), padding=(3, 0))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (1): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (2): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (3): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (4): STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs1): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downs2): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (downt2): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (5-7): 3 x STAttentionBlock(\n",
            "          (pes): PositionalEncoding()\n",
            "          (ff_nets): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (in_nets): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (out_nets): Sequential(\n",
            "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (out_nett): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (tan): Tanh()\n",
            "          (relu): LeakyReLU(negative_slope=0.1)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (drop_out): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (fuse_visual_head): VisualHead(\n",
            "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
            "      (bn1): MaskedNorm(\n",
            "        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu1): ReLU()\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (pe): PositionalEncoding()\n",
            "      (feedforward): PositionwiseFeedForward(\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (pwff_layer): Sequential(\n",
            "          (0): Conv1d(512, 2048, kernel_size=(3,), stride=(1,), padding=same)\n",
            "          (1): ReLU()\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Conv1d(2048, 512, kernel_size=(3,), stride=(1,), padding=same)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      (plus_conv): Identity()\n",
            "      (gloss_output_layer): Linear(in_features=512, out_features=1094, bias=True)\n",
            "    )\n",
            "    (body_visual_head): VisualHead(\n",
            "      (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
            "      (bn1): MaskedNorm(\n",
            "        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu1): ReLU()\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (pe): PositionalEncoding()\n",
            "      (feedforward): PositionwiseFeedForward(\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (pwff_layer): Sequential(\n",
            "          (0): Conv1d(512, 2048, kernel_size=(3,), stride=(1,), padding=same)\n",
            "          (1): ReLU()\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Conv1d(2048, 512, kernel_size=(3,), stride=(1,), padding=same)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      (plus_conv): Identity()\n",
            "      (gloss_output_layer): Linear(in_features=512, out_features=1094, bias=True)\n",
            "    )\n",
            "    (left_visual_head): VisualHead(\n",
            "      (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (bn1): MaskedNorm(\n",
            "        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu1): ReLU()\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (pe): PositionalEncoding()\n",
            "      (feedforward): PositionwiseFeedForward(\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (pwff_layer): Sequential(\n",
            "          (0): Conv1d(512, 2048, kernel_size=(3,), stride=(1,), padding=same)\n",
            "          (1): ReLU()\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Conv1d(2048, 512, kernel_size=(3,), stride=(1,), padding=same)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      (plus_conv): Identity()\n",
            "      (gloss_output_layer): Linear(in_features=512, out_features=1094, bias=True)\n",
            "    )\n",
            "    (right_visual_head): VisualHead(\n",
            "      (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (bn1): MaskedNorm(\n",
            "        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu1): ReLU()\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (pe): PositionalEncoding()\n",
            "      (feedforward): PositionwiseFeedForward(\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (pwff_layer): Sequential(\n",
            "          (0): Conv1d(512, 2048, kernel_size=(3,), stride=(1,), padding=same)\n",
            "          (1): ReLU()\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Conv1d(2048, 512, kernel_size=(3,), stride=(1,), padding=same)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      (plus_conv): Identity()\n",
            "      (gloss_output_layer): Linear(in_features=512, out_features=1094, bias=True)\n",
            "    )\n",
            "    (recognition_loss_func): CTCLoss()\n",
            "  )\n",
            ")\n",
            "number of params: 44.159272M\n",
            "/content/MSKA/train.py:138: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(args.resume, map_location='cpu')\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1733384312.628951    4681 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1733384312.945930    4681 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1733384312.946215    4681 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1733384312.949178    4681 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1733384312.949421    4681 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1733384312.949628    4681 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1733384312.951886    4681 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1733384312.952054    4681 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-12-05 07:38:32.952254: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1733384312.983288    4681 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-12-05 07:38:32.986942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12605 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Test:  [ 0/65]  eta: 0:09:42  loss: 38.4826 (38.4826)  time: 8.9590  data: 0.5778  max mem: 864\n",
            "Test:  [10/65]  eta: 0:04:06  loss: 36.5755 (37.1441)  time: 4.4745  data: 0.0540  max mem: 1096\n",
            "Test:  [20/65]  eta: 0:03:10  loss: 39.3809 (40.9553)  time: 4.0070  data: 0.0012  max mem: 1096\n",
            "Test:  [30/65]  eta: 0:02:26  loss: 41.9803 (41.2606)  time: 4.0125  data: 0.0014  max mem: 1096\n",
            "Test:  [40/65]  eta: 0:01:42  loss: 40.1438 (40.3496)  time: 3.9787  data: 0.0019  max mem: 1096\n",
            "Test:  [50/65]  eta: 0:01:02  loss: 46.5406 (42.9224)  time: 4.1036  data: 0.0019  max mem: 1230\n",
            "Test:  [60/65]  eta: 0:00:21  loss: 50.0922 (43.4705)  time: 4.4879  data: 0.0016  max mem: 1230\n",
            "Test:  [64/65]  eta: 0:00:04  loss: 47.8787 (43.4010)  time: 4.4980  data: 0.0013  max mem: 1230\n",
            "Test: Total time: 0:04:35 (4.2433 s / it)\n",
            "* Averaged stats: loss: 47.8787 (43.4010)  wer: 20.0694 (20.0694)\n",
            "* DEV loss 43.401\n",
            "Dev loss of the network on the 65 test videos: 43.401\n",
            "Test:  [ 0/81]  eta: 0:06:26  loss: 43.1414 (43.1414)  time: 4.7665  data: 0.4639  max mem: 1230\n",
            "Test:  [10/81]  eta: 0:04:58  loss: 28.2511 (33.5942)  time: 4.2058  data: 0.0441  max mem: 1230\n",
            "Test:  [20/81]  eta: 0:04:13  loss: 34.4888 (38.5738)  time: 4.1301  data: 0.0015  max mem: 1230\n",
            "Test:  [30/81]  eta: 0:03:28  loss: 48.4945 (42.5888)  time: 4.0372  data: 0.0006  max mem: 1230\n",
            "Test:  [40/81]  eta: 0:02:47  loss: 48.4945 (43.4289)  time: 3.9999  data: 0.0009  max mem: 1230\n",
            "Test:  [50/81]  eta: 0:02:05  loss: 35.1845 (42.5046)  time: 3.9913  data: 0.0017  max mem: 1230\n",
            "Test:  [60/81]  eta: 0:01:23  loss: 35.1845 (42.4813)  time: 3.7654  data: 0.0026  max mem: 1230\n",
            "Test:  [70/81]  eta: 0:00:43  loss: 38.0258 (41.8697)  time: 3.5404  data: 0.0028  max mem: 1230\n",
            "Test:  [80/81]  eta: 0:00:03  loss: 40.7436 (41.8088)  time: 3.5165  data: 0.0013  max mem: 1230\n",
            "Test: Total time: 0:05:13 (3.8683 s / it)\n",
            "* Averaged stats: loss: 40.7436 (41.8088)  wer: 20.5447 (20.5447)\n",
            "* DEV loss 41.809\n",
            "Test loss of the network on the 81 test videos: 41.809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/ColabNotebooks/MSKA-main/data/Phoenix-2014T/Phoenix-2014T.train /content/data/Phoenix-2014T\n",
        "!cp -r /content/drive/MyDrive/ColabNotebooks/MSKA-main/data/Phoenix-2014T/Phoenix-2014T.dev /content/data/Phoenix-2014T\n",
        "!cp -r /content/drive/MyDrive/ColabNotebooks/MSKA-main/data/Phoenix-2014T/Phoenix-2014T.test /content/data/Phoenix-2014T"
      ],
      "metadata": {
        "id": "_wCfgra8KuxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjRlh8703Z6E",
        "outputId": "cc81fc7a-8270-491e-d14f-d702f4d1c045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7RwVSwhsx42",
        "outputId": "5706287e-1eb8-41b0-8a99-c804a137a669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting loguru\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: portalocker, loguru\n",
            "Successfully installed loguru-0.7.3 portalocker-3.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install loguru portalocker"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "%cd ctcdecode/third_party\n",
        "!tar -zxvf boost_1_67_0.tar.gz && tar -zxvf openfst-1.6.7.tar.gz\n",
        "%cd ../\n",
        "!python setup.py build\n",
        "!python setup.py install\n",
        "!pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9GrLW-IsA5H",
        "outputId": "cf3ed22d-6863-4b7d-b2ce-71251e8890da",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mKt qu truyn trc tuyn b ct bt n 5000 dng cui.\u001b[0m\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:196:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:209:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(int64_t, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  209 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e4m3fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:209:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:535\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:115:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(const c10::Half&, const c10::Half&)\u001b[m\u001b[K\n",
            "  115 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Half& a, const Half& b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:115:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:163:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Half, float)\u001b[m\u001b[K\n",
            "  163 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:163:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:177:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Half)\u001b[m\u001b[K\n",
            "  177 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Half b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:177:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:206:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Half, double)\u001b[m\u001b[K\n",
            "  206 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:206:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:220:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Half)\u001b[m\u001b[K\n",
            "  220 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Half b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:220:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:236:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(c10::Half, int)\u001b[m\u001b[K\n",
            "  236 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, int b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:236:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:249:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(int, c10::Half)\u001b[m\u001b[K\n",
            "  249 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Half b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:249:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:264:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(c10::Half, int64_t)\u001b[m\u001b[K\n",
            "  264 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, int64_t b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:264:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:277:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(int64_t, c10::Half)\u001b[m\u001b[K\n",
            "  277 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Half b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:277:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:148\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:52:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(const c10::Float8_e5m2&, const c10::Float8_e5m2&)\u001b[m\u001b[K\n",
            "   52 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e5m2& a, const Float8_e5m2& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:52:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:102:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e5m2, float)\u001b[m\u001b[K\n",
            "  102 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:102:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:116:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  116 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e5m2 b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:116:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:145:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e5m2, double)\u001b[m\u001b[K\n",
            "  145 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:145:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:159:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  159 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e5m2 b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:159:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:175:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(c10::Float8_e5m2, int)\u001b[m\u001b[K\n",
            "  175 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, int b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:175:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:188:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(int, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  188 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e5m2 b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:188:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:203:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(c10::Float8_e5m2, int64_t)\u001b[m\u001b[K\n",
            "  203 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, int64_t b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:203:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:216:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(int64_t, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  216 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e5m2 b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:216:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz.h:138\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:49:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(const c10::Float8_e5m2fnuz&, const c10::Float8_e5m2fnuz&)\u001b[m\u001b[K\n",
            "   49 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e5m2fnuz& a, const Float8_e5m2fnuz& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:49:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:99:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e5m2fnuz, float)\u001b[m\u001b[K\n",
            "   99 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:99:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:113:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  113 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e5m2fnuz b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:113:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:142:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e5m2fnuz, double)\u001b[m\u001b[K\n",
            "  142 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:142:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:156:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  156 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e5m2fnuz b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:156:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:172:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(c10::Float8_e5m2fnuz, int)\u001b[m\u001b[K\n",
            "  172 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, int b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:172:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:185:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(int, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  185 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e5m2fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:185:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:200:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(c10::Float8_e5m2fnuz, int64_t)\u001b[m\u001b[K\n",
            "  200 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, int64_t b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:200:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:213:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(int64_t, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  213 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e5m2fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:213:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, int64_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(int64_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, int32_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(int32_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, uint64_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(uint64_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, uint32_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(uint32_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(const c10::SymInt&, double)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(double, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(const c10::SymInt&, float)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(float, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue.h:1581\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List_inl.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List.h:488\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef_inl.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef.h:631\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/WrapDimUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorNames.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/NamedTensorUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:112:35:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno match for \u001b[01m\u001b[Koperator*\u001b[m\u001b[K (operand type is \u001b[01m\u001b[Kconst TypePtr\u001b[m\u001b[K {aka \u001b[01m\u001b[Kconst c10::Type::SingletonOrSharedTypePtr<c10::Type>\u001b[m\u001b[K})\n",
            "  112 |       return *getElementType() == \u001b[01;31m\u001b[K*rhs_->getElementType()\u001b[m\u001b[K;\n",
            "      |                                   \u001b[01;31m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:397:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Ktemplate<class T> constexpr c10::complex<U> c10::operator*(const c10::complex<U>&, const c10::complex<U>&)\u001b[m\u001b[K\n",
            "  397 | constexpr complex<T> \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const complex<T>& lhs, const complex<T>& rhs) {\n",
            "      |                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:397:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  template argument deduction/substitution failed:\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue.h:1581\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List_inl.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List.h:488\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef_inl.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef.h:631\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/WrapDimUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorNames.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/NamedTensorUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:112:35:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  \u001b[01m\u001b[Kconst TypePtr\u001b[m\u001b[K {aka \u001b[01m\u001b[Kconst c10::Type::SingletonOrSharedTypePtr<c10::Type>\u001b[m\u001b[K} is not derived from \u001b[01m\u001b[Kconst c10::complex<U>\u001b[m\u001b[K\n",
            "  112 |       return *getElementType() == \u001b[01;36m\u001b[K*rhs_->getElementType()\u001b[m\u001b[K;\n",
            "      |                                   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:403:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Ktemplate<class T> constexpr c10::complex<U> c10::operator*(const c10::complex<U>&, const T&)\u001b[m\u001b[K\n",
            "  403 | constexpr complex<T> \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const complex<T>& lhs, const T& rhs) {\n",
            "      |                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:403:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  template argument deduction/substitution failed:\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue.h:1581\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List_inl.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List.h:488\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef_inl.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef.h:631\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/WrapDimUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorNames.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/NamedTensorUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:112:35:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  \u001b[01m\u001b[Kconst TypePtr\u001b[m\u001b[K {aka \u001b[01m\u001b[Kconst c10::Type::SingletonOrSharedTypePtr<c10::Type>\u001b[m\u001b[K} is not derived from \u001b[01m\u001b[Kconst c10::complex<U>\u001b[m\u001b[K\n",
            "  112 |       return *getElementType() == \u001b[01;36m\u001b[K*rhs_->getElementType()\u001b[m\u001b[K;\n",
            "      |                                   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:409:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Ktemplate<class T> constexpr c10::complex<U> c10::operator*(const T&, const c10::complex<U>&)\u001b[m\u001b[K\n",
            "  409 | constexpr complex<T> \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const T& lhs, const complex<T>& rhs) {\n",
            "      |                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:409:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  template argument deduction/substitution failed:\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue.h:1581\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List_inl.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List.h:488\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef_inl.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef.h:631\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/WrapDimUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorNames.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/NamedTensorUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:112:35:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  112 |       return *getElementType() == \u001b[01;36m\u001b[K*rhs_->getElementType()\u001b[m\u001b[K;\n",
            "      |                                   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16.h:133\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:114:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(const c10::BFloat16&, const c10::BFloat16&)\u001b[m\u001b[K\n",
            "  114 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const BFloat16& a, const BFloat16& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:114:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:170:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::BFloat16, float)\u001b[m\u001b[K\n",
            "  170 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(BFloat16 a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:170:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:183:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::BFloat16)\u001b[m\u001b[K\n",
            "  183 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, BFloat16 b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:183:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:211:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::BFloat16, double)\u001b[m\u001b[K\n",
            "  211 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(BFloat16 a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:211:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:224:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::BFloat16)\u001b[m\u001b[K\n",
            "  224 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, BFloat16 b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:224:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:239:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(c10::BFloat16, int)\u001b[m\u001b[K\n",
            "  239 | inline C10_HOST_DEVICE BFloat16 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(BFloat16 a, int b) {\n",
            "      |                                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:239:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:252:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(int, c10::BFloat16)\u001b[m\u001b[K\n",
            "  252 | inline C10_HOST_DEVICE BFloat16 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, BFloat16 b) {\n",
            "      |                                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:252:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:267:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(c10::BFloat16, int64_t)\u001b[m\u001b[K\n",
            "  267 | inline C10_HOST_DEVICE BFloat16 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(BFloat16 a, int64_t b) {\n",
            "      |                                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:267:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:280:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(int64_t, c10::BFloat16)\u001b[m\u001b[K\n",
            "  280 | inline C10_HOST_DEVICE BFloat16 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, BFloat16 b) {\n",
            "      |                                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:280:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn.h:240\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:44:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(const c10::Float8_e4m3fn&, const c10::Float8_e4m3fn&)\u001b[m\u001b[K\n",
            "   44 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e4m3fn& a, const Float8_e4m3fn& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:44:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:94:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e4m3fn, float)\u001b[m\u001b[K\n",
            "   94 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fn a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:94:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:108:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e4m3fn)\u001b[m\u001b[K\n",
            "  108 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e4m3fn b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:108:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:137:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e4m3fn, double)\u001b[m\u001b[K\n",
            "  137 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fn a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:137:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:151:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e4m3fn)\u001b[m\u001b[K\n",
            "  151 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e4m3fn b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:151:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:167:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(c10::Float8_e4m3fn, int)\u001b[m\u001b[K\n",
            "  167 | inline C10_HOST_DEVICE Float8_e4m3fn \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fn a, int b) {\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:167:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:180:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(int, c10::Float8_e4m3fn)\u001b[m\u001b[K\n",
            "  180 | inline C10_HOST_DEVICE Float8_e4m3fn \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e4m3fn b) {\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:180:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:195:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(c10::Float8_e4m3fn, int64_t)\u001b[m\u001b[K\n",
            "  195 | inline C10_HOST_DEVICE Float8_e4m3fn \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fn a, int64_t b) {\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:195:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:208:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(int64_t, c10::Float8_e4m3fn)\u001b[m\u001b[K\n",
            "  208 | inline C10_HOST_DEVICE Float8_e4m3fn \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e4m3fn b) {\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:208:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz.h:139\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:45:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(const c10::Float8_e4m3fnuz&, const c10::Float8_e4m3fnuz&)\u001b[m\u001b[K\n",
            "   45 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e4m3fnuz& a, const Float8_e4m3fnuz& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:45:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:95:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e4m3fnuz, float)\u001b[m\u001b[K\n",
            "   95 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fnuz a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:95:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:109:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  109 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e4m3fnuz b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:109:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:138:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e4m3fnuz, double)\u001b[m\u001b[K\n",
            "  138 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fnuz a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:138:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:152:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  152 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e4m3fnuz b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:152:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:168:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(c10::Float8_e4m3fnuz, int)\u001b[m\u001b[K\n",
            "  168 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fnuz a, int b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:168:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:181:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(int, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  181 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e4m3fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:181:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:196:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(c10::Float8_e4m3fnuz, int64_t)\u001b[m\u001b[K\n",
            "  196 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fnuz a, int64_t b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:196:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:209:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(int64_t, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  209 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e4m3fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:209:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:535\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:115:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(const c10::Half&, const c10::Half&)\u001b[m\u001b[K\n",
            "  115 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Half& a, const Half& b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:115:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:163:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Half, float)\u001b[m\u001b[K\n",
            "  163 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:163:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:177:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Half)\u001b[m\u001b[K\n",
            "  177 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Half b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:177:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:206:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Half, double)\u001b[m\u001b[K\n",
            "  206 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:206:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:220:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Half)\u001b[m\u001b[K\n",
            "  220 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Half b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:220:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:236:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(c10::Half, int)\u001b[m\u001b[K\n",
            "  236 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, int b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:236:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:249:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(int, c10::Half)\u001b[m\u001b[K\n",
            "  249 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Half b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:249:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:264:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(c10::Half, int64_t)\u001b[m\u001b[K\n",
            "  264 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, int64_t b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:264:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:277:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(int64_t, c10::Half)\u001b[m\u001b[K\n",
            "  277 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Half b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:277:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:148\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:52:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(const c10::Float8_e5m2&, const c10::Float8_e5m2&)\u001b[m\u001b[K\n",
            "   52 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e5m2& a, const Float8_e5m2& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:52:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:102:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e5m2, float)\u001b[m\u001b[K\n",
            "  102 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:102:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:116:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  116 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e5m2 b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:116:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:145:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e5m2, double)\u001b[m\u001b[K\n",
            "  145 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:145:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:159:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  159 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e5m2 b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:159:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:175:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(c10::Float8_e5m2, int)\u001b[m\u001b[K\n",
            "  175 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, int b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:175:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:188:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(int, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  188 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e5m2 b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:188:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:203:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(c10::Float8_e5m2, int64_t)\u001b[m\u001b[K\n",
            "  203 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, int64_t b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:203:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:216:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(int64_t, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  216 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e5m2 b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:216:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz.h:138\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:49:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(const c10::Float8_e5m2fnuz&, const c10::Float8_e5m2fnuz&)\u001b[m\u001b[K\n",
            "   49 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e5m2fnuz& a, const Float8_e5m2fnuz& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:49:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:99:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e5m2fnuz, float)\u001b[m\u001b[K\n",
            "   99 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:99:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:113:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  113 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e5m2fnuz b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:113:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:142:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e5m2fnuz, double)\u001b[m\u001b[K\n",
            "  142 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:142:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:156:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  156 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e5m2fnuz b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:156:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:172:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(c10::Float8_e5m2fnuz, int)\u001b[m\u001b[K\n",
            "  172 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, int b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:172:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:185:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(int, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  185 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e5m2fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:185:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:200:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(c10::Float8_e5m2fnuz, int64_t)\u001b[m\u001b[K\n",
            "  200 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, int64_t b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:200:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:213:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(int64_t, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  213 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e5m2fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:213:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, int64_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(int64_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, int32_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(int32_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, uint64_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(uint64_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, uint32_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(uint32_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(const c10::SymInt&, double)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(double, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(const c10::SymInt&, float)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(float, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue.h:1581\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List_inl.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List.h:488\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef_inl.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef.h:631\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/WrapDimUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorNames.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/NamedTensorUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h: In instantiation of \u001b[01m\u001b[Kbool c10::SingleElementType<K, T>::equals(const c10::Type&) const [with c10::TypeKind K = c10::TypeKind::FutureType; T = c10::FutureType]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:110:8:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:112:14:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno match for \u001b[01m\u001b[Koperator*\u001b[m\u001b[K (operand type is \u001b[01m\u001b[Kconst TypePtr\u001b[m\u001b[K {aka \u001b[01m\u001b[Kconst c10::Type::SingletonOrSharedTypePtr<c10::Type>\u001b[m\u001b[K})\n",
            "  112 |       return \u001b[01;31m\u001b[K*getElementType()\u001b[m\u001b[K == *rhs_->getElementType();\n",
            "      |              \u001b[01;31m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:397:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Ktemplate<class T> constexpr c10::complex<U> c10::operator*(const c10::complex<U>&, const c10::complex<U>&)\u001b[m\u001b[K\n",
            "  397 | constexpr complex<T> \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const complex<T>& lhs, const complex<T>& rhs) {\n",
            "      |                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:397:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  template argument deduction/substitution failed:\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue.h:1581\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List_inl.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List.h:488\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef_inl.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef.h:631\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/WrapDimUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorNames.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/NamedTensorUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:112:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  \u001b[01m\u001b[Kconst TypePtr\u001b[m\u001b[K {aka \u001b[01m\u001b[Kconst c10::Type::SingletonOrSharedTypePtr<c10::Type>\u001b[m\u001b[K} is not derived from \u001b[01m\u001b[Kconst c10::complex<U>\u001b[m\u001b[K\n",
            "  112 |       return \u001b[01;36m\u001b[K*getElementType()\u001b[m\u001b[K == *rhs_->getElementType();\n",
            "      |              \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:403:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Ktemplate<class T> constexpr c10::complex<U> c10::operator*(const c10::complex<U>&, const T&)\u001b[m\u001b[K\n",
            "  403 | constexpr complex<T> \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const complex<T>& lhs, const T& rhs) {\n",
            "      |                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:403:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  template argument deduction/substitution failed:\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue.h:1581\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List_inl.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List.h:488\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef_inl.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef.h:631\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/WrapDimUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorNames.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/NamedTensorUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:112:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  \u001b[01m\u001b[Kconst TypePtr\u001b[m\u001b[K {aka \u001b[01m\u001b[Kconst c10::Type::SingletonOrSharedTypePtr<c10::Type>\u001b[m\u001b[K} is not derived from \u001b[01m\u001b[Kconst c10::complex<U>\u001b[m\u001b[K\n",
            "  112 |       return \u001b[01;36m\u001b[K*getElementType()\u001b[m\u001b[K == *rhs_->getElementType();\n",
            "      |              \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:409:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Ktemplate<class T> constexpr c10::complex<U> c10::operator*(const T&, const c10::complex<U>&)\u001b[m\u001b[K\n",
            "  409 | constexpr complex<T> \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const T& lhs, const complex<T>& rhs) {\n",
            "      |                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:409:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  template argument deduction/substitution failed:\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue.h:1581\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List_inl.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List.h:488\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef_inl.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef.h:631\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/WrapDimUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorNames.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/NamedTensorUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:112:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  112 |       return \u001b[01;36m\u001b[K*getElementType()\u001b[m\u001b[K == *rhs_->getElementType();\n",
            "      |              \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16.h:133\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:114:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(const c10::BFloat16&, const c10::BFloat16&)\u001b[m\u001b[K\n",
            "  114 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const BFloat16& a, const BFloat16& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:114:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:170:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::BFloat16, float)\u001b[m\u001b[K\n",
            "  170 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(BFloat16 a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:170:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:183:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::BFloat16)\u001b[m\u001b[K\n",
            "  183 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, BFloat16 b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:183:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:211:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::BFloat16, double)\u001b[m\u001b[K\n",
            "  211 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(BFloat16 a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:211:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:224:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::BFloat16)\u001b[m\u001b[K\n",
            "  224 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, BFloat16 b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:224:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:239:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(c10::BFloat16, int)\u001b[m\u001b[K\n",
            "  239 | inline C10_HOST_DEVICE BFloat16 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(BFloat16 a, int b) {\n",
            "      |                                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:239:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:252:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(int, c10::BFloat16)\u001b[m\u001b[K\n",
            "  252 | inline C10_HOST_DEVICE BFloat16 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, BFloat16 b) {\n",
            "      |                                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:252:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:267:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(c10::BFloat16, int64_t)\u001b[m\u001b[K\n",
            "  267 | inline C10_HOST_DEVICE BFloat16 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(BFloat16 a, int64_t b) {\n",
            "      |                                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:267:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:280:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(int64_t, c10::BFloat16)\u001b[m\u001b[K\n",
            "  280 | inline C10_HOST_DEVICE BFloat16 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, BFloat16 b) {\n",
            "      |                                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:280:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn.h:240\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:44:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(const c10::Float8_e4m3fn&, const c10::Float8_e4m3fn&)\u001b[m\u001b[K\n",
            "   44 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e4m3fn& a, const Float8_e4m3fn& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:44:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:94:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e4m3fn, float)\u001b[m\u001b[K\n",
            "   94 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fn a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:94:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:108:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e4m3fn)\u001b[m\u001b[K\n",
            "  108 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e4m3fn b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:108:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:137:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e4m3fn, double)\u001b[m\u001b[K\n",
            "  137 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fn a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:137:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:151:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e4m3fn)\u001b[m\u001b[K\n",
            "  151 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e4m3fn b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:151:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:167:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(c10::Float8_e4m3fn, int)\u001b[m\u001b[K\n",
            "  167 | inline C10_HOST_DEVICE Float8_e4m3fn \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fn a, int b) {\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:167:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:180:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(int, c10::Float8_e4m3fn)\u001b[m\u001b[K\n",
            "  180 | inline C10_HOST_DEVICE Float8_e4m3fn \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e4m3fn b) {\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:180:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:195:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(c10::Float8_e4m3fn, int64_t)\u001b[m\u001b[K\n",
            "  195 | inline C10_HOST_DEVICE Float8_e4m3fn \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fn a, int64_t b) {\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:195:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:208:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(int64_t, c10::Float8_e4m3fn)\u001b[m\u001b[K\n",
            "  208 | inline C10_HOST_DEVICE Float8_e4m3fn \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e4m3fn b) {\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:208:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz.h:139\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:45:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(const c10::Float8_e4m3fnuz&, const c10::Float8_e4m3fnuz&)\u001b[m\u001b[K\n",
            "   45 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e4m3fnuz& a, const Float8_e4m3fnuz& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:45:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:95:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e4m3fnuz, float)\u001b[m\u001b[K\n",
            "   95 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fnuz a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:95:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:109:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  109 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e4m3fnuz b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:109:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:138:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e4m3fnuz, double)\u001b[m\u001b[K\n",
            "  138 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fnuz a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:138:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:152:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  152 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e4m3fnuz b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:152:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:168:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(c10::Float8_e4m3fnuz, int)\u001b[m\u001b[K\n",
            "  168 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fnuz a, int b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:168:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:181:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(int, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  181 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e4m3fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:181:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:196:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(c10::Float8_e4m3fnuz, int64_t)\u001b[m\u001b[K\n",
            "  196 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fnuz a, int64_t b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:196:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:209:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(int64_t, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  209 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e4m3fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:209:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:535\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:115:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(const c10::Half&, const c10::Half&)\u001b[m\u001b[K\n",
            "  115 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Half& a, const Half& b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:115:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:163:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Half, float)\u001b[m\u001b[K\n",
            "  163 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:163:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:177:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Half)\u001b[m\u001b[K\n",
            "  177 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Half b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:177:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:206:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Half, double)\u001b[m\u001b[K\n",
            "  206 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:206:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:220:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Half)\u001b[m\u001b[K\n",
            "  220 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Half b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:220:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:236:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(c10::Half, int)\u001b[m\u001b[K\n",
            "  236 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, int b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:236:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:249:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(int, c10::Half)\u001b[m\u001b[K\n",
            "  249 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Half b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:249:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:264:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(c10::Half, int64_t)\u001b[m\u001b[K\n",
            "  264 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, int64_t b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:264:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:277:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(int64_t, c10::Half)\u001b[m\u001b[K\n",
            "  277 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Half b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:277:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:148\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:52:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(const c10::Float8_e5m2&, const c10::Float8_e5m2&)\u001b[m\u001b[K\n",
            "   52 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e5m2& a, const Float8_e5m2& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:52:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:102:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e5m2, float)\u001b[m\u001b[K\n",
            "  102 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:102:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:116:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  116 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e5m2 b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:116:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:145:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e5m2, double)\u001b[m\u001b[K\n",
            "  145 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:145:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:159:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  159 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e5m2 b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:159:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:175:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(c10::Float8_e5m2, int)\u001b[m\u001b[K\n",
            "  175 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, int b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:175:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:188:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(int, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  188 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e5m2 b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:188:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:203:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(c10::Float8_e5m2, int64_t)\u001b[m\u001b[K\n",
            "  203 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, int64_t b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:203:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:216:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(int64_t, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  216 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e5m2 b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:216:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz.h:138\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:49:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(const c10::Float8_e5m2fnuz&, const c10::Float8_e5m2fnuz&)\u001b[m\u001b[K\n",
            "   49 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e5m2fnuz& a, const Float8_e5m2fnuz& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:49:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:99:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e5m2fnuz, float)\u001b[m\u001b[K\n",
            "   99 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:99:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:113:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  113 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e5m2fnuz b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:113:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:142:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e5m2fnuz, double)\u001b[m\u001b[K\n",
            "  142 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:142:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:156:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  156 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e5m2fnuz b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:156:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:172:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(c10::Float8_e5m2fnuz, int)\u001b[m\u001b[K\n",
            "  172 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, int b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:172:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:185:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(int, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  185 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e5m2fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:185:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:200:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(c10::Float8_e5m2fnuz, int64_t)\u001b[m\u001b[K\n",
            "  200 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, int64_t b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:200:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:213:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(int64_t, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  213 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e5m2fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:213:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, int64_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(int64_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, int32_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(int32_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, uint64_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(uint64_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, uint32_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(uint32_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(const c10::SymInt&, double)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(double, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(const c10::SymInt&, float)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(float, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue.h:1581\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List_inl.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List.h:488\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef_inl.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef.h:631\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/WrapDimUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorNames.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/NamedTensorUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:112:35:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno match for \u001b[01m\u001b[Koperator*\u001b[m\u001b[K (operand type is \u001b[01m\u001b[Kconst TypePtr\u001b[m\u001b[K {aka \u001b[01m\u001b[Kconst c10::Type::SingletonOrSharedTypePtr<c10::Type>\u001b[m\u001b[K})\n",
            "  112 |       return *getElementType() == \u001b[01;31m\u001b[K*rhs_->getElementType()\u001b[m\u001b[K;\n",
            "      |                                   \u001b[01;31m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:397:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Ktemplate<class T> constexpr c10::complex<U> c10::operator*(const c10::complex<U>&, const c10::complex<U>&)\u001b[m\u001b[K\n",
            "  397 | constexpr complex<T> \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const complex<T>& lhs, const complex<T>& rhs) {\n",
            "      |                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:397:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  template argument deduction/substitution failed:\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue.h:1581\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List_inl.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List.h:488\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef_inl.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef.h:631\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/WrapDimUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorNames.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/NamedTensorUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:112:35:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  \u001b[01m\u001b[Kconst TypePtr\u001b[m\u001b[K {aka \u001b[01m\u001b[Kconst c10::Type::SingletonOrSharedTypePtr<c10::Type>\u001b[m\u001b[K} is not derived from \u001b[01m\u001b[Kconst c10::complex<U>\u001b[m\u001b[K\n",
            "  112 |       return *getElementType() == \u001b[01;36m\u001b[K*rhs_->getElementType()\u001b[m\u001b[K;\n",
            "      |                                   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:403:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Ktemplate<class T> constexpr c10::complex<U> c10::operator*(const c10::complex<U>&, const T&)\u001b[m\u001b[K\n",
            "  403 | constexpr complex<T> \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const complex<T>& lhs, const T& rhs) {\n",
            "      |                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:403:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  template argument deduction/substitution failed:\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue.h:1581\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List_inl.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List.h:488\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef_inl.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef.h:631\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/WrapDimUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorNames.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/NamedTensorUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:112:35:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  \u001b[01m\u001b[Kconst TypePtr\u001b[m\u001b[K {aka \u001b[01m\u001b[Kconst c10::Type::SingletonOrSharedTypePtr<c10::Type>\u001b[m\u001b[K} is not derived from \u001b[01m\u001b[Kconst c10::complex<U>\u001b[m\u001b[K\n",
            "  112 |       return *getElementType() == \u001b[01;36m\u001b[K*rhs_->getElementType()\u001b[m\u001b[K;\n",
            "      |                                   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:409:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Ktemplate<class T> constexpr c10::complex<U> c10::operator*(const T&, const c10::complex<U>&)\u001b[m\u001b[K\n",
            "  409 | constexpr complex<T> \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const T& lhs, const complex<T>& rhs) {\n",
            "      |                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:409:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  template argument deduction/substitution failed:\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue.h:1581\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List_inl.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List.h:488\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef_inl.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef.h:631\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/WrapDimUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorNames.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/NamedTensorUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:112:35:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  112 |       return *getElementType() == \u001b[01;36m\u001b[K*rhs_->getElementType()\u001b[m\u001b[K;\n",
            "      |                                   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16.h:133\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:114:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(const c10::BFloat16&, const c10::BFloat16&)\u001b[m\u001b[K\n",
            "  114 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const BFloat16& a, const BFloat16& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:114:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:170:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::BFloat16, float)\u001b[m\u001b[K\n",
            "  170 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(BFloat16 a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:170:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:183:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::BFloat16)\u001b[m\u001b[K\n",
            "  183 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, BFloat16 b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:183:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:211:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::BFloat16, double)\u001b[m\u001b[K\n",
            "  211 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(BFloat16 a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:211:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:224:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::BFloat16)\u001b[m\u001b[K\n",
            "  224 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, BFloat16 b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:224:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:239:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(c10::BFloat16, int)\u001b[m\u001b[K\n",
            "  239 | inline C10_HOST_DEVICE BFloat16 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(BFloat16 a, int b) {\n",
            "      |                                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:239:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:252:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(int, c10::BFloat16)\u001b[m\u001b[K\n",
            "  252 | inline C10_HOST_DEVICE BFloat16 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, BFloat16 b) {\n",
            "      |                                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:252:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:267:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(c10::BFloat16, int64_t)\u001b[m\u001b[K\n",
            "  267 | inline C10_HOST_DEVICE BFloat16 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(BFloat16 a, int64_t b) {\n",
            "      |                                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:267:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:280:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(int64_t, c10::BFloat16)\u001b[m\u001b[K\n",
            "  280 | inline C10_HOST_DEVICE BFloat16 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, BFloat16 b) {\n",
            "      |                                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:280:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn.h:240\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:44:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(const c10::Float8_e4m3fn&, const c10::Float8_e4m3fn&)\u001b[m\u001b[K\n",
            "   44 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e4m3fn& a, const Float8_e4m3fn& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:44:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:94:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e4m3fn, float)\u001b[m\u001b[K\n",
            "   94 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fn a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:94:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:108:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e4m3fn)\u001b[m\u001b[K\n",
            "  108 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e4m3fn b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:108:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:137:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e4m3fn, double)\u001b[m\u001b[K\n",
            "  137 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fn a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:137:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:151:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e4m3fn)\u001b[m\u001b[K\n",
            "  151 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e4m3fn b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:151:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:167:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(c10::Float8_e4m3fn, int)\u001b[m\u001b[K\n",
            "  167 | inline C10_HOST_DEVICE Float8_e4m3fn \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fn a, int b) {\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:167:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:180:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(int, c10::Float8_e4m3fn)\u001b[m\u001b[K\n",
            "  180 | inline C10_HOST_DEVICE Float8_e4m3fn \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e4m3fn b) {\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:180:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:195:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(c10::Float8_e4m3fn, int64_t)\u001b[m\u001b[K\n",
            "  195 | inline C10_HOST_DEVICE Float8_e4m3fn \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fn a, int64_t b) {\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:195:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:208:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(int64_t, c10::Float8_e4m3fn)\u001b[m\u001b[K\n",
            "  208 | inline C10_HOST_DEVICE Float8_e4m3fn \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e4m3fn b) {\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:208:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz.h:139\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:45:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(const c10::Float8_e4m3fnuz&, const c10::Float8_e4m3fnuz&)\u001b[m\u001b[K\n",
            "   45 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e4m3fnuz& a, const Float8_e4m3fnuz& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:45:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:95:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e4m3fnuz, float)\u001b[m\u001b[K\n",
            "   95 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fnuz a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:95:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:109:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  109 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e4m3fnuz b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:109:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:138:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e4m3fnuz, double)\u001b[m\u001b[K\n",
            "  138 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fnuz a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:138:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:152:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  152 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e4m3fnuz b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:152:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:168:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(c10::Float8_e4m3fnuz, int)\u001b[m\u001b[K\n",
            "  168 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fnuz a, int b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:168:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:181:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(int, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  181 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e4m3fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:181:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:196:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(c10::Float8_e4m3fnuz, int64_t)\u001b[m\u001b[K\n",
            "  196 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fnuz a, int64_t b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:196:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:209:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(int64_t, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  209 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e4m3fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:209:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:535\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:115:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(const c10::Half&, const c10::Half&)\u001b[m\u001b[K\n",
            "  115 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Half& a, const Half& b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:115:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:163:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Half, float)\u001b[m\u001b[K\n",
            "  163 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:163:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:177:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Half)\u001b[m\u001b[K\n",
            "  177 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Half b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:177:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:206:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Half, double)\u001b[m\u001b[K\n",
            "  206 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:206:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:220:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Half)\u001b[m\u001b[K\n",
            "  220 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Half b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:220:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:236:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(c10::Half, int)\u001b[m\u001b[K\n",
            "  236 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, int b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:236:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:249:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(int, c10::Half)\u001b[m\u001b[K\n",
            "  249 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Half b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:249:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:264:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(c10::Half, int64_t)\u001b[m\u001b[K\n",
            "  264 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, int64_t b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:264:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:277:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(int64_t, c10::Half)\u001b[m\u001b[K\n",
            "  277 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Half b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:277:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:148\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:52:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(const c10::Float8_e5m2&, const c10::Float8_e5m2&)\u001b[m\u001b[K\n",
            "   52 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e5m2& a, const Float8_e5m2& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:52:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:102:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e5m2, float)\u001b[m\u001b[K\n",
            "  102 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:102:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:116:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  116 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e5m2 b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:116:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:145:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e5m2, double)\u001b[m\u001b[K\n",
            "  145 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:145:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:159:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  159 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e5m2 b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:159:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:175:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(c10::Float8_e5m2, int)\u001b[m\u001b[K\n",
            "  175 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, int b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:175:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:188:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(int, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  188 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e5m2 b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:188:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:203:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(c10::Float8_e5m2, int64_t)\u001b[m\u001b[K\n",
            "  203 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, int64_t b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:203:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:216:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(int64_t, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  216 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e5m2 b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:216:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz.h:138\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:49:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(const c10::Float8_e5m2fnuz&, const c10::Float8_e5m2fnuz&)\u001b[m\u001b[K\n",
            "   49 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e5m2fnuz& a, const Float8_e5m2fnuz& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:49:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:99:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e5m2fnuz, float)\u001b[m\u001b[K\n",
            "   99 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:99:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:113:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  113 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e5m2fnuz b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:113:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:142:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e5m2fnuz, double)\u001b[m\u001b[K\n",
            "  142 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:142:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:156:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  156 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e5m2fnuz b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:156:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:172:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(c10::Float8_e5m2fnuz, int)\u001b[m\u001b[K\n",
            "  172 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, int b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:172:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:185:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(int, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  185 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e5m2fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:185:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:200:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(c10::Float8_e5m2fnuz, int64_t)\u001b[m\u001b[K\n",
            "  200 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, int64_t b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:200:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:213:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(int64_t, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  213 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e5m2fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:213:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, int64_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(int64_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, int32_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(int32_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, uint64_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(uint64_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, uint32_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(uint32_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(const c10::SymInt&, double)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(double, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(const c10::SymInt&, float)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(float, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue.h:1581\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List_inl.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List.h:488\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef_inl.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef.h:631\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/WrapDimUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorNames.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/NamedTensorUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h: In instantiation of \u001b[01m\u001b[Kbool c10::SingleElementType<K, T>::equals(const c10::Type&) const [with c10::TypeKind K = c10::TypeKind::ListType; T = c10::ListType]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:110:8:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:112:14:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno match for \u001b[01m\u001b[Koperator*\u001b[m\u001b[K (operand type is \u001b[01m\u001b[Kconst TypePtr\u001b[m\u001b[K {aka \u001b[01m\u001b[Kconst c10::Type::SingletonOrSharedTypePtr<c10::Type>\u001b[m\u001b[K})\n",
            "  112 |       return \u001b[01;31m\u001b[K*getElementType()\u001b[m\u001b[K == *rhs_->getElementType();\n",
            "      |              \u001b[01;31m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:397:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Ktemplate<class T> constexpr c10::complex<U> c10::operator*(const c10::complex<U>&, const c10::complex<U>&)\u001b[m\u001b[K\n",
            "  397 | constexpr complex<T> \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const complex<T>& lhs, const complex<T>& rhs) {\n",
            "      |                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:397:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  template argument deduction/substitution failed:\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue.h:1581\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List_inl.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List.h:488\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef_inl.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef.h:631\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/WrapDimUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorNames.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/NamedTensorUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:112:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  \u001b[01m\u001b[Kconst TypePtr\u001b[m\u001b[K {aka \u001b[01m\u001b[Kconst c10::Type::SingletonOrSharedTypePtr<c10::Type>\u001b[m\u001b[K} is not derived from \u001b[01m\u001b[Kconst c10::complex<U>\u001b[m\u001b[K\n",
            "  112 |       return \u001b[01;36m\u001b[K*getElementType()\u001b[m\u001b[K == *rhs_->getElementType();\n",
            "      |              \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:403:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Ktemplate<class T> constexpr c10::complex<U> c10::operator*(const c10::complex<U>&, const T&)\u001b[m\u001b[K\n",
            "  403 | constexpr complex<T> \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const complex<T>& lhs, const T& rhs) {\n",
            "      |                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:403:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  template argument deduction/substitution failed:\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue.h:1581\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List_inl.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List.h:488\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef_inl.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef.h:631\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/WrapDimUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorNames.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/NamedTensorUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:112:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  \u001b[01m\u001b[Kconst TypePtr\u001b[m\u001b[K {aka \u001b[01m\u001b[Kconst c10::Type::SingletonOrSharedTypePtr<c10::Type>\u001b[m\u001b[K} is not derived from \u001b[01m\u001b[Kconst c10::complex<U>\u001b[m\u001b[K\n",
            "  112 |       return \u001b[01;36m\u001b[K*getElementType()\u001b[m\u001b[K == *rhs_->getElementType();\n",
            "      |              \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:409:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Ktemplate<class T> constexpr c10::complex<U> c10::operator*(const T&, const c10::complex<U>&)\u001b[m\u001b[K\n",
            "  409 | constexpr complex<T> \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const T& lhs, const complex<T>& rhs) {\n",
            "      |                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:409:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  template argument deduction/substitution failed:\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue.h:1581\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List_inl.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List.h:488\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef_inl.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef.h:631\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/WrapDimUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorNames.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/NamedTensorUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:112:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  112 |       return \u001b[01;36m\u001b[K*getElementType()\u001b[m\u001b[K == *rhs_->getElementType();\n",
            "      |              \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16.h:133\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:114:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(const c10::BFloat16&, const c10::BFloat16&)\u001b[m\u001b[K\n",
            "  114 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const BFloat16& a, const BFloat16& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:114:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:170:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::BFloat16, float)\u001b[m\u001b[K\n",
            "  170 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(BFloat16 a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:170:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:183:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::BFloat16)\u001b[m\u001b[K\n",
            "  183 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, BFloat16 b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:183:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:211:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::BFloat16, double)\u001b[m\u001b[K\n",
            "  211 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(BFloat16 a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:211:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:224:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::BFloat16)\u001b[m\u001b[K\n",
            "  224 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, BFloat16 b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:224:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:239:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(c10::BFloat16, int)\u001b[m\u001b[K\n",
            "  239 | inline C10_HOST_DEVICE BFloat16 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(BFloat16 a, int b) {\n",
            "      |                                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:239:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:252:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(int, c10::BFloat16)\u001b[m\u001b[K\n",
            "  252 | inline C10_HOST_DEVICE BFloat16 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, BFloat16 b) {\n",
            "      |                                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:252:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:267:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(c10::BFloat16, int64_t)\u001b[m\u001b[K\n",
            "  267 | inline C10_HOST_DEVICE BFloat16 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(BFloat16 a, int64_t b) {\n",
            "      |                                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:267:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:280:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(int64_t, c10::BFloat16)\u001b[m\u001b[K\n",
            "  280 | inline C10_HOST_DEVICE BFloat16 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, BFloat16 b) {\n",
            "      |                                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:280:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn.h:240\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:44:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(const c10::Float8_e4m3fn&, const c10::Float8_e4m3fn&)\u001b[m\u001b[K\n",
            "   44 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e4m3fn& a, const Float8_e4m3fn& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:44:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:94:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e4m3fn, float)\u001b[m\u001b[K\n",
            "   94 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fn a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:94:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:108:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e4m3fn)\u001b[m\u001b[K\n",
            "  108 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e4m3fn b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:108:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:137:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e4m3fn, double)\u001b[m\u001b[K\n",
            "  137 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fn a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:137:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:151:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e4m3fn)\u001b[m\u001b[K\n",
            "  151 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e4m3fn b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:151:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:167:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(c10::Float8_e4m3fn, int)\u001b[m\u001b[K\n",
            "  167 | inline C10_HOST_DEVICE Float8_e4m3fn \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fn a, int b) {\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:167:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:180:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(int, c10::Float8_e4m3fn)\u001b[m\u001b[K\n",
            "  180 | inline C10_HOST_DEVICE Float8_e4m3fn \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e4m3fn b) {\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:180:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:195:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(c10::Float8_e4m3fn, int64_t)\u001b[m\u001b[K\n",
            "  195 | inline C10_HOST_DEVICE Float8_e4m3fn \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fn a, int64_t b) {\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:195:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:208:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(int64_t, c10::Float8_e4m3fn)\u001b[m\u001b[K\n",
            "  208 | inline C10_HOST_DEVICE Float8_e4m3fn \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e4m3fn b) {\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:208:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz.h:139\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:45:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(const c10::Float8_e4m3fnuz&, const c10::Float8_e4m3fnuz&)\u001b[m\u001b[K\n",
            "   45 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e4m3fnuz& a, const Float8_e4m3fnuz& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:45:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:95:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e4m3fnuz, float)\u001b[m\u001b[K\n",
            "   95 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fnuz a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:95:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:109:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  109 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e4m3fnuz b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:109:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:138:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e4m3fnuz, double)\u001b[m\u001b[K\n",
            "  138 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fnuz a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:138:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:152:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  152 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e4m3fnuz b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:152:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:168:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(c10::Float8_e4m3fnuz, int)\u001b[m\u001b[K\n",
            "  168 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fnuz a, int b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:168:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:181:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(int, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  181 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e4m3fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:181:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:196:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(c10::Float8_e4m3fnuz, int64_t)\u001b[m\u001b[K\n",
            "  196 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fnuz a, int64_t b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:196:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:209:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(int64_t, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  209 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e4m3fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:209:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:535\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:115:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(const c10::Half&, const c10::Half&)\u001b[m\u001b[K\n",
            "  115 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Half& a, const Half& b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:115:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:163:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Half, float)\u001b[m\u001b[K\n",
            "  163 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:163:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:177:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Half)\u001b[m\u001b[K\n",
            "  177 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Half b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:177:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:206:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Half, double)\u001b[m\u001b[K\n",
            "  206 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:206:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:220:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Half)\u001b[m\u001b[K\n",
            "  220 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Half b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:220:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:236:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(c10::Half, int)\u001b[m\u001b[K\n",
            "  236 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, int b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:236:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:249:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(int, c10::Half)\u001b[m\u001b[K\n",
            "  249 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Half b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:249:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:264:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(c10::Half, int64_t)\u001b[m\u001b[K\n",
            "  264 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, int64_t b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:264:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:277:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(int64_t, c10::Half)\u001b[m\u001b[K\n",
            "  277 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Half b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:277:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:148\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:52:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(const c10::Float8_e5m2&, const c10::Float8_e5m2&)\u001b[m\u001b[K\n",
            "   52 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e5m2& a, const Float8_e5m2& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:52:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:102:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e5m2, float)\u001b[m\u001b[K\n",
            "  102 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:102:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:116:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  116 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e5m2 b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:116:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:145:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e5m2, double)\u001b[m\u001b[K\n",
            "  145 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:145:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:159:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  159 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e5m2 b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:159:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:175:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(c10::Float8_e5m2, int)\u001b[m\u001b[K\n",
            "  175 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, int b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:175:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:188:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(int, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  188 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e5m2 b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:188:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:203:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(c10::Float8_e5m2, int64_t)\u001b[m\u001b[K\n",
            "  203 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, int64_t b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:203:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:216:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(int64_t, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  216 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e5m2 b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:216:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz.h:138\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:49:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(const c10::Float8_e5m2fnuz&, const c10::Float8_e5m2fnuz&)\u001b[m\u001b[K\n",
            "   49 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e5m2fnuz& a, const Float8_e5m2fnuz& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:49:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:99:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e5m2fnuz, float)\u001b[m\u001b[K\n",
            "   99 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:99:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:113:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  113 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e5m2fnuz b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:113:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:142:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e5m2fnuz, double)\u001b[m\u001b[K\n",
            "  142 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:142:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:156:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  156 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e5m2fnuz b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:156:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:172:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(c10::Float8_e5m2fnuz, int)\u001b[m\u001b[K\n",
            "  172 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, int b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:172:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:185:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(int, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  185 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e5m2fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:185:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:200:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(c10::Float8_e5m2fnuz, int64_t)\u001b[m\u001b[K\n",
            "  200 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, int64_t b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:200:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:213:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(int64_t, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  213 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e5m2fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:213:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, int64_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(int64_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, int32_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(int32_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, uint64_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(uint64_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, uint32_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(uint32_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(const c10::SymInt&, double)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(double, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(const c10::SymInt&, float)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(float, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue.h:1581\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List_inl.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List.h:488\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef_inl.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef.h:631\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/WrapDimUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorNames.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/NamedTensorUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:112:35:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno match for \u001b[01m\u001b[Koperator*\u001b[m\u001b[K (operand type is \u001b[01m\u001b[Kconst TypePtr\u001b[m\u001b[K {aka \u001b[01m\u001b[Kconst c10::Type::SingletonOrSharedTypePtr<c10::Type>\u001b[m\u001b[K})\n",
            "  112 |       return *getElementType() == \u001b[01;31m\u001b[K*rhs_->getElementType()\u001b[m\u001b[K;\n",
            "      |                                   \u001b[01;31m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:397:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Ktemplate<class T> constexpr c10::complex<U> c10::operator*(const c10::complex<U>&, const c10::complex<U>&)\u001b[m\u001b[K\n",
            "  397 | constexpr complex<T> \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const complex<T>& lhs, const complex<T>& rhs) {\n",
            "      |                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:397:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  template argument deduction/substitution failed:\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue.h:1581\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List_inl.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List.h:488\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef_inl.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef.h:631\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/WrapDimUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorNames.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/NamedTensorUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:112:35:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  \u001b[01m\u001b[Kconst TypePtr\u001b[m\u001b[K {aka \u001b[01m\u001b[Kconst c10::Type::SingletonOrSharedTypePtr<c10::Type>\u001b[m\u001b[K} is not derived from \u001b[01m\u001b[Kconst c10::complex<U>\u001b[m\u001b[K\n",
            "  112 |       return *getElementType() == \u001b[01;36m\u001b[K*rhs_->getElementType()\u001b[m\u001b[K;\n",
            "      |                                   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:403:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Ktemplate<class T> constexpr c10::complex<U> c10::operator*(const c10::complex<U>&, const T&)\u001b[m\u001b[K\n",
            "  403 | constexpr complex<T> \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const complex<T>& lhs, const T& rhs) {\n",
            "      |                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:403:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  template argument deduction/substitution failed:\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue.h:1581\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List_inl.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List.h:488\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef_inl.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef.h:631\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/WrapDimUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorNames.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/NamedTensorUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:112:35:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  \u001b[01m\u001b[Kconst TypePtr\u001b[m\u001b[K {aka \u001b[01m\u001b[Kconst c10::Type::SingletonOrSharedTypePtr<c10::Type>\u001b[m\u001b[K} is not derived from \u001b[01m\u001b[Kconst c10::complex<U>\u001b[m\u001b[K\n",
            "  112 |       return *getElementType() == \u001b[01;36m\u001b[K*rhs_->getElementType()\u001b[m\u001b[K;\n",
            "      |                                   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:409:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Ktemplate<class T> constexpr c10::complex<U> c10::operator*(const T&, const c10::complex<U>&)\u001b[m\u001b[K\n",
            "  409 | constexpr complex<T> \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const T& lhs, const complex<T>& rhs) {\n",
            "      |                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:409:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  template argument deduction/substitution failed:\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue.h:1581\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List_inl.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/List.h:488\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef_inl.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/IListRef.h:631\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/WrapDimUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorNames.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/NamedTensorUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/jit_type.h:112:35:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  112 |       return *getElementType() == \u001b[01;36m\u001b[K*rhs_->getElementType()\u001b[m\u001b[K;\n",
            "      |                                   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16.h:133\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:114:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(const c10::BFloat16&, const c10::BFloat16&)\u001b[m\u001b[K\n",
            "  114 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const BFloat16& a, const BFloat16& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:114:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:170:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::BFloat16, float)\u001b[m\u001b[K\n",
            "  170 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(BFloat16 a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:170:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:183:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::BFloat16)\u001b[m\u001b[K\n",
            "  183 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, BFloat16 b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:183:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:211:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::BFloat16, double)\u001b[m\u001b[K\n",
            "  211 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(BFloat16 a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:211:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:224:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::BFloat16)\u001b[m\u001b[K\n",
            "  224 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, BFloat16 b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:224:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:239:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(c10::BFloat16, int)\u001b[m\u001b[K\n",
            "  239 | inline C10_HOST_DEVICE BFloat16 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(BFloat16 a, int b) {\n",
            "      |                                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:239:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:252:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(int, c10::BFloat16)\u001b[m\u001b[K\n",
            "  252 | inline C10_HOST_DEVICE BFloat16 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, BFloat16 b) {\n",
            "      |                                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:252:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:267:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(c10::BFloat16, int64_t)\u001b[m\u001b[K\n",
            "  267 | inline C10_HOST_DEVICE BFloat16 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(BFloat16 a, int64_t b) {\n",
            "      |                                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:267:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:280:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::BFloat16 c10::operator*(int64_t, c10::BFloat16)\u001b[m\u001b[K\n",
            "  280 | inline C10_HOST_DEVICE BFloat16 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, BFloat16 b) {\n",
            "      |                                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/BFloat16-inl.h:280:33:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn.h:240\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:44:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(const c10::Float8_e4m3fn&, const c10::Float8_e4m3fn&)\u001b[m\u001b[K\n",
            "   44 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e4m3fn& a, const Float8_e4m3fn& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:44:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:94:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e4m3fn, float)\u001b[m\u001b[K\n",
            "   94 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fn a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:94:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:108:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e4m3fn)\u001b[m\u001b[K\n",
            "  108 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e4m3fn b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:108:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:137:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e4m3fn, double)\u001b[m\u001b[K\n",
            "  137 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fn a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:137:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:151:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e4m3fn)\u001b[m\u001b[K\n",
            "  151 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e4m3fn b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:151:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:167:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(c10::Float8_e4m3fn, int)\u001b[m\u001b[K\n",
            "  167 | inline C10_HOST_DEVICE Float8_e4m3fn \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fn a, int b) {\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:167:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:180:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(int, c10::Float8_e4m3fn)\u001b[m\u001b[K\n",
            "  180 | inline C10_HOST_DEVICE Float8_e4m3fn \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e4m3fn b) {\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:180:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:195:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(c10::Float8_e4m3fn, int64_t)\u001b[m\u001b[K\n",
            "  195 | inline C10_HOST_DEVICE Float8_e4m3fn \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fn a, int64_t b) {\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:195:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:208:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fn c10::operator*(int64_t, c10::Float8_e4m3fn)\u001b[m\u001b[K\n",
            "  208 | inline C10_HOST_DEVICE Float8_e4m3fn \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e4m3fn b) {\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fn-inl.h:208:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz.h:139\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:45:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(const c10::Float8_e4m3fnuz&, const c10::Float8_e4m3fnuz&)\u001b[m\u001b[K\n",
            "   45 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e4m3fnuz& a, const Float8_e4m3fnuz& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:45:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:95:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e4m3fnuz, float)\u001b[m\u001b[K\n",
            "   95 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fnuz a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:95:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:109:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  109 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e4m3fnuz b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:109:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:138:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e4m3fnuz, double)\u001b[m\u001b[K\n",
            "  138 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fnuz a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:138:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:152:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  152 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e4m3fnuz b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:152:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:168:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(c10::Float8_e4m3fnuz, int)\u001b[m\u001b[K\n",
            "  168 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fnuz a, int b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:168:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:181:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(int, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  181 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e4m3fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:181:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:196:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(c10::Float8_e4m3fnuz, int64_t)\u001b[m\u001b[K\n",
            "  196 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e4m3fnuz a, int64_t b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:196:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:209:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e4m3fnuz c10::operator*(int64_t, c10::Float8_e4m3fnuz)\u001b[m\u001b[K\n",
            "  209 | inline C10_HOST_DEVICE Float8_e4m3fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e4m3fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e4m3fnuz-inl.h:209:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:535\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:115:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(const c10::Half&, const c10::Half&)\u001b[m\u001b[K\n",
            "  115 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Half& a, const Half& b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:115:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:163:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Half, float)\u001b[m\u001b[K\n",
            "  163 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:163:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:177:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Half)\u001b[m\u001b[K\n",
            "  177 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Half b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:177:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:206:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Half, double)\u001b[m\u001b[K\n",
            "  206 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:206:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:220:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Half)\u001b[m\u001b[K\n",
            "  220 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Half b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:220:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:236:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(c10::Half, int)\u001b[m\u001b[K\n",
            "  236 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, int b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:236:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:249:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(int, c10::Half)\u001b[m\u001b[K\n",
            "  249 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Half b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:249:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:264:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(c10::Half, int64_t)\u001b[m\u001b[K\n",
            "  264 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Half a, int64_t b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:264:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:277:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Half c10::operator*(int64_t, c10::Half)\u001b[m\u001b[K\n",
            "  277 | inline C10_HOST_DEVICE Half \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Half b) {\n",
            "      |                             \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half-inl.h:277:29:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:148\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:52:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(const c10::Float8_e5m2&, const c10::Float8_e5m2&)\u001b[m\u001b[K\n",
            "   52 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e5m2& a, const Float8_e5m2& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:52:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:102:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e5m2, float)\u001b[m\u001b[K\n",
            "  102 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:102:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:116:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  116 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e5m2 b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:116:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:145:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e5m2, double)\u001b[m\u001b[K\n",
            "  145 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:145:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:159:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  159 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e5m2 b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:159:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:175:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(c10::Float8_e5m2, int)\u001b[m\u001b[K\n",
            "  175 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, int b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:175:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:188:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(int, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  188 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e5m2 b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:188:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:203:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(c10::Float8_e5m2, int64_t)\u001b[m\u001b[K\n",
            "  203 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2 a, int64_t b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:203:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:216:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2 c10::operator*(int64_t, c10::Float8_e5m2)\u001b[m\u001b[K\n",
            "  216 | inline C10_HOST_DEVICE Float8_e5m2 \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e5m2 b) {\n",
            "      |                                    \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2-inl.h:216:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz.h:138\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:49:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(const c10::Float8_e5m2fnuz&, const c10::Float8_e5m2fnuz&)\u001b[m\u001b[K\n",
            "   49 | \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const Float8_e5m2fnuz& a, const Float8_e5m2fnuz& b) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:49:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:99:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(c10::Float8_e5m2fnuz, float)\u001b[m\u001b[K\n",
            "   99 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, float b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:99:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:113:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kfloat c10::operator*(float, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  113 | inline C10_HOST_DEVICE float \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(float a, Float8_e5m2fnuz b) {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:113:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:142:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(c10::Float8_e5m2fnuz, double)\u001b[m\u001b[K\n",
            "  142 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, double b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:142:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:156:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdouble c10::operator*(double, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  156 | inline C10_HOST_DEVICE double \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(double a, Float8_e5m2fnuz b) {\n",
            "      |                               \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:156:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:172:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(c10::Float8_e5m2fnuz, int)\u001b[m\u001b[K\n",
            "  172 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, int b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:172:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:185:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(int, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  185 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int a, Float8_e5m2fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:185:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:200:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(c10::Float8_e5m2fnuz, int64_t)\u001b[m\u001b[K\n",
            "  200 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(Float8_e5m2fnuz a, int64_t b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:200:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:213:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::Float8_e5m2fnuz c10::operator*(int64_t, c10::Float8_e5m2fnuz)\u001b[m\u001b[K\n",
            "  213 | inline C10_HOST_DEVICE Float8_e5m2fnuz \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(int64_t a, Float8_e5m2fnuz b) {\n",
            "      |                                        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2fnuz-inl.h:213:40:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, int64_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(int64_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:350:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  350 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, int32_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(int32_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:351:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  351 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(int32_t, SymInt) // make sure constants work\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, uint64_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(uint64_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:352:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  352 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint64_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(const c10::SymInt&, uint32_t)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymInt c10::operator*(uint32_t, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:353:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  353 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(uint32_t, SymInt)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(const c10::SymInt&, double)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(double, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:354:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  354 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(double, SymFloat)\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(const c10::SymInt&, float)\u001b[m\u001b[K\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:327:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  327 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(const SymInt& a, scalar_t b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kc10::SymFloat c10::operator*(float, const c10::SymInt&)\u001b[m\u001b[K\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:331:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 2 arguments, 1 provided\n",
            "  331 |   C10_API RetTy \u001b[01;36m\u001b[Koperator\u001b[m\u001b[K*(scalar_t a, const SymInt& b); \\\n",
            "      |                 \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/SymInt.h:355:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro \u001b[01m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K\n",
            "  355 | \u001b[01;36m\u001b[KDECLARE_SYMINT_OP\u001b[m\u001b[K(float, SymFloat) // just for completeness\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::GroupNormImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::LocalResponseNormImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::LayerNormImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::UnfoldImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::FoldImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::EmbeddingBagImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::EmbeddingImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::ConvTranspose3dImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h: In instantiation of \u001b[01m\u001b[Kvoid torch::nn::ConvTransposeNdImpl<D, Derived>::pretty_print(std::ostream&) const [with long unsigned int D = 3; Derived = torch::nn::ConvTranspose3dImpl; std::ostream = std::basic_ostream<char>]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:282:8:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:304:67:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<3>::padding_mode() const\u001b[m\u001b[K\n",
            "  304 |     if (!std::get_if<enumtype::kZeros>(&\u001b[01;31m\u001b[Kthis->options.padding_mode()\u001b[m\u001b[K)) {\n",
            "      |                                         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(const int&) [with long unsigned int D = 3; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<3>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(int&&) [with long unsigned int D = 3; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<3>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:306:67:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<3>::padding_mode() const\u001b[m\u001b[K\n",
            "  306 |              << enumtype::get_enum_name(\u001b[01;31m\u001b[Kthis->options.padding_mode()\u001b[m\u001b[K);\n",
            "      |                                         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(const int&) [with long unsigned int D = 3; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<3>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(int&&) [with long unsigned int D = 3; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<3>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h: In instantiation of \u001b[01m\u001b[Kvoid torch::nn::ConvNdImpl<D, Derived>::pretty_print(std::ostream&) const [with long unsigned int D = 3; Derived = torch::nn::ConvTranspose3dImpl; std::ostream = std::basic_ostream<char>]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:117:8:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:144:61:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<3>::padding_mode() const\u001b[m\u001b[K\n",
            "  144 |     if (!std::get_if<enumtype::kZeros>(&\u001b[01;31m\u001b[Koptions.padding_mode()\u001b[m\u001b[K)) {\n",
            "      |                                         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(const int&) [with long unsigned int D = 3; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<3>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(int&&) [with long unsigned int D = 3; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<3>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:146:61:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<3>::padding_mode() const\u001b[m\u001b[K\n",
            "  146 |              << enumtype::get_enum_name(\u001b[01;31m\u001b[Koptions.padding_mode()\u001b[m\u001b[K);\n",
            "      |                                         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(const int&) [with long unsigned int D = 3; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<3>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(int&&) [with long unsigned int D = 3; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<3>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::ConvTranspose2dImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h: In instantiation of \u001b[01m\u001b[Kvoid torch::nn::ConvTransposeNdImpl<D, Derived>::pretty_print(std::ostream&) const [with long unsigned int D = 2; Derived = torch::nn::ConvTranspose2dImpl; std::ostream = std::basic_ostream<char>]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:282:8:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:304:67:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<2>::padding_mode() const\u001b[m\u001b[K\n",
            "  304 |     if (!std::get_if<enumtype::kZeros>(&\u001b[01;31m\u001b[Kthis->options.padding_mode()\u001b[m\u001b[K)) {\n",
            "      |                                         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(const int&) [with long unsigned int D = 2; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<2>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(int&&) [with long unsigned int D = 2; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<2>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:306:67:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<2>::padding_mode() const\u001b[m\u001b[K\n",
            "  306 |              << enumtype::get_enum_name(\u001b[01;31m\u001b[Kthis->options.padding_mode()\u001b[m\u001b[K);\n",
            "      |                                         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(const int&) [with long unsigned int D = 2; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<2>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(int&&) [with long unsigned int D = 2; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<2>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h: In instantiation of \u001b[01m\u001b[Kvoid torch::nn::ConvNdImpl<D, Derived>::pretty_print(std::ostream&) const [with long unsigned int D = 2; Derived = torch::nn::ConvTranspose2dImpl; std::ostream = std::basic_ostream<char>]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:117:8:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:144:61:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<2>::padding_mode() const\u001b[m\u001b[K\n",
            "  144 |     if (!std::get_if<enumtype::kZeros>(&\u001b[01;31m\u001b[Koptions.padding_mode()\u001b[m\u001b[K)) {\n",
            "      |                                         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(const int&) [with long unsigned int D = 2; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<2>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(int&&) [with long unsigned int D = 2; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<2>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:146:61:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<2>::padding_mode() const\u001b[m\u001b[K\n",
            "  146 |              << enumtype::get_enum_name(\u001b[01;31m\u001b[Koptions.padding_mode()\u001b[m\u001b[K);\n",
            "      |                                         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(const int&) [with long unsigned int D = 2; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<2>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(int&&) [with long unsigned int D = 2; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<2>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::ConvTranspose1dImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h: In instantiation of \u001b[01m\u001b[Kvoid torch::nn::ConvTransposeNdImpl<D, Derived>::pretty_print(std::ostream&) const [with long unsigned int D = 1; Derived = torch::nn::ConvTranspose1dImpl; std::ostream = std::basic_ostream<char>]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:282:8:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:304:67:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<1>::padding_mode() const\u001b[m\u001b[K\n",
            "  304 |     if (!std::get_if<enumtype::kZeros>(&\u001b[01;31m\u001b[Kthis->options.padding_mode()\u001b[m\u001b[K)) {\n",
            "      |                                         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(const int&) [with long unsigned int D = 1; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<1>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(int&&) [with long unsigned int D = 1; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<1>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:306:67:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<1>::padding_mode() const\u001b[m\u001b[K\n",
            "  306 |              << enumtype::get_enum_name(\u001b[01;31m\u001b[Kthis->options.padding_mode()\u001b[m\u001b[K);\n",
            "      |                                         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(const int&) [with long unsigned int D = 1; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<1>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(int&&) [with long unsigned int D = 1; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<1>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h: In instantiation of \u001b[01m\u001b[Kvoid torch::nn::ConvNdImpl<D, Derived>::pretty_print(std::ostream&) const [with long unsigned int D = 1; Derived = torch::nn::ConvTranspose1dImpl; std::ostream = std::basic_ostream<char>]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:117:8:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:144:61:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<1>::padding_mode() const\u001b[m\u001b[K\n",
            "  144 |     if (!std::get_if<enumtype::kZeros>(&\u001b[01;31m\u001b[Koptions.padding_mode()\u001b[m\u001b[K)) {\n",
            "      |                                         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(const int&) [with long unsigned int D = 1; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<1>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(int&&) [with long unsigned int D = 1; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<1>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:146:61:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<1>::padding_mode() const\u001b[m\u001b[K\n",
            "  146 |              << enumtype::get_enum_name(\u001b[01;31m\u001b[Koptions.padding_mode()\u001b[m\u001b[K);\n",
            "      |                                         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(const int&) [with long unsigned int D = 1; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<1>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(int&&) [with long unsigned int D = 1; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<1>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::Conv3dImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h: In instantiation of \u001b[01m\u001b[Kvoid torch::nn::ConvNdImpl<D, Derived>::pretty_print(std::ostream&) const [with long unsigned int D = 3; Derived = torch::nn::Conv3dImpl; std::ostream = std::basic_ostream<char>]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:117:8:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:144:61:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<3>::padding_mode() const\u001b[m\u001b[K\n",
            "  144 |     if (!std::get_if<enumtype::kZeros>(&\u001b[01;31m\u001b[Koptions.padding_mode()\u001b[m\u001b[K)) {\n",
            "      |                                         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(const int&) [with long unsigned int D = 3; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<3>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(int&&) [with long unsigned int D = 3; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<3>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:146:61:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<3>::padding_mode() const\u001b[m\u001b[K\n",
            "  146 |              << enumtype::get_enum_name(\u001b[01;31m\u001b[Koptions.padding_mode()\u001b[m\u001b[K);\n",
            "      |                                         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(const int&) [with long unsigned int D = 3; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<3>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(int&&) [with long unsigned int D = 3; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<3>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::Conv2dImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h: In instantiation of \u001b[01m\u001b[Kvoid torch::nn::ConvNdImpl<D, Derived>::pretty_print(std::ostream&) const [with long unsigned int D = 2; Derived = torch::nn::Conv2dImpl; std::ostream = std::basic_ostream<char>]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:117:8:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:144:61:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<2>::padding_mode() const\u001b[m\u001b[K\n",
            "  144 |     if (!std::get_if<enumtype::kZeros>(&\u001b[01;31m\u001b[Koptions.padding_mode()\u001b[m\u001b[K)) {\n",
            "      |                                         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(const int&) [with long unsigned int D = 2; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<2>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(int&&) [with long unsigned int D = 2; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<2>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:146:61:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<2>::padding_mode() const\u001b[m\u001b[K\n",
            "  146 |              << enumtype::get_enum_name(\u001b[01;31m\u001b[Koptions.padding_mode()\u001b[m\u001b[K);\n",
            "      |                                         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(const int&) [with long unsigned int D = 2; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<2>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(int&&) [with long unsigned int D = 2; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<2>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::Conv1dImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h: In instantiation of \u001b[01m\u001b[Kvoid torch::nn::ConvNdImpl<D, Derived>::pretty_print(std::ostream&) const [with long unsigned int D = 1; Derived = torch::nn::Conv1dImpl; std::ostream = std::basic_ostream<char>]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:117:8:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:144:61:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<1>::padding_mode() const\u001b[m\u001b[K\n",
            "  144 |     if (!std::get_if<enumtype::kZeros>(&\u001b[01;31m\u001b[Koptions.padding_mode()\u001b[m\u001b[K)) {\n",
            "      |                                         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(const int&) [with long unsigned int D = 1; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<1>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(int&&) [with long unsigned int D = 1; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<1>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:146:61:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<1>::padding_mode() const\u001b[m\u001b[K\n",
            "  146 |              << enumtype::get_enum_name(\u001b[01;31m\u001b[Koptions.padding_mode()\u001b[m\u001b[K);\n",
            "      |                                         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(const int&) [with long unsigned int D = 1; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<1>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding_mode(int&&) [with long unsigned int D = 1; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<1>&]\u001b[m\u001b[K\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:95:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   95 |   TORCH_ARG(conv_padding_mode_t, \u001b[01;36m\u001b[Kpadding_mode\u001b[m\u001b[K) = torch::kZeros;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::AdaptiveLogSoftmaxWithLossImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::MultiheadAttentionImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::ThresholdImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::LogSoftmaxImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::SoftminImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::SoftmaxImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::BilinearImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::UnflattenImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::LinearImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::TransformerDecoderImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::TransformerEncoderImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::TransformerDecoderLayerImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::TransformerEncoderLayerImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::GRUCellImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::LSTMCellImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::RNNCellImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::GRUImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::LSTMImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::RNNImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::FractionalMaxPool3dImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of \u001b[01m\u001b[Kstd::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(int) const [with Derived = torch::nn::FractionalMaxPool2dImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:35:27:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:78:60:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kinvalid conversion from \u001b[01m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K [\u001b[01;31m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-fpermissive\u0007-fpermissive\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   78 |       copy->children_[child.key()]->clone_(*child.value(), \u001b[01;31m\u001b[Kdevice\u001b[m\u001b[K);\n",
            "      |                                                            \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                            \u001b[01;31m\u001b[Kc10::TensorOptions (*)(c10::Device)\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/module.h:580:38:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 2 of \u001b[01m\u001b[Kvirtual void torch::nn::Module::clone_(torch::nn::Module&, int)\u001b[m\u001b[K\n",
            "  580 |   virtual void clone_(Module& other, \u001b[01;36m\u001b[Kconst std::optional\u001b[m\u001b[K<Device>& device);\n",
            "      |                                      \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h: In instantiation of \u001b[01m\u001b[Kconst torch::ExpandingArray<D>& torch::nn::ConvTransposeNdImpl<D, Derived>::padding() const [with long unsigned int D = 3; Derived = torch::nn::ConvTranspose3dImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:288:23:\u001b[m\u001b[K   required from \u001b[01m\u001b[Kvoid torch::nn::ConvTransposeNdImpl<D, Derived>::pretty_print(std::ostream&) const [with long unsigned int D = 3; Derived = torch::nn::ConvTranspose3dImpl; std::ostream = std::basic_ostream<char>]\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:282:8:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:313:61:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<3>::padding() const\u001b[m\u001b[K\n",
            "  313 |     return std::get<ExpandingArray<D>>(\u001b[01;31m\u001b[Kthis->options.padding()\u001b[m\u001b[K);\n",
            "      |                                        \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:61:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding(const int&) [with long unsigned int D = 3; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<3>&]\u001b[m\u001b[K\n",
            "   61 |   TORCH_ARG(padding_t, \u001b[01;36m\u001b[Kpadding\u001b[m\u001b[K) = 0;\n",
            "      |                        \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:61:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   61 |   TORCH_ARG(padding_t, \u001b[01;36m\u001b[Kpadding\u001b[m\u001b[K) = 0;\n",
            "      |                        \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:61:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding(int&&) [with long unsigned int D = 3; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<3>&]\u001b[m\u001b[K\n",
            "   61 |   TORCH_ARG(padding_t, \u001b[01;36m\u001b[Kpadding\u001b[m\u001b[K) = 0;\n",
            "      |                        \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:61:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   61 |   TORCH_ARG(padding_t, \u001b[01;36m\u001b[Kpadding\u001b[m\u001b[K) = 0;\n",
            "      |                        \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/conv.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:64:18:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype(auto) torch::nn::detail::ConvNdOptions<D>::padding(std::initializer_list<long int>) [with long unsigned int D = 3]\u001b[m\u001b[K\n",
            "   64 |   decltype(auto) \u001b[01;36m\u001b[Kpadding\u001b[m\u001b[K(std::initializer_list<int64_t> il) {\n",
            "      |                  \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:64:18:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h: In instantiation of \u001b[01m\u001b[Kvoid torch::nn::ConvNdImpl<D, Derived>::reset_parameters() [with long unsigned int D = 3; Derived = torch::nn::ConvTranspose3dImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:101:5:\u001b[m\u001b[K   required from \u001b[01m\u001b[Kvoid torch::nn::ConvNdImpl<D, Derived>::reset() [with long unsigned int D = 3; Derived = torch::nn::ConvTranspose3dImpl]\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:33:8:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:105:27:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kcannot convert \u001b[01m\u001b[Kconst torch::enumtype::kFanIn\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K\n",
            "  105 |     \u001b[01;31m\u001b[Kinit::kaiming_uniform_(\u001b[m\u001b[K\n",
            "      |     \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~~~^\u001b[m\u001b[K\n",
            "      |                           \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                           \u001b[01;31m\u001b[Kconst torch::enumtype::kFanIn\u001b[m\u001b[K\n",
            "  106 | \u001b[01;31m\u001b[K        weight,\u001b[m\u001b[K\n",
            "      |         \u001b[01;31m\u001b[K~~~~~~~\u001b[m\u001b[K            \n",
            "  107 | \u001b[01;31m\u001b[K        /*a=*/std::sqrt(5))\u001b[m\u001b[K; // NOLINT(cppcoreguidelines-avoid-magic-numbers)\n",
            "      |         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/init.h:99:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 3 of \u001b[01m\u001b[Kat::Tensor torch::nn::init::kaiming_uniform_(at::Tensor, double, int, int)\u001b[m\u001b[K\n",
            "   99 |     \u001b[01;36m\u001b[KFanModeType mode = torch::kFanIn\u001b[m\u001b[K,\n",
            "      |     \u001b[01;36m\u001b[K~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h: In instantiation of \u001b[01m\u001b[Kconst torch::ExpandingArray<D>& torch::nn::ConvTransposeNdImpl<D, Derived>::padding() const [with long unsigned int D = 2; Derived = torch::nn::ConvTranspose2dImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:288:23:\u001b[m\u001b[K   required from \u001b[01m\u001b[Kvoid torch::nn::ConvTransposeNdImpl<D, Derived>::pretty_print(std::ostream&) const [with long unsigned int D = 2; Derived = torch::nn::ConvTranspose2dImpl; std::ostream = std::basic_ostream<char>]\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:282:8:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:313:61:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<2>::padding() const\u001b[m\u001b[K\n",
            "  313 |     return std::get<ExpandingArray<D>>(\u001b[01;31m\u001b[Kthis->options.padding()\u001b[m\u001b[K);\n",
            "      |                                        \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:61:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding(const int&) [with long unsigned int D = 2; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<2>&]\u001b[m\u001b[K\n",
            "   61 |   TORCH_ARG(padding_t, \u001b[01;36m\u001b[Kpadding\u001b[m\u001b[K) = 0;\n",
            "      |                        \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:61:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   61 |   TORCH_ARG(padding_t, \u001b[01;36m\u001b[Kpadding\u001b[m\u001b[K) = 0;\n",
            "      |                        \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:61:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding(int&&) [with long unsigned int D = 2; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<2>&]\u001b[m\u001b[K\n",
            "   61 |   TORCH_ARG(padding_t, \u001b[01;36m\u001b[Kpadding\u001b[m\u001b[K) = 0;\n",
            "      |                        \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:61:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   61 |   TORCH_ARG(padding_t, \u001b[01;36m\u001b[Kpadding\u001b[m\u001b[K) = 0;\n",
            "      |                        \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/conv.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:64:18:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype(auto) torch::nn::detail::ConvNdOptions<D>::padding(std::initializer_list<long int>) [with long unsigned int D = 2]\u001b[m\u001b[K\n",
            "   64 |   decltype(auto) \u001b[01;36m\u001b[Kpadding\u001b[m\u001b[K(std::initializer_list<int64_t> il) {\n",
            "      |                  \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:64:18:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h: In instantiation of \u001b[01m\u001b[Kvoid torch::nn::ConvNdImpl<D, Derived>::reset_parameters() [with long unsigned int D = 2; Derived = torch::nn::ConvTranspose2dImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:101:5:\u001b[m\u001b[K   required from \u001b[01m\u001b[Kvoid torch::nn::ConvNdImpl<D, Derived>::reset() [with long unsigned int D = 2; Derived = torch::nn::ConvTranspose2dImpl]\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:33:8:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:105:27:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kcannot convert \u001b[01m\u001b[Kconst torch::enumtype::kFanIn\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K\n",
            "  105 |     \u001b[01;31m\u001b[Kinit::kaiming_uniform_(\u001b[m\u001b[K\n",
            "      |     \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~~~^\u001b[m\u001b[K\n",
            "      |                           \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                           \u001b[01;31m\u001b[Kconst torch::enumtype::kFanIn\u001b[m\u001b[K\n",
            "  106 | \u001b[01;31m\u001b[K        weight,\u001b[m\u001b[K\n",
            "      |         \u001b[01;31m\u001b[K~~~~~~~\u001b[m\u001b[K            \n",
            "  107 | \u001b[01;31m\u001b[K        /*a=*/std::sqrt(5))\u001b[m\u001b[K; // NOLINT(cppcoreguidelines-avoid-magic-numbers)\n",
            "      |         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/init.h:99:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 3 of \u001b[01m\u001b[Kat::Tensor torch::nn::init::kaiming_uniform_(at::Tensor, double, int, int)\u001b[m\u001b[K\n",
            "   99 |     \u001b[01;36m\u001b[KFanModeType mode = torch::kFanIn\u001b[m\u001b[K,\n",
            "      |     \u001b[01;36m\u001b[K~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h: In instantiation of \u001b[01m\u001b[Kconst torch::ExpandingArray<D>& torch::nn::ConvTransposeNdImpl<D, Derived>::padding() const [with long unsigned int D = 1; Derived = torch::nn::ConvTranspose1dImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:288:23:\u001b[m\u001b[K   required from \u001b[01m\u001b[Kvoid torch::nn::ConvTransposeNdImpl<D, Derived>::pretty_print(std::ostream&) const [with long unsigned int D = 1; Derived = torch::nn::ConvTranspose1dImpl; std::ostream = std::basic_ostream<char>]\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:282:8:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:313:61:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kno matching function for call to \u001b[01m\u001b[Ktorch::nn::detail::ConvNdOptions<1>::padding() const\u001b[m\u001b[K\n",
            "  313 |     return std::get<ExpandingArray<D>>(\u001b[01;31m\u001b[Kthis->options.padding()\u001b[m\u001b[K);\n",
            "      |                                        \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:61:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding(const int&) [with long unsigned int D = 1; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<1>&]\u001b[m\u001b[K\n",
            "   61 |   TORCH_ARG(padding_t, \u001b[01;36m\u001b[Kpadding\u001b[m\u001b[K) = 0;\n",
            "      |                        \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:61:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   61 |   TORCH_ARG(padding_t, \u001b[01;36m\u001b[Kpadding\u001b[m\u001b[K) = 0;\n",
            "      |                        \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:7:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "    7 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(const T& new_##name) -> decltype(*this) { /* NOLINT */ \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:61:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype (*(torch::nn::detail::ConvNdOptions<D>*)this) torch::nn::detail::ConvNdOptions<D>::padding(int&&) [with long unsigned int D = 1; decltype (*(torch::nn::detail::ConvNdOptions<D>*)this) = torch::nn::detail::ConvNdOptions<1>&]\u001b[m\u001b[K\n",
            "   61 |   TORCH_ARG(padding_t, \u001b[01;36m\u001b[Kpadding\u001b[m\u001b[K) = 0;\n",
            "      |                        \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:61:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "   61 |   TORCH_ARG(padding_t, \u001b[01;36m\u001b[Kpadding\u001b[m\u001b[K) = 0;\n",
            "      |                        \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/arg.h:11:15:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro \u001b[01m\u001b[KTORCH_ARG\u001b[m\u001b[K\n",
            "   11 |   inline auto \u001b[01;36m\u001b[Kname\u001b[m\u001b[K(T&& new_##name) -> decltype(*this) { /* NOLINT */      \\\n",
            "      |               \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/conv.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:64:18:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kcandidate: \u001b[01m\u001b[Kdecltype(auto) torch::nn::detail::ConvNdOptions<D>::padding(std::initializer_list<long int>) [with long unsigned int D = 1]\u001b[m\u001b[K\n",
            "   64 |   decltype(auto) \u001b[01;36m\u001b[Kpadding\u001b[m\u001b[K(std::initializer_list<int64_t> il) {\n",
            "      |                  \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h:64:18:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  candidate expects 1 argument, 0 provided\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h: In instantiation of \u001b[01m\u001b[Kvoid torch::nn::ConvNdImpl<D, Derived>::reset_parameters() [with long unsigned int D = 1; Derived = torch::nn::ConvTranspose1dImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:101:5:\u001b[m\u001b[K   required from \u001b[01m\u001b[Kvoid torch::nn::ConvNdImpl<D, Derived>::reset() [with long unsigned int D = 1; Derived = torch::nn::ConvTranspose1dImpl]\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:33:8:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:105:27:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kcannot convert \u001b[01m\u001b[Kconst torch::enumtype::kFanIn\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K\n",
            "  105 |     \u001b[01;31m\u001b[Kinit::kaiming_uniform_(\u001b[m\u001b[K\n",
            "      |     \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~~~^\u001b[m\u001b[K\n",
            "      |                           \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                           \u001b[01;31m\u001b[Kconst torch::enumtype::kFanIn\u001b[m\u001b[K\n",
            "  106 | \u001b[01;31m\u001b[K        weight,\u001b[m\u001b[K\n",
            "      |         \u001b[01;31m\u001b[K~~~~~~~\u001b[m\u001b[K            \n",
            "  107 | \u001b[01;31m\u001b[K        /*a=*/std::sqrt(5))\u001b[m\u001b[K; // NOLINT(cppcoreguidelines-avoid-magic-numbers)\n",
            "      |         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/init.h:99:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 3 of \u001b[01m\u001b[Kat::Tensor torch::nn::init::kaiming_uniform_(at::Tensor, double, int, int)\u001b[m\u001b[K\n",
            "   99 |     \u001b[01;36m\u001b[KFanModeType mode = torch::kFanIn\u001b[m\u001b[K,\n",
            "      |     \u001b[01;36m\u001b[K~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h: In instantiation of \u001b[01m\u001b[Kvoid torch::nn::ConvNdImpl<D, Derived>::reset_parameters() [with long unsigned int D = 3; Derived = torch::nn::Conv3dImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:101:5:\u001b[m\u001b[K   required from \u001b[01m\u001b[Kvoid torch::nn::ConvNdImpl<D, Derived>::reset() [with long unsigned int D = 3; Derived = torch::nn::Conv3dImpl]\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:33:8:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:105:27:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kcannot convert \u001b[01m\u001b[Kconst torch::enumtype::kFanIn\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K\n",
            "  105 |     \u001b[01;31m\u001b[Kinit::kaiming_uniform_(\u001b[m\u001b[K\n",
            "      |     \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~~~^\u001b[m\u001b[K\n",
            "      |                           \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                           \u001b[01;31m\u001b[Kconst torch::enumtype::kFanIn\u001b[m\u001b[K\n",
            "  106 | \u001b[01;31m\u001b[K        weight,\u001b[m\u001b[K\n",
            "      |         \u001b[01;31m\u001b[K~~~~~~~\u001b[m\u001b[K            \n",
            "  107 | \u001b[01;31m\u001b[K        /*a=*/std::sqrt(5))\u001b[m\u001b[K; // NOLINT(cppcoreguidelines-avoid-magic-numbers)\n",
            "      |         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/init.h:99:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 3 of \u001b[01m\u001b[Kat::Tensor torch::nn::init::kaiming_uniform_(at::Tensor, double, int, int)\u001b[m\u001b[K\n",
            "   99 |     \u001b[01;36m\u001b[KFanModeType mode = torch::kFanIn\u001b[m\u001b[K,\n",
            "      |     \u001b[01;36m\u001b[K~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h: In instantiation of \u001b[01m\u001b[Kvoid torch::nn::ConvNdImpl<D, Derived>::reset_parameters() [with long unsigned int D = 2; Derived = torch::nn::Conv2dImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:101:5:\u001b[m\u001b[K   required from \u001b[01m\u001b[Kvoid torch::nn::ConvNdImpl<D, Derived>::reset() [with long unsigned int D = 2; Derived = torch::nn::Conv2dImpl]\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:33:8:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:105:27:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kcannot convert \u001b[01m\u001b[Kconst torch::enumtype::kFanIn\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K\n",
            "  105 |     \u001b[01;31m\u001b[Kinit::kaiming_uniform_(\u001b[m\u001b[K\n",
            "      |     \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~~~^\u001b[m\u001b[K\n",
            "      |                           \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                           \u001b[01;31m\u001b[Kconst torch::enumtype::kFanIn\u001b[m\u001b[K\n",
            "  106 | \u001b[01;31m\u001b[K        weight,\u001b[m\u001b[K\n",
            "      |         \u001b[01;31m\u001b[K~~~~~~~\u001b[m\u001b[K            \n",
            "  107 | \u001b[01;31m\u001b[K        /*a=*/std::sqrt(5))\u001b[m\u001b[K; // NOLINT(cppcoreguidelines-avoid-magic-numbers)\n",
            "      |         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/init.h:99:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 3 of \u001b[01m\u001b[Kat::Tensor torch::nn::init::kaiming_uniform_(at::Tensor, double, int, int)\u001b[m\u001b[K\n",
            "   99 |     \u001b[01;36m\u001b[KFanModeType mode = torch::kFanIn\u001b[m\u001b[K,\n",
            "      |     \u001b[01;36m\u001b[K~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h: In instantiation of \u001b[01m\u001b[Kvoid torch::nn::ConvNdImpl<D, Derived>::reset_parameters() [with long unsigned int D = 1; Derived = torch::nn::Conv1dImpl]\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:101:5:\u001b[m\u001b[K   required from \u001b[01m\u001b[Kvoid torch::nn::ConvNdImpl<D, Derived>::reset() [with long unsigned int D = 1; Derived = torch::nn::Conv1dImpl]\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:33:8:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/modules/conv.h:105:27:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kcannot convert \u001b[01m\u001b[Kconst torch::enumtype::kFanIn\u001b[m\u001b[K to \u001b[01m\u001b[Kint\u001b[m\u001b[K\n",
            "  105 |     \u001b[01;31m\u001b[Kinit::kaiming_uniform_(\u001b[m\u001b[K\n",
            "      |     \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~~~~^\u001b[m\u001b[K\n",
            "      |                           \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
            "      |                           \u001b[01;31m\u001b[Kconst torch::enumtype::kFanIn\u001b[m\u001b[K\n",
            "  106 | \u001b[01;31m\u001b[K        weight,\u001b[m\u001b[K\n",
            "      |         \u001b[01;31m\u001b[K~~~~~~~\u001b[m\u001b[K            \n",
            "  107 | \u001b[01;31m\u001b[K        /*a=*/std::sqrt(5))\u001b[m\u001b[K; // NOLINT(cppcoreguidelines-avoid-magic-numbers)\n",
            "      |         \u001b[01;31m\u001b[K~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kctcdecode/src/binding.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/nn/init.h:99:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 3 of \u001b[01m\u001b[Kat::Tensor torch::nn::init::kaiming_uniform_(at::Tensor, double, int, int)\u001b[m\u001b[K\n",
            "   99 |     \u001b[01;36m\u001b[KFanModeType mode = torch::kFanIn\u001b[m\u001b[K,\n",
            "      |     \u001b[01;36m\u001b[K~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/ctcdecode/third_party/kenlm -I/content/ctcdecode/third_party/openfst-1.6.7/src/include -I/content/ctcdecode/third_party/ThreadPool -I/content/ctcdecode/third_party/boost_1_67_0 -I/content/ctcdecode/third_party/utf8 -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/include/python3.10 -c third_party/openfst-1.6.7/src/lib/fst.cc -o build/temp.linux-x86_64-cpython-310/third_party/openfst-1.6.7/src/lib/fst.o -O3 -DKENLM_MAX_ORDER=6 -std=c++14 -fPIC -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB -DINCLUDE_KENLM -DKENLM_MAX_ORDER=6 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=ctc_decode -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "error: command '/usr/bin/x86_64-linux-gnu-g++' failed with exit code 1\n",
            "In file included from \u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/fst.h:21\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kthird_party/openfst-1.6.7/src/lib/fst.cc:6\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/compat.h:\u001b[m\u001b[K In member function \u001b[01m\u001b[Kvoid fst::CheckSummer::Update(const string&)\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/compat.h:87:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: \u001b[01m\u001b[Kint\u001b[m\u001b[K and \u001b[01m\u001b[Kstd::basic_string<char>::size_type\u001b[m\u001b[K {aka \u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   87 |     for (int i = 0; \u001b[01;35m\u001b[Ki < data.size()\u001b[m\u001b[K; ++i) {\n",
            "      |                     \u001b[01;35m\u001b[K~~^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/fst.h:30\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kthird_party/openfst-1.6.7/src/lib/fst.cc:6\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/symbol-table.h:\u001b[m\u001b[K In member function \u001b[01m\u001b[Kstd::string fst::internal::SymbolTableImpl::Find(int64) const\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/symbol-table.h:142:24:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: \u001b[01m\u001b[Kint64\u001b[m\u001b[K {aka \u001b[01m\u001b[Klong int\u001b[m\u001b[K} and \u001b[01m\u001b[Ksize_t\u001b[m\u001b[K {aka \u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  142 |     if (idx < 0 || \u001b[01;35m\u001b[Kidx >= symbols_.size()\u001b[m\u001b[K) return \"\";\n",
            "      |                    \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/symbol-table.h:\u001b[m\u001b[K In member function \u001b[01m\u001b[Kint64 fst::internal::SymbolTableImpl::GetNthKey(ssize_t) const\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/symbol-table.h:159:24:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: \u001b[01m\u001b[Kssize_t\u001b[m\u001b[K {aka \u001b[01m\u001b[Klong int\u001b[m\u001b[K} and \u001b[01m\u001b[Ksize_t\u001b[m\u001b[K {aka \u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  159 |     if (pos < 0 || \u001b[01;35m\u001b[Kpos >= symbols_.size()\u001b[m\u001b[K) return kNoSymbol;\n",
            "      |                    \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/symbol-table.h:\u001b[m\u001b[K In member function \u001b[01m\u001b[Kbool fst::SymbolTableIterator::Done() const\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/symbol-table.h:403:36:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: \u001b[01m\u001b[Kconst ssize_t\u001b[m\u001b[K {aka \u001b[01m\u001b[Kconst long int\u001b[m\u001b[K} and \u001b[01m\u001b[Kconst size_t\u001b[m\u001b[K {aka \u001b[01m\u001b[Kconst long unsigned int\u001b[m\u001b[K} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  403 |   bool Done() const { return (\u001b[01;35m\u001b[Kpos_ == nsymbols_\u001b[m\u001b[K); }\n",
            "      |                               \u001b[01;35m\u001b[K~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/symbol-table.h:\u001b[m\u001b[K In member function \u001b[01m\u001b[Kvoid fst::SymbolTableIterator::Next()\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/symbol-table.h:414:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: \u001b[01m\u001b[Kssize_t\u001b[m\u001b[K {aka \u001b[01m\u001b[Klong int\u001b[m\u001b[K} and \u001b[01m\u001b[Ksize_t\u001b[m\u001b[K {aka \u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  414 |     if (\u001b[01;35m\u001b[Kpos_ < nsymbols_\u001b[m\u001b[K) key_ = table_.GetNthKey(pos_);\n",
            "      |         \u001b[01;35m\u001b[K~~~~~^~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/connect.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/test-properties.h:14\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/const-fst.h:21\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/matcher-fst.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kthird_party/openfst-1.6.7/src/lib/fst.cc:12\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/dfs-visit.h:\u001b[m\u001b[K In function \u001b[01m\u001b[Kvoid fst::DfsVisit(const FST&, Visitor*, ArcFilter, bool)\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/dfs-visit.h:97:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Ktypedef \u001b[01m\u001b[Kusing StateId = typename FST::Arc::StateId\u001b[m\u001b[K locally defined but not used [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-local-typedefs\u0007-Wunused-local-typedefs\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   97 |   using \u001b[01;35m\u001b[KStateId\u001b[m\u001b[K = typename Arc::StateId;\n",
            "      |         \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/state-map.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/arcsort.h:14\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/accumulator.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/label-reachable.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/lookahead-matcher.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/matcher-fst.h:14\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kthird_party/openfst-1.6.7/src/lib/fst.cc:12\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/arc-map.h:\u001b[m\u001b[K In function \u001b[01m\u001b[Kvoid fst::ArcMap(fst::MutableFst<Arc>*, C*)\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/arc-map.h:97:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Ktypedef \u001b[01m\u001b[Kusing StateId = typename FromArc::StateId\u001b[m\u001b[K locally defined but not used [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-local-typedefs\u0007-Wunused-local-typedefs\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   97 |   using \u001b[01;35m\u001b[KStateId\u001b[m\u001b[K = typename FromArc::StateId;\n",
            "      |         \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/arc-map.h:\u001b[m\u001b[K In function \u001b[01m\u001b[Kvoid fst::ArcMap(const fst::Fst<Arc>&, fst::MutableFst<B>*, C*)\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/ctcdecode/third_party/openfst-1.6.7/src/include/fst/arc-map.h:184:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Ktypedef \u001b[01m\u001b[Kusing Weight = typename FromArc::Weight\u001b[m\u001b[K locally defined but not used [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-local-typedefs\u0007-Wunused-local-typedefs\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  184 |   using \u001b[01;35m\u001b[KWeight\u001b[m\u001b[K = typename FromArc::Weight;\n",
            "      |         \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "Processing /content/ctcdecode\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ctcdecode\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for ctcdecode (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for ctcdecode\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for ctcdecode\n",
            "Failed to build ctcdecode\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (ctcdecode)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}